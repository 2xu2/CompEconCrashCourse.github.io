[
  {
    "objectID": "Julia/Lectures/Julia_Lec_4_Compecon_Xing_Xu.html",
    "href": "Julia/Lectures/Julia_Lec_4_Compecon_Xing_Xu.html",
    "title": "Lecture 4: Incomplete market models with transition dynamics",
    "section": "",
    "text": "In this lecture, I introduce the basic set-up of the workhorse incomplete market model – the Aiyagari model and discuss how to compute it numerically. When writing this lecture, I largely follow from my answer for problem set 3 and 4 for Manuel Amador’s Macro class.\nUseful notes: Jesus Fernandez-Villaverde’s notes on heterogeneous agent models: part 1, part 2, part 3.\n\nGeneral set up of the Aiyagari model\n\nEnvironment:\n\nHousehold:\nContinuum of household with mass 1:\nHousehold has identical preferences: \\[\n\\sum_{t=0}^\\infty \\beta^t u(c_t)\n\\],\nsubject to a budget constraint: \\(c_t + a_{t+1} \\leq w_t l_t(s^t) + R_t a_t, \\forall t\\),\nand a borrowing limit: \\(a_{t + 1} \\geq \\phi, \\forall t\\),\nwith \\(a_0, l_0 \\geq 0\\) given.\n\nLet labor endowments for each household follow a markov chain with a transition matrix \\(\\pi\\), \\(\\pi(s'|s) &gt; 0, \\forall s, s'\\). The invariant distribution of labor supply is a probability distribution \\(\\lambda\\) such that \\(\\lambda \\pi = \\pi\\).\nBy law of large number, the aggregate labor supply \\(L = \\sum_{s \\in S} \\lambda(s) l(s)\\) does not depend on \\(s\\) (no aggregate uncertainty). This is a key feature of the problem.\n\n\n\nFirm:\nA perfectly competitive firm with Neo-classical technology: \\[\nY_t = F(K_t, L_t).\n\\]\n\n\nAggregate resource constraint:\n\\[\nC_t + K_{t+1} - (1 - \\delta) K_t = F(K_t, L)\n\\] with depreciation rate \\(\\delta \\in (0,1)\\).\n\n\n\n\nRecursive formulation of the household problem\nAssume utility is strictly increasing. Taking the interest rate \\(R\\) and \\(w\\) as given, the household problem takes the recursive form:\n\\(V(a, s) = \\max_{a'\\geq \\phi} u(Ra + w l(s) - a') + \\beta E[V(a', s')]\\)\nwhere \\(s\\) is the realization of the labor endowment today.\n\nSide notes on alternative specification of the household problem:\nAlternatively we can write the problem as \\(V(x, s) = \\max_{a'\\geq \\phi} u(x - a') + \\beta E[V(Ra' + w l(s'), s')]\\), where \\(x \\equiv Ra + w l(s)\\) is the cash in hand today. Note that the value function will be different as it is now a function of \\(x\\). The key here is that one need to make sure that the state variables on both sides are consistent.\nOn top of this, Aiyagari used a trick to simplify the problem. Define \\(\\hat{a} = a + \\phi\\), \\(\\hat{x} = x + \\phi\\). Then, the household problem can be rewritten as:\n\\(v(\\hat{x}, s) = \\max_{\\hat{a}' \\geq 0} u(\\hat{x} - \\hat{a}') + \\beta E[v(R\\hat{a}' + w l(s') - (R - 1) \\phi), s']\\)\n\nNow let’s try to solve the household problem using \\(a\\) as the first state variable given particular \\(R\\) and \\(w\\). This is essentially a partial equilibrium and is often referred to as a Bewley/Hugget model.\n\n\n\nComputing the Bewley/Hugget Model\nNote that here only the product of \\(w\\) and \\(l\\) matters here and there’s no interesting mechanism for determining \\(w\\). For simplicity, we define \\(y(s) \\equiv wl(s)\\) such that \\(V(a, s) = \\max_{a'\\geq \\phi} u(Ra + y(s) - a') + \\beta E[V(a', s')]\\). Further assume \\(s\\) follows a first-order markov chain governed by states \\(y(s)\\) and transition matrix \\(P\\).\nWe will construct grids using \\(a\\). Let \\(a\\) start from \\(\\phi\\) so the agent cannot over-borrow.\nThe following codes are adopted from problem set 2 and 3 from Manuel Amador’s Macro class.\nAs before, Base.@kwdef struct is used to store the parameters. However here instead of some specific types like Float64, we use parametric types like R1 and T1. These can really be any types dependent on the input. Check the documentation for parametric types here.\n\nusing LinearAlgebra\nusing Plots\n\n\nBase.@kwdef struct Household{T1, T2, T3, R1, S}\n    β::R1 = 0.95\n    ρ::R1 = 2.0 \n    ϕ::R1 = 0.0  # The borrowing limit is zero \n    P::T1 = [0.5 0.5; 0.2 0.8] # transition matrix for state s\n    l::T2 = [0.5, 1.0] # labor endowment: l(s) (normalize w to 1.0 so that y(s) = l(s))\n    a_min::R1 = ϕ\n    a_max::R1 = 5.0\n    points::S = 10_000\n    \n    a_grid::T3 = range(a_min, a_max, points)\nend\n\nu(c, m) = c ^ (1 - m.ρ) / (1 - m.ρ)  \nuprime(c, m) = c ^ (-m.ρ) \n\nuprime (generic function with 1 method)\n\n\nNow solve the value function as before. Since we have two states now, we need a matrix to store the value and policy for each different combination of \\(a\\) and \\(y\\).\nThere are mainly two tricks in the code. The first is to pre-compute the expected discounted value for each \\(a'\\) and \\(s'\\) conditional on \\(s\\) within the outer loop. The second is to take use of the fact of strictly increasing policy function as we have seen in Lecture 2.\n\nfunction solve_household(h; R = 0.9, w = 1.0, v0 = zeros(length(h.a_grid), length(h.l)),  tol = 1e-6)\n    \n    # unpacking \n    (; a_grid, l, β, P) = h\n    \n    v1 = similar(v0)\n    pol = similar(v0, Int)\n    βv = similar(v1)\n    \n    n = length(a_grid)\n    \n    iter = 0\n    while true\n        distance = zero(eltype(v0))\n        iter += 1 \n        \n        # Precompute βE[V(a', s')] for better performance\n        for s in eachindex(l)\n            for i in eachindex(a_grid)\n                accum = zero(eltype(v0))\n                for sprime in eachindex(l)\n                    accum += β * P[s, sprime] * v0[i, sprime]\n                end\n                βv[i, s] = accum\n            end \n        end\n        # or simply βv = β .* v0 * P' \n\n        for s in eachindex(l) \n            pol_i = 1\n            for i in eachindex(a_grid)\n                just_started = true \n                vmax = zero(eltype(v0))\n                for j in pol_i:n #take use of strictly increasing policy function\n                    c = R * a_grid[i] + w*l[s] - a_grid[j]\n                    if c &gt; 0.0\n                        v_tmp = u(c, h) + βv[j, s]\n                        if just_started\n                            vmax = v_tmp\n                            pol_i = j\n                            just_started = false\n                        elseif v_tmp &gt; vmax \n                            vmax = v_tmp \n                            pol_i = j\n                        else \n                            break \n                        end \n                    end \n                end \n                v1[i, s] = vmax\n                pol[i, s] = pol_i\n                dis = abs(vmax - v0[i, s])\n                if dis &gt; distance\n                    distance = dis\n                end \n            end \n        end \n        \n        if distance &lt; tol\n            break\n        else \n            v0 .= v1\n        end \n    end \n    return (v = v1, pol = pol, h = h, R = R, w = w)\nend \n    \n\nsolve_household (generic function with 1 method)\n\n\nExplanations over how the code works (GPT generated, which is actually pretty good):\nThis function solve_household solves the household problem defined earlier using value function iteration. The function takes in the model parameters as input, par, and some optional arguments such as an initial guess for the value function v0 and a tolerance level tol.\nThe function initializes some variables such as v1 and pol as arrays of zeros with the same shape as v0, which is the value function from the previous iteration. βv is also initialized as an array of zeros, which will be used to store the expected value of the next iteration.\nThe function then performs the value function iteration using a nested loop over ytilde and ahat_grid. The inner loop first computes the expected value of the next iteration using the Bellman equation and stores it in βv.\nThe inner loop then maximizes the Bellman equation over the choice of next period asset holding ahat_grid[j] using a nested loop that starts at pol_i. This is done to take advantage of the fact that the optimal choice of ahat_grid[j] is increasing in j. The loop computes the value of the Bellman equation for each ahat_grid[j] and stops once the first ahat_grid[j] is found that yields a negative consumption level c. The function then stores the optimal value function vmax and the corresponding choice of j in pol_i and moves on to the next ahat_grid[i].\nThe function then computes the distance between the value function from the current iteration v0 and the value function from the previous iteration v1. If the distance is less than the tolerance level tol, the function exits the loop and returns the value function v1, the policy function pol, and the model parameters m.\nOverall, the function uses a nested loop to solve the household problem using value function iteration, and it takes advantage of the fact that the problem has a recursive structure and a simple functional form for the utility function to compute the optimal value and policy functions efficiently.\n\nh = Household() # struct with default parameter values\nsol_1 = solve_household(h, R = 0.658) #input some random R. \n\n(v = [-26.71326843693425 -25.314667038332857; -26.711953170852723 -25.314338113656607; … ; -24.019524603316466 -23.72455416253825; -24.019409824729976 -23.72445885993552], pol = [1 1; 1 1; … ; 4194 4864; 4194 4864], h = Household{Matrix{Float64}, Vector{Float64}, StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, Float64, Int64}(0.95, 2.0, 0.0, [0.5 0.5; 0.2 0.8], [0.5, 1.0], 0.0, 5.0, 10000, 0.0:0.0005000500050005:5.0), R = 0.658, w = 1.0)\n\n\nLet’s take a look at the value function and policy functions\n\nfunction do_v_plot(sol_1)\n\n    income = sol_1.w * sol_1.h.l \n    p1 = Plots.plot(xlabel = \"Current saving, a\", ylabel = \"Value, v\")\n    for i in eachindex(income)\n        temp = income[i]\n        plot!(p1, sol_1.h.a_grid, sol_1.v[:,i], label = \"y = $temp\")\n    end\n    \n    return p1\nend\n\ndo_v_plot(sol_1)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfunction do_pol_plot(sol_1)\n\n    (; pol, h)= sol_1 \n\n    p1 = Plots.plot(xlabel = \"Current saving, a\", ylabel = \"Saving next period, a' \")\n    for s in eachindex(h.l)\n        temp = sol_1.w * h.l[s]\n        yvals = [[h.a_grid[pol[i, s]] for i in eachindex(h.a_grid)]]\n        plot!(p1, sol_1.h.a_grid, yvals, label = \"y = $temp\")\n    end\n    \n    return p1\nend\n\ndo_pol_plot(sol_1)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that when \\(y\\) is low. The policy function for \\(a'\\) is flat. The intuition is that the agent has incentive to borrow for consumption smoothing when endowment is low (why?) but is borrowing constrained due to the \\(0\\) borrowing limit. As a result, the agent consumes all her endowment. This is sometimes referred to as “Hand-to-mouth” consumption.\n\n\nRecursive competitive equilibrium (Aiyagari 1994)\nWith some understanding of the partial equilibrium, we now try to build towards the general equilibrium. With household optimality, firm optimality and market clearing conditions, the equilibrium can be formally defined by a recursive competitive equilibrium.\nThe key difference is that every household now needs to know the distribution of everyone else’s asset holdings to infer future interest rate.\nLet \\(a \\in A \\equiv [\\phi, \\infty]\\), \\(s \\in S\\). From the recursive form of the household problem, for given R we can solve for a value function \\(v(a, s): A \\times S \\to R\\) and a policy function for saving \\(g(a, s): A \\times S \\to A\\).\n\nPrices in general equilibrium\nNow for simplicity, let the firm technology be characterized by a CRS Cobb-Douglas production function, i.e. \\[\nY_t = A K_t^\\alpha L_t^{1 - \\alpha}.\n\\]\nThe firm’s problem takes the form: (why?)\n\\[\\max_{K_t, L_t} A K_t^\\alpha L_t^{1 - \\alpha} - (R_t -1 +\\delta) K_t - w_t L_t\\]\nFirm’s first order conditions: \\[\n\\begin{cases}\nR_t = A \\alpha K_t^{\\alpha - 1} L_t^{1 - \\alpha} +1 - \\delta \\\\\nw_t = A (1 - \\alpha) K_t^\\alpha L_t^{-\\alpha}\n\\end{cases}\n\\]\nNote that \\(w\\) can be pinned down by \\(R\\) in equilibrium: \\[\nw_t(R_t) = A^{\\frac{1}{1-\\alpha}} (1 - \\alpha) \\alpha^{\\frac{\\alpha}{1 - \\alpha}} \\left(R_t - 1 +\\delta \\right)^{\\frac{\\alpha}{1 - \\alpha}}\n\\]\nThis is very handy when it comes to computing the equilibrium prices.\n\n\n\nStationary Competitive Equilibrium\n\nSet up of a (recursive) stationary competitive equilibrium\nA stationary competitive equilibrium is defined by a system of constant prices (interest rate and wage) and allocations such that individuals optimize and markets clear.\nDefine \\(\\lambda_t(a, s): A \\times S \\to [0,1]\\) to be the distribution of household over current asset \\(a\\) and state \\(s\\). Imagine it to be a matrix with each entry filled with the fraction of household with each combination of possible \\(a\\) and \\(s\\). Hypothetically, this should evolve over time following a law of motion: \\[\n\\lambda_{t+1}(a', s') = \\sum_{s \\in S} \\sum_{a: g(a,s) = a'} \\pi(s'|s) \\lambda_t(a,s), \\quad \\forall a', s'\n\\]\nwhere \\(\\pi(s'|s)\\) is the transition probability and \\(\\sum_{a: g(a,s) = a'}\\) reads that all \\(a\\) such that \\(g(a,s) = a'\\). Intuitively, the fraction of households that falls into the state \\(a'\\) and \\(s'\\) next period will be the fraction of households (with different \\(a\\) and \\(s\\)) that choose \\(a'\\) times the conditional probability that the household moves into \\(s'\\) next period.\nDoes the economy converge to some kind of steady state (stationary equilibrium)? Here, in a stationary equilibrium, \\(\\lambda_t = \\lambda, \\forall t\\) and all aggregate real quantities and prices stay constant. Aiyari (1994) proved that under some conditions, with no aggregate shock, a stationary competitive equilibrium exists for the economy. For clarity, I will formally define the stationary competitive equilibrium as follows.\nA stationary competitive equilibrium is scalars \\(\\{R, w, K, L\\}\\) and functions \\(\\{v, g, \\lambda\\}\\) such that:\n\nThe value function, \\(v\\) satisfies the Household’s problem given \\(R, w\\) and \\(l(s)\\), and \\(g\\) is an optimal policy to the problem.\n\\(\\lambda\\) is the stationary distribution that arises from \\(g\\) and \\(\\pi\\) (from above).\nAsset market clears, i.e. \\(K = \\sum_{s \\in S} \\sum_{a \\in A} \\lambda(a,s) g(a,s)\\).\nLabor market clears, i.e. \\(L = \\sum_{s \\in S} \\sum_{a \\in A} \\lambda(a,s) l(s)\\).\nFirm’s optimality conditions are satisfied.\n\nGood’s market will clear with a Walras’ Law-ish argument.\nNow let’s build towards computing the model. Add some more parameters in the struct.\n\nBase.@kwdef struct Household_GE{T1, T2, T3, R1, S}\n    β::R1 = 0.7\n    ρ::R1 = 2.0 \n    ϕ::R1 = 0.0  # The borrowing limit is zero \n    P::T1 = [0.5 0.5; 0.2 0.8] # transition matrix for state s\n    l::T2 = [1.0, 5.0] # l(s)\n    a_min::R1 = ϕ\n    a_max::R1 = 5.0\n    points::S = 10_000\n\n    a_grid::T3 = range(a_min, a_max, points)\n\n    A::R1 = 1.20\n    α::R1 = 0.7\n    δ::R1 = 1.0  #full depreciation\nend\n\nu(c, m) = c ^ (1 - m.ρ) / (1 - m.ρ)  \nuprime(c, m) = c ^ (-m.ρ) \n\nuprime (generic function with 1 method)\n\n\n\nh_GE = Household_GE()\n\nHousehold_GE{Matrix{Float64}, Vector{Float64}, StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, Float64, Int64}(0.7, 2.0, 0.0, [0.5 0.5; 0.2 0.8], [1.0, 5.0], 0.0, 5.0, 10000, 0.0:0.0005000500050005:5.0, 1.2, 0.7, 1.0)\n\n\nIt is useful to note that at stationary equilibrium, \\(L\\) is a constant. This is because if you solve for the invariant distribution of \\(P\\) (the transition probability \\(\\pi\\) ), \\(L\\) can be written as \\(\\sum_{s \\in S} \\pi(s) l(s)\\). Here we will numerically compute \\(L\\).\n\nfunction compute_L(P, l)\n    # approximate the invariant distribution of labor endowment (inefficient)\n    temp = P^100\n    L = 0\n    for i in eachindex(l)\n        L = L + l[i] * temp[1,i] \n    end\n    return L\nend\n\ncompute_L(h_GE.P, h_GE.l)\n\n3.857142857142877\n\n\nFirst let’s compute the invariant distribution given some \\(R\\). For simplicity let \\(A\\) be 1 (not the correct way if you want to calibrate the model). Since we want to include firm’s optimality conditions, modify the function for computing \\(v\\) to include firm’s optimality condition. Now we have \\(K\\) as input and then solve for \\(R\\) and \\(w\\) endogenously.\n\nfunction solve_household_GE(h_GE; K = 0.5, v0 = zeros(length(h_GE.a_grid), length(h_GE.l)),  tol = 1e-6)\n    \n    # unpacking \n    (; a_grid, l, β, P, A, α, δ) = h_GE\n    \n    L = compute_L(P, l)\n\n    R = A * α * K^(α - 1) * L^(1 - α) + 1 - δ# Get R from the firm's first order condition\n\n    w = A * (1 - α) * K^α * L^(- α) # Get w from the firm's first order condition\n\n\n    #Given K\n\n    v1 = similar(v0)\n    pol = similar(v0, Int)\n    βv = similar(v1)\n    \n    n = length(a_grid)\n    \n    iter = 0\n    while true\n        distance = zero(eltype(v0))\n        iter += 1 \n        \n        # Precompute βE[V(a', s')] for better performance\n        for s in eachindex(l)\n            for i in eachindex(a_grid)\n                accum = zero(eltype(v0))\n                for sprime in eachindex(l)\n                    accum += β * P[s, sprime] * v0[i, sprime]\n                end\n                βv[i, s] = accum\n            end \n        end\n\n        for s in eachindex(l) \n            pol_i = 1\n            for i in eachindex(a_grid)\n                just_started = true \n                vmax = zero(eltype(v0))\n                for j in pol_i:n #take use of strictly increasing policy function\n                    c = R * a_grid[i] + w * l[s] - a_grid[j]\n                    if c &gt; 0.0\n                        v_tmp = u(c, h_GE) + βv[j, s]\n                        if just_started\n                            vmax = v_tmp\n                            pol_i = j\n                            just_started = false\n                        elseif v_tmp &gt; vmax \n                            vmax = v_tmp \n                            pol_i = j\n                        else \n                            break \n                        end \n                    end \n                end \n                v1[i, s] = vmax\n                pol[i, s] = pol_i\n                dis = abs(vmax - v0[i, s])\n                if dis &gt; distance\n                    distance = dis\n                end \n            end \n        end \n        \n        if distance &lt; tol\n            break\n        else \n            v0 .= v1\n        end \n    end \n    return (v = v1, pol = pol, h = h_GE, R = R, w = w)\nend \n    \n\nsolve_household_GE (generic function with 1 method)\n\n\n\nsol_2 = solve_household_GE(h_GE, K = 0.75)\n\n(v = [-17.561774071593458 -7.641618063043207; -17.509638148903143 -7.637543522427641; … ; -1.5204371786915847 -1.4164179272473385; -1.5203069683874395 -1.4163050174215155], pol = [1 324; 1 325; … ; 9364 9940; 9365 9941], h = Household_GE{Matrix{Float64}, Vector{Float64}, StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, Float64, Int64}(0.7, 2.0, 0.0, [0.5 0.5; 0.2 0.8], [1.0, 5.0], 0.0, 5.0, 10000, 0.0:0.0005000500050005:5.0, 1.2, 0.7, 1.0), R = 1.3729054349841805, w = 0.11440878624868113)\n\n\n\nfunction compute_stationary_distribution(sol; tol = 1e-8, pdf_0 = fill(1.0 / prod(size(sol.v)), size(sol.v)) )\n    (; pol, h) = sol\n    \n    pdf_1 = similar(pdf_0)\n    \n    while true \n        fill!(pdf_1, zero(eltype(pdf_0)))\n        \n        for i in eachindex(h.a_grid)\n            for s in eachindex(h.l)\n                for sprime in eachindex(h.l)\n                    pdf_1[pol[i, s], sprime] += h.P[s, sprime] * pdf_0[i, s]\n                end\n            end \n        end\n        \n        distance = zero(eltype(pdf_0))\n        for (a, b) in zip(pdf_0, pdf_1)\n            distance = max(abs(a - b), distance)\n        end\n        \n        (distance &lt; tol) && break \n        pdf_0 .= pdf_1\n    end \n    return pdf_1\nend \n\ncompute_stationary_distribution (generic function with 1 method)\n\n\n\npdfA = compute_stationary_distribution(sol_2)\nplot(sol_2.h.a_grid, sum(pdfA, dims = 2)[:, 1], label = \"pdf\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOf course you can also plot the CDF.\n\nplot(sol_2.h.a_grid, cumsum(sum(pdfA, dims = 2)[:, 1]), label = \"cdf\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also compute the aggregate asset supply under the invariant distribution, which is simply:\n\n# function for computing A under the invariant distribution\nfunction compute_A(sol, pdf)\n    a = similar(sol.v)\n    a = sol.h.a_grid[sol.pol]\n    return a⋅pdf \nend\n\ncompute_A (generic function with 1 method)\n\n\n\n@show compute_A(sol_2, pdfA)\n\ncompute_A(sol_2, pdfA) = 1.047829596172126\n\n\n1.047829596172126\n\n\n\n\nThe capital demand and supply curve\nSince the aggregate labor supply \\(L\\) is a constant as we have argued, the only equilibrium object that has to been determined endogenously is the market clearing capital (or asset). Now, the equilibrium interest rate \\(R = AαK^{α - 1} L^{1 - α} + 1 - δ\\) is a one-to-one function of \\(K\\). The inverse function \\(K(R)\\) gives the capital demand curve, which is continuous and downward sloping. From the household problem, given each R, we can endogenously solve out the asset supply curve with the invariant distribution of household, which will be continuous and upward sloping. I denote the supply as \\(A(R)\\). The unique intersection of \\(K(R)\\) and \\(A(R)\\) gives out the equilibrium capital and the corresponding interest rate.\nThe following function solves out the aggregate asset supply and capital demand over a grid of possible equilibrium interest rate \\(R\\).\n\nfunction K_demand_supply(h_GE; R_grids = range(0.95, 1.0/h_GE.β, 100), K_demand = similar(R_grids), A_supply = similar(R_grids), w_grids = similar(R_grids))\n    (; a_grid, l, β, P, A, α, δ) = h_GE\n    L = compute_L(P, l)\n    # get the demand function\n    K_demand  = @. ((R_grids  - 1 + δ)/(A * α  * L^(1 - α)))^(1/(α - 1))\n\n    # equilibrium wages\n    w_grids = @. A^(1/(1-α)) * (1 - α) * α^(α/(1 - α)) / (R_grids - 1 + δ)^(α/(1-α))\n    # get the supply function (use the original VFI function)\n    for i in eachindex(R_grids)\n        sol = solve_household(h_GE, R = R_grids[i], w = w_grids[i])\n        pdf = compute_stationary_distribution(sol)\n        A_supply[i] = compute_A(sol, pdf)\n    end\n    return R_grids, K_demand, A_supply\nend\n\nR_grids, K_demand, A_supply = K_demand_supply(h_GE)\n\n(0.95:0.004834054834054834:1.4285714285714286, [2.5592811230762695, 2.516345927319649, 2.474342418197531, 2.4332458368040855, 2.3930322016718937, 2.353678280645201, 2.3151615639038146, 2.277460238085242, 2.2405531614551712, 2.2044198400790145  …  0.7282763869637299, 0.719867466600011, 0.7115843300746376, 0.7034246696389707, 0.695386227650787, 0.6874667953188908, 0.6796642114833356, 0.6719763614301456, 0.6644011757394387, 0.6569366291659031], [0.3935551678730847, 0.39275776490277464, 0.39199031525591366, 0.3911147352032359, 0.39089303063609615, 0.39115584409938453, 0.39160472443612426, 0.39218564845568704, 0.3928700139055018, 0.39364469678411473  …  1.2179868137367416, 1.3090272943476338, 1.4205468127468952, 1.5608866788486613, 1.7443162211259264, 1.9941783002778637, 2.3511808837319235, 2.847716210221898, 3.433878827587586, 3.958195215474183])\n\n\n\nfunction K_plot(K_demand, A_supply, h_GE; R_grids = range(0.95, 1.0/h_GE.β, 100))\n    plot(R_grids, K_demand, label = \"K(R)\")\n    plot!(R_grids, A_supply, label = \"A(R)\")\nend\n\nK_plot(K_demand, A_supply, h_GE)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can look at when \\(A(R)\\) first exceeds \\(K(R)\\) to have a guess on the equilibrium capital and interest rate.\n\nfunction find_first(K_demand, A_supply)\n    idx = 0\n    for i in eachindex(K_demand)\n        if A_supply[i] &gt; K_demand[i]\n            idx = i\n            break\n        end\n    end\n    return idx\nend\n\ni = find_first(K_demand, A_supply)\n\nK1 = K_demand[i]\nK2 = K_demand[i - 1]\nR1 = R_grids[i - 1]\nR2 = R_grids[i]\n\nprint(\"The equilibrium capital is between $K1 and $K2. The equilibrium interest rate is between $R1 and $R2.\")\n\nThe equilibrium capital is between 0.8003704925496153 and 0.8100242546324644. The equilibrium interest rate is between 1.3415584415584416 and 1.3463924963924965.\n\n\nChallenge for solving the equilibrium:\n\n\nSolving the stationary competitive equilibrium\nNow we have everything ready to compute the stationary competitive equilibrium.\nThe algorithm goes as follows:\n\nStart from a given \\(K_0\\)\nFor each \\(K_t\\) and obtain \\(R\\) and \\(w\\)\nSolve the household problem given \\(R\\) and \\(w\\)\nCompute invariant distribution \\(\\lambda(a, s)\\)\nGet \\(A \\equiv \\sum_{s \\in S} \\sum_{a \\in A} \\lambda(a,s) g(a,s)\\).\nGuess \\(K_{t+1} = ϵ A + (1 - ϵ) K_t\\). Go back to the second step and iterate until convergence.\n\n\ncompute_A(sol_2, pdfA)\n\n1.047829596172126\n\n\n\nfunction compute_stationary_equilibrium(h_GE; K0 = 0.70, tol = 1e-5, iterate = 0, ϵ = 0.3)\n    sol = solve_household_GE(h_GE, K = K0)\n    pdf = compute_stationary_distribution(sol)\n    A = compute_A(sol, pdf)\n\n    K = K0\n    K1 = ϵ * A + (1 - ϵ) *  K\n\n    while true \n        distance = zero(eltype(K))\n        sol = solve_household_GE(h_GE, K = K)\n        pdf = compute_stationary_distribution(sol)\n        A = compute_A(sol, pdf)\n        K1 = ϵ * A + (1 - ϵ) * K # for speed\n\n        distance = abs(K1 - K)\n        (distance &lt; tol || iterate == 100) && break\n        iterate += 1\n        K = copy(K1)\n    end \n    return (K_rce = K, sol_rce = sol, iterate = iterate) \nend\n\ncompute_stationary_equilibrium (generic function with 1 method)\n\n\nWarning: this can get slow as the parameter values are casually set and the algorithms are not optimized. If you play around with the parameters you might notice that sometimes it doesn’t converge. I will discuss this with more detail.\n\n@time begin\n    sol_GE = compute_stationary_equilibrium(h_GE)\nend\n\n  0.706224 seconds (24.39 k allocations: 12.320 MiB, 2.37% compilation time)\n\n\n(K_rce = 0.807696820287375, sol_rce = (v = [-16.717896304757282 -7.336975047166834; -16.67191258870082 -7.3334192227477315; … ; -1.606486499114749 -1.490479825567775; -1.6063520123876334 -1.4903641858039804], pol = [1 337; 1 338; … ; 9198 9812; 9199 9813], h = Household_GE{Matrix{Float64}, Vector{Float64}, StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, Float64, Int64}(0.7, 2.0, 0.0, [0.5 0.5; 0.2 0.8], [1.0, 5.0], 0.0, 5.0, 10000, 0.0:0.0005000500050005:5.0, 1.2, 0.7, 1.0), R = 1.342717011889535, w = 0.12050091789432643), iterate = 7)\n\n\n\n# equilibrium interest rate\n@show sol_GE.sol_rce.R\n\nsol_GE.sol_rce.R = 1.342717011889535\n\n\n1.342717011889535\n\n\n\n# equilibrium wage \n@show sol_GE.sol_rce.w\n\nsol_GE.sol_rce.w = 0.12050091789432643\n\n\n0.12050091789432643\n\n\n\nfunction do_pol_plot_GE(sol_1)\n\n    (; pol, h)= sol_1 \n\n    p1 = Plots.plot(xlabel = \"Current saving, a\", ylabel = \"Saving next period, a' \")\n    for s in eachindex(h.l)\n        temp = h.l[s]\n        yvals = [[h.a_grid[pol[i, s]] for i in eachindex(h.a_grid)]]\n        plot!(p1, sol_1.h.a_grid, yvals, label = \"l = $temp\")\n    end\n    \n    return p1\nend\n\n\ndo_pol_plot_GE(sol_GE.sol_rce)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat properties are important for solving the stationary equilibrium?\nOriginally the value that labor endowment process takes are 2 and 4, with same transition probability (now it’s 1 and 5). We can see that the algorithm for solving the stationary equilibrium doesn’t converge.\n\nh_GE1 = Household_GE(l = [2.0, 4.0])\n\nHousehold_GE{Matrix{Float64}, Vector{Float64}, StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, Float64, Int64}(0.7, 2.0, 0.0, [0.5 0.5; 0.2 0.8], [2.0, 4.0], 0.0, 5.0, 10000, 0.0:0.0005000500050005:5.0, 1.2, 0.7, 1.0)\n\n\nLet’s look at the capital demand and supply curve. Do you notice anything different?\n\nR_grids1, K_demand1, A_supply1 = K_demand_supply(h_GE1)\nK_plot(K_demand1, A_supply1, h_GE1)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe main difference is steeper asset supply curve, especially close to where the equilibrium asset and interest rate lies. We can check if we can solve for the stationary equilibrium.\n\nsol_GE1 = compute_stationary_equilibrium(h_GE1)\n\n(K_rce = 0.689482173249647, sol_rce = (v = [-10.938373253202755 -8.118259358389057; -10.926025926801701 -8.114221970562886; … ; -1.5501109947084142 -1.4943803850038575; -1.5499807113138844 -1.4942593212902437], pol = [1 118; 1 119; … ; 9491 9788; 9492 9789], h = Household_GE{Matrix{Float64}, Vector{Float64}, StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, Float64, Int64}(0.7, 2.0, 0.0, [0.5 0.5; 0.2 0.8], [2.0, 4.0], 0.0, 5.0, 10000, 0.0:0.0005000500050005:5.0, 1.2, 0.7, 1.0), R = 1.3591154017758917, w = 0.11713573011418807), iterate = 100)\n\n\n\n@show sol_GE1.iterate\n\nsol_GE1.iterate = 100\n\n\n100\n\n\nRecall that 100 is the upper bound we set for the total iterations. You can change it to higher value but in short you don’t get convergence. It is also often the case with other parameter choices as long as the asset supply curve is steep around where equilibrium lies around, i.e. the elasticity for interest rate is high.\nWhy this is troublesome? Now because the aggregate asset supply rises sharply where \\(R\\) is close to the equilibrium, to find an equilibrium we need good approximations of the policy function around where it matters. However recall that we used even grids for the assets, which causes inaccuracy of the policy function as we simply don’t have enough points where it truly matters. Again this is just due to approximation errors, which can be resolved from more grids around the equilibrium. One possible solution is endogenous grid methods.\nFor our purpose, we can just make the asset supply less elastic. That’s why I make the possible values of labor endowments wider. The reason this works goes back to the very nature of the “incompleteness” of the model. Household can’t insure against all future risks, so they have to save more than in a complete market due to strict concavity of utility. This is called precautionary saving. When the labor endowments get more fluctuant, either through wider values or smaller autocorrelation, the household saves more due to this motive. Fixing other parameters, households’ saving behavior is more driven by the uncertainty of the income shock.\nFor clarity, the key here lies in the comparison between the incentives to save due to precautionary saving and higher interest rate. Just for intuition, we enhanced the first channel and made the asset supply less elastic of the second.\nA final comment is that don’t be afraid when your code doesn’t work. Of course mostly it is some random mistakes and as long as you correct them, it is perfectly fine. More importantly, there are cases where something that doesn’t work actually teaches you a lesson, and often a most valuable one. Digging into some seemingly weird situations can provide valuable insights, as is the case here.\n\n\n\nTransition dynamics for incomplete market\nEconomists are often interested in the short-run response of agents given an unexpected one-time shock (often referred to as the MIT shock). Now we have the tools to compute the stationary competitive equilibrium. However as you can see, even under stationarity, this is a very complicated process.\nAssuming that households have perfect foresight over prices, this implies that household needs to know everyone else’s state today (knowing the distribution is sufficient) to infer the prices next period. In dynamic programming term, you need the whole distribution as an additional state variable. Note that the distribution is of very high dimensionality (here \\(A \\times s\\)), taking conditional expectation over this gigantic object is merely impossible.\nI put a simpler exercise based on a variation of the Hugget model in the exercise (adopted from Manuel’s problem set). One should be able to figure it out with the hints provided. I will provide a solution if you send me an email.\nKrussel Smith (1998) is a very important contribution to the computation technique of the model. They are able to show that first order approximations over prices provide very accurate results because the policy function is close to linear when \\(a\\) is not very low.\nThe latest development of the field is the sequence Jacobian. Auclert et al. provides a computation technique that is crazy fast.\n\n\nConclusion\nIncomplete market models are the workhorse models in modern Macroeconomic research, particularly in Macro-Labor and Macro-Finance. Knowing how to compute the basic model is of vital importance. In this lecture I started with the partial equilibrium version of the heteorgeneous household saving model (known as a Bewley/Hugget model), then I built towards the general equilibrium version of the model (known as an Aiyagari model). This lecture serves more as an introduction to allude readers to dive deeper themselves."
  },
  {
    "objectID": "Julia/Lectures/Julia_Lec_6_Compecon_Xing_Xu.html",
    "href": "Julia/Lectures/Julia_Lec_6_Compecon_Xing_Xu.html",
    "title": "Lecture 3: McCall’s Job search model",
    "section": "",
    "text": "Xing Xu, University of Minnesota, 2023 Summer\nThe McCall’s job search model is a classic model and widely used as the introduction to dynamic programming due to its simplicity and flexibility. However for the consistency with Tim’s Macro class, I discuss the Neoclassical growth model first.\nIn this lecture, we will compute the basic model and add a bunch of extensions.\nMain reference:\n\nTim’s Notes\nQuantecon’s notes\n\n\n3.1 The basic setup (Largely follows from Tim’s notes)\nAn unemployed worker faces a wage offer \\(w\\) every period. We assume the cumulative distribution of the wage offer to be \\(F(v) = Prob(w \\leq v), w \\in [0, B]\\).\nThe unemployment can choose either to accept the offer and get \\(w\\) forever, or receive unemployment benefit \\(b\\) and search again.\nAn unemployed worker solves \\[\n\\max E \\sum_{t = 0}^\\infty \\beta^t y_t\n\\]\nwhere \\(y_t = \\begin{cases}\nw \\text{ if employed } \\\\\nb \\text{ if unemployed }\n\\end{cases}\\).\nThe Bellman equation for an unemployed worker is: \\[\nV(w) = \\max \\{ \\frac{w}{1 - \\beta}, b + \\beta EV(w') \\},\n\\] \\[\nV(w) = \\max \\{ \\frac{w}{1 - \\beta}, b + \\beta \\int_0^B V(w')dF(w') \\}\n\\]\n\nusing Pkg\nPkg.add([\"LaTeXStrings\", \"Statistics\", \"Distributions\", \"Expectations\"])\n\n    Updating registry at `~/.julia/registries/General.toml`\n   Resolving package versions...\n  No Changes to `~/Documents/Teaching/Julia course 2023 Summer/Project.toml`\n  No Changes to `~/Documents/Teaching/Julia course 2023 Summer/Manifest.toml`\n\n\n\nusing LaTeXStrings # For Latex String in the graph\nusing LinearAlgebra, Statistics\nusing Distributions, Expectations\nusing Random\n\n\nusing StatsPlots\n\n\n\n3.2 Theoretical derivation\nSuppose we have solved the problem and found \\(V(w)\\). Then \\[\n\\bar{V} = b + \\beta \\int_0^B V(w')dF(w')\n\\] is a constant. Let \\(\\bar{w}\\) be such that \\[\n\\frac{\\bar{w}}{1 - \\beta} = \\bar{V} = b + \\beta \\int_0^B V(w')dF(w')\n\\]\nThen we have the policy function (as an indicator) being the unemployed worker will reject the offer if \\(w &lt; \\bar{w}\\) and accept the offer if \\(w \\geq \\bar{w}\\).\nSo hypothetically, the value function should look like:\n\nw = range(0, 4.0, length=100)\nv1 = 1/(1 - 0.7) .* w\nv2 = similar(w)\nv2 .= 7.98\nv3 = [max(v1[i], v2[i]) + 0.07 for i in 1:100] # +0.07 for asthetics\nplot(w, v1, line = (:red, 1), label = L\"\\frac{w}{1 - β}\")\nplot!(w, v2, line = (:green, 1), label = L\"\\bar{V}\")\nplot!(w, v3, line = (:blue, 2.5), label = L\"V(w)\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor formal derivations of the result check Tim’s notes.\nNow for simplicity, let the wage offer follows a discrete distribution that is uniform across the grids (this mimics the behavior of a continuous uniform distribution).\n\n\n3.3 Computing the model (VFI)\nThe steps are similar to those of the second lecture.\n\n# struct of parameters\nBase.@kwdef struct worker# or simply @kwdef\n    β :: Float64 = 0.7\n    b :: Float64 = 1.5 # unemployment benefit\n    N :: Int64 = 100\n\n    w = range(0.0, 4.0, N) # range of the distribution of wage offer \n    P :: Vector{Float64} = ones(N)./N # probability distribution\nend\n\nw_parameter = worker()\n\nworker(0.7, 1.5, 100, 0.0:0.04040404040404041:4.0, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01  …  0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01])\n\n\n\nfunction Mccall_discrete(w_parameter; tol = 1e-6)\n     # unpacking \n    (; β, b, N, w, P) = w_parameter\n    \n    v = ones(N)\n    pol = similar(v, Int)\n    v1 = similar(v)\n    βEv = zero(eltype(v))\n\n    iterate = 0\n\n    while true  \n        distance = zero(eltype(v))\n        \n        βEv = β * P' * v \n\n        # not very efficient\n        for i in eachindex(v1)\n            if w[i]/(1 - β) ≥ b + βEv \n                v1[i] = w[i]/(1 - β)\n                pol[i] = 2 #accepting the offer\n            else\n                v1[i] = b + βEv\n                pol[i] = 1 #rejecting the offer\n            end\n        end\n        \n        distance = maximum(abs.(v1 - v))\n\n        (distance &lt; tol || iterate == 1000) && break # break out of the whole loop if one of the statements is true\n        iterate += 1\n\n        # Vectorized update of v using element-wise assignment\n        v .= v1\n    end\n\n    return (v=v, βEv = βEv, pol=pol, iterate=iterate)\n\nend\n\nMccall_discrete (generic function with 1 method)\n\n\n\nMccall_discrete(w_parameter)\n\n(v = [7.758051209066076, 7.758051209066076, 7.758051209066076, 7.758051209066076, 7.758051209066076, 7.758051209066076, 7.758051209066076, 7.758051209066076, 7.758051209066076, 7.758051209066076  …  12.12121212121212, 12.255892255892254, 12.39057239057239, 12.525252525252524, 12.659932659932657, 12.794612794612792, 12.929292929292927, 13.063973063973062, 13.198653198653197, 13.333333333333332], βEv = 6.258051619163654, pol = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  2, 2, 2, 2, 2, 2, 2, 2, 2, 2], iterate = 18)\n\n\n\nfunction v_plot_Mccall(w_parameter)\n    w = w_parameter.w\n    (v, βEv, pol, iterate) = Mccall_discrete(w_parameter)\n    v2 = similar(w)\n    v2.= βEv + w_parameter.b\n    plot(w, w/(1 -  w_parameter.β), line = (:red, 1), label = L\"\\frac{w}{1 - β}\")\n    plot!(w, v2, line = (:green, 1), label = L\"\\bar{V}\")\n    plot!(w, v .+ 0.1, line = (:blue, 2.5), label = L\"V(w)\")\nend\n\nv_plot_Mccall(w_parameter)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the graph, one can observe that with the specified parameters. The reservation wage takes the value around 2.3.\nThe simplest way to obtain it is to observe that the policy function (indexed by 1 and 2 here) jumps from not accepting to accepting at the reservation wage.\nThis can be easily implemented with the findfirst() built-in function. Of course, you can alternatively write a loop over pol and use an if to find the index and break after the condition is met.\n\nfunction Reserve_w(w_parameter)\n    w = w_parameter.w\n    (v, βEv, pol, iterate) = Mccall_discrete(w_parameter)\n    \n    idx = findfirst(==(2), pol)\n    \n    return w[idx]\nend\n\nw1 = Reserve_w(w_parameter)\n\n2.3434343434343434\n\n\n\n\n3.4 Comparative Statics\nSince the employee’s decision is solely characterized by the reservation wage, looking at the impact of changing some of the model’s parameters on the reservation wage gives us a lot of insights.\nFirst, let’s think of the impact of a change in \\(\\beta\\) will have on the reservation wage. I make \\(\\beta\\) go up from 0.7 to 0.9.\n\nw2 = Reserve_w(worker(β = 0.9)) # easy change of parameter with struct\n\n2.909090909090909\n\n\n\nw2 &gt; w1\n\ntrue\n\n\nOther things being equal, the reservation wage is higher. That is, the worker is willing to wait longer for a higher paying job. This is consistent with the typical interpretation of higher \\(\\beta\\) as being more patient.\nNext up, let’s look at a change in the unemployment benefit \\(b\\). Let’s decrease the reservation wage \\(b\\) from \\(1.5\\) to \\(1.0\\).\n\nw3 = Reserve_w(worker(b = 1.0)) # easy change of parameter with struct\n\n2.101010101010101\n\n\n\nw3 &lt; w1\n\ntrue\n\n\nA decrease in unemployment benefit results in a smaller reservation wage (and lowers worker’s welfare). Intuitively, the opportunity cost of not accepting an offer is higher. An worker is then willing to take offers that pays less. This result can be formally proven. See Tim’s Notes.\nAt last, let’s look at the effect of a mean-preserving spread of the wage distribution on the reservation wage. A mean-preserving spread is a special case of second-order stochastic dominance – namely, the special case of equal means. Let A and B be two distributions. If B is a mean-preserving spread of A, then A is second-order stochastically dominant over B; and the converse holds if A and B have equal means.\nA necessary (not sufficient) condition for mean-preserving spread is higher variance.\nHere we can easily construct a mean-preserving spread for \\(P\\) with putting equal weights only on the first and last index of \\(w\\). (with 0.5 prob., worker gets 0 and with 0.5 prob., worker gets 4)\n\nN = w_parameter.N\nP_spread = zeros(N)\nP_spread[1] = 0.5\nP_spread[N] = 0.5\nw4 = Reserve_w(worker(P = P_spread))\n\n2.8686868686868685\n\n\n\nw4 &gt; w1\n\ntrue\n\n\nIt might seem surprising at first glance that a mean preserving spread actually increases worker’s reservation wage (in this case also worker’s welfare). This is because by the setup of the problem, the worker only cares about the right-tail of the distribution - she can always decline an offer that she doesn’t like. Intuitively, the worker will prefer a wage distribution that has equal mean but higher variance. The theoretical derivation for this result can again be seen in Tim’s Notes.\n\n\n3.5 Stopping time\nWe can compute the mean stopping time of job search. This is the expected periods of an unemployed worker finding a job.\nHere since we assumed an uniform distribution. We know the probability of an unemployed worker accepting the offer each period is \\(\\frac{\\bar{w}}{4.0}\\), where \\(\\bar{w}\\) is the reservation wage. We can compute the stopping time numerically:\n\nfunction stopping_time(w_parameter, reserv_wage; repeat = 1000)\n    stop_time = zeros(Int, repeat)\n    (;w, P) = w_parameter\n    for i in 1:repeat\n        t = 0 #initialization   \n        \n        while true\n            wage = draw_wage(w, P)\n\n            if wage &lt; reserv_wage\n                t = t + 1\n            else \n                stop_time[i] = t\n                break\n            end\n        end\n    end\n    \n    return mean(stop_time)\nend\n\nfunction draw_wage(w, P)\n    # typical way of how to draw a random number from arbirtrary distribution\n    x = rand() #random number from 0 to 1\n    temp = 0.0\n    wage = zero(eltype(w))\n    for i in eachindex(P)\n        if x &gt; temp\n            temp = temp + P[i]\n        else\n            wage = w[i]\n            break\n        end\n    end\n    return wage\nend\n\ndraw_wage (generic function with 1 method)\n\n\n\nstopping_time(w_parameter, w1)\n\n1.359\n\n\n\nstopping_time(w_parameter, w2)\n\n2.512\n\n\nHolding the distribution constant, higher reservation wage implies longer waits.\n\n\n3.6 continuous distribution (follows from Quantecon)\nNow let’s add some continuous distributional assumptions for the wage offer. Check out how to work with the “Distributions” package in the first problem set.\nWith no particular reason, let the wage offer follow a Log-normal distribution with unit shape and unit scale.\nLet’s take a look at how the distribution looks like.\n\nwdist_con = LogNormal() \n\nplot(0:0.1:10, pdf.(wdist_con, 0:0.1:10), xlabel = \"wages\", ylabel = \"probabilities\", legend = false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwdist_con\n\nLogNormal{Float64}(μ=0.0, σ=1.0)\n\n\n\n\nChallenge: need to compute the numerical expectation\nTo solve the household problem, we need to solve for the constant \\(b + \\beta \\int_0^B V(w')dF(w')\\). However, we can’t analytically solve for \\(b + \\beta \\int_0^B V(w')dF(w')\\) as we only have a numerical approximation of \\(V(.)\\). Moreover, the computer can’t deal with continuous grids. In particular, \\(V(.)\\) has to be defined on discrete grids, so we have to numerically approximate the integral \\(\\int_0^B V(w')dF(w')\\).\nWe can use the Expectations package, which automatically finds the best algorithm to compute numerical expectations (usually Gaussian Quadrature).\n\n# struct of parameters\nBase.@kwdef struct worker_continuous \n    β :: Float64 = 0.7\n    b :: Float64 = 5 * 10^7 # unemployment benefit\n    N :: Int64 = 100\n\n    wdist_continuous :: Sampleable = LogNormal(0.0, 1.0) # root type for distributions\n    \nend\n\nw_continuous = worker_continuous()\n\nworker_continuous(0.7, 5.0e7, 100, LogNormal{Float64}(μ=0.0, σ=1.0))\n\n\n\nfunction Mccall_continuous(w_continuous; N = 100, tol = 1e-6 ,  v = zeros(N))\n     # unpacking \n    (; β, b, wdist_continuous) = w_continuous\n    \n    v1 = similar(v)\n    E = expectation(wdist_continuous; n = w_continuous.N ) # expectation operator\n    w = nodes(E) \n\n    iterate = 0\n\n    while true  \n        distance = zero(eltype(v))\n        \n        v1 = max.(w/(1 - β), b + β * E * v)\n\n        distance = maximum(abs.(v1 - v))\n        \n        (distance &lt; tol || iterate == 1000) && break # break out of the whole loop if one of the statements is true\n        iterate += 1\n\n        # Vectorized update of v using element-wise assignment\n        v .= v1\n    end\n    return (v = v, w=w, iterate = iterate)\nend\n\n\nMccall_continuous (generic function with 1 method)\n\n\n\nv, w, = Mccall_continuous(w_continuous)\n\n(v = [1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8  …  1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 1.666666666666639e8, 2.5064905493460503e8, 5.714051277395748e8], w = [5.833572664144068e-9, 1.3298806708858358e-8, 2.6250326658469462e-8, 4.807794944383888e-8, 8.38914683026871e-8, 1.4137052800433642e-7, 2.3195935788611737e-7, 3.725719800588602e-7, 5.880207840756581e-7, 9.144625593480436e-7  …  1.093538483098684e6, 1.7006201601733423e6, 2.6840451067791427e6, 4.311100052669397e6, 7.073610137250996e6, 1.1920163280393668e7, 2.079955596209706e7, 3.809476403895941e7, 7.519471648038152e7, 1.7142153832187247e8], iterate = 89)\n\n\n\nv1 = 1/(1 - w_continuous.β) .* w\nv2 = similar(w)\nplot(w, v1, line = (:red, 1), label = L\"\\frac{w}{1 - β}\")\nplot!(w, ones(w_continuous.N).*v[1], line = (:green, 1), label = L\"\\bar{V}\")\nplot!(w, v .+ 0.1, line = (:blue, 2.5), label = L\"V(w)\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot very accurate due to the setting of grids.\n\n\n3.7 Conclusion\nIn this lecture, we computed the most basic Mccall job search model. We also discussed some of the model’s properties with numerical results. Further readings for this topic on Quantecon Lecture 28 - 33 are highly recommended."
  },
  {
    "objectID": "Julia/Lectures/Julia_Lec_2_Compecon_Xing_Xu.html",
    "href": "Julia/Lectures/Julia_Lec_2_Compecon_Xing_Xu.html",
    "title": "Lecture 2: A canonical Neo-classical growth model and introduction to value function iteration (VFI)",
    "section": "",
    "text": "Xing Xu, University of Minnesota, 2023 Summer"
  },
  {
    "objectID": "Julia/Lectures/Julia_Lec_2_Compecon_Xing_Xu.html#conclusion",
    "href": "Julia/Lectures/Julia_Lec_2_Compecon_Xing_Xu.html#conclusion",
    "title": "Lecture 2: A canonical Neo-classical growth model and introduction to value function iteration (VFI)",
    "section": "2.5 Conclusion",
    "text": "2.5 Conclusion\nWe have gone carefully through solving a very standard problem in Macroeconomics. The goal is to showcase how to perform basic value function iteration in Julia. We mainly talked through how to code the problem in loop version and vector version. Along the way, I showed some important features of Julia coding. Most importantly, loops, functions, struct, broadcasting and vector/matrix operations.\nAt last, we compared the performance of coding with loops and vectorizations. It might occur to you that loop version has better performance. Please keep in mind this varies in different problems and it is useful to know both methodologies."
  },
  {
    "objectID": "Julia/Assignments/Julia_PS_2_Compecon_Xing_Xu.html",
    "href": "Julia/Assignments/Julia_PS_2_Compecon_Xing_Xu.html",
    "title": "Question 2.1: Adding labor supply to the model.",
    "section": "",
    "text": "One natural extension to the problem is to add preferences for leisure to characterize labor supply changes.\nDenote the labor supply as \\(l_t\\). For simplicity, let household has 1 unit of labor endowment each period. Leisure can thus be denoted as \\(1 - l_t\\). Now, consider the following problem:\n\\[\\begin{align*}\n    V(k_0) \\equiv \\max_{\\{c_t, l_t, k_{t+1}\\}_{t=0}^\\infty} &\\sum_{t=0}^\\infty \\beta^t u(c_t, 1 - l_t) \\\\\n    \\text{subject to } c_t + k_{t+1} &\\leq F(k_t, l_t) + (1 - \\delta) k_t, \\forall t\\\\\n    c_t, k_{t+1} \\geq 0,& l_t \\in [0,1], \\forall t \\\\\n       \\quad k_0 &\\text{ given }\n\\end{align*}\\]\nLet the utility be denoted as:\nExercise: Find the Euler equation as before. What changed? In addition, use the FOCs from \\(c_t\\) and \\(l_t\\) to characterize the intratemporal substitution between consumption and leisure. Make some economic justifications for the results.\nThe recursive formulation of the problem is:\n\\[\\begin{align*}\n    V(k) = & \\max_{c,l, k'} \\{u(c, 1 - l) + \\beta V(k') \\}\\\\\n    \\text{subject to } & c + k' \\leq F(k, l) + (1 - \\delta) k\\\\\n    & c , k' \\geq 0, l \\in [0, 1]\n\\end{align*}\\]\nAgain, we can substitute in \\(c\\) and write the problem as the following,\n\\[\nV(k) =  \\max_{l, k' \\in \\Gamma(k)} \\{u(F(k, l) + (1 - \\delta) k - k', 1 - l) + \\beta V(k')\\}\n\\] where \\(\\Gamma(k) \\equiv \\{k', l | l \\in [0,1], k' \\in [0, F(k, l) + (1 - \\delta) k]\\}\\)\n\nSolving the problem\nLet’s specify some parameter values as before. Again we take use of struct.\n\nBase.@kwdef struct Household_labor # or simply @kwdef\n    σ :: Float64 = 2.0\n    β :: Float64 = 0.9\n    A :: Float64 = 2.0\n    α :: Float64 = 0.7\n    δ :: Float64 = 0.9\n    γ :: Float64 = 0.3 # additional parameter for the utility weight between consumption and leisure\nend\n\nh_l = Household() \n\nHousehold(2.0, 0.9, 2.0, 0.7, 0.9)\n\n\nIn addition, we need to specify the utility function and the production function. We use a separable CRRA utility for consumption and leisure. Production function is the same.\n\nu2(c,l, m) = γ * c^(1.0 - m.σ)/(1.0 - m.σ) + (1.0 - γ) * (1.0 - l)^(1.0 - m.σ)/(1.0 - m.σ)\nF2(k,l, m) = m.A * k^m.α * l^(1.0 - m.α)\n\nF2 (generic function with 1 method)\n\n\nLet’s build towards solving the model. First, note that the maximum sustainable capital is the same as before. Again, \\(F(\\tilde{k}, 1) = \\delta \\tilde{k}\\), which is \\(A \\tilde{k}^\\alpha = \\delta \\tilde{k}\\). Since \\(\\delta &gt; 0\\), \\(\\tilde{k} = (\\frac{A}{\\delta})^{\\frac{1}{1 - \\alpha}}\\). Intuitively, this is because that if we let consumption be \\(0\\) and use all labor endowment for production. The maximum sustainable level for capital in the long term will be when \\(F(\\tilde{k}, 1) = \\delta \\tilde{k}\\).\nEverything else basically follows, except that we also need to find optimal labor supply (or leisure). There are two ways to do this. You will write the codes for VFI with the algorithms provided below. Try to write all codes by yourself and check with the basic model without labor supply decisions in the lecture.\nThe brute force way of solving this starts with constructing an additional grid for labor and search over maximized value with different combinations of \\(k'\\) and \\(l\\). Since \\(l \\in [0,1]\\), we can initialize \\(l\\) with range(0.0, 1.0, 10) (10 grids for simplicity).\nThe algorithm is very similar to that in the lecture. We need an additional loop over possible values of \\(l\\). You will also need two policy functions, pol_kprime for storing optimal policy index for \\(k'\\) and \\(pol_l\\) for \\(l\\). For each combination of \\(k'\\) and \\(l\\), compute \\(c\\) and check whether it is non-negative.\nExercise: Write the function for performing VFI for the new model. Write the loop version first. After that, plot the value function and the policy function for \\(k'\\) and \\(l\\) given each \\(k\\).\nThink: does the trick with strictly increasing policy function we used in the lecture still apply here? If so how can we implement it?\nExercise: Vectorize your code as in the lecture. (partially first and try full vectorization if you are confident) Check with the result from the loop version."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Python/Lectures/New/lecture1.html",
    "href": "Python/Lectures/New/lecture1.html",
    "title": "Lesson 1",
    "section": "",
    "text": "Self-introductions\nConda\n\n\nEnvironments\n\n\nImporting packages\nVariables\n\n\nAssignment (using =)\nNaming\nTypes (str, int, float, bool, lists/tuples/sets, dicts)\nFor ints/floats: operations\nLists/tuples/sets and dicts\n\nFor lists/tuples: subsets, len(), sum(), max(), min(), etc.\n\nFor strings: subsets, addition, and f-strings\n\n\nIf statements\n\n\nComparisons\nand and or\nIndentation\n\n\nLoops\n\n\nIndentation\nFor loops\nWhile loops\nBreaks\nContinue\n\n\nFunctions\n\n\nSyntax\nIndentation\nArguments\nReturns\nComments\n\nDocstrings\n\n\n\nPrinting text"
  },
  {
    "objectID": "Python/Lectures/New/lecture1.html#overview",
    "href": "Python/Lectures/New/lecture1.html#overview",
    "title": "Lesson 1",
    "section": "",
    "text": "Self-introductions\nConda\n\n\nEnvironments\n\n\nImporting packages\nVariables\n\n\nAssignment (using =)\nNaming\nTypes (str, int, float, bool, lists/tuples/sets, dicts)\nFor ints/floats: operations\nLists/tuples/sets and dicts\n\nFor lists/tuples: subsets, len(), sum(), max(), min(), etc.\n\nFor strings: subsets, addition, and f-strings\n\n\nIf statements\n\n\nComparisons\nand and or\nIndentation\n\n\nLoops\n\n\nIndentation\nFor loops\nWhile loops\nBreaks\nContinue\n\n\nFunctions\n\n\nSyntax\nIndentation\nArguments\nReturns\nComments\n\nDocstrings\n\n\n\nPrinting text"
  },
  {
    "objectID": "Python/Lectures/New/lecture1.html#self-introductions",
    "href": "Python/Lectures/New/lecture1.html#self-introductions",
    "title": "Lesson 1",
    "section": "1. Self-introductions",
    "text": "1. Self-introductions"
  },
  {
    "objectID": "Python/Lectures/New/lecture1.html#conda",
    "href": "Python/Lectures/New/lecture1.html#conda",
    "title": "Lesson 1",
    "section": "2. Conda",
    "text": "2. Conda\nDoes lots of things, we’re using it for package management\nPackages are how people share their code with others\n\n2.1 Environments\nAllows you to keep packages organized - see here\n\nTo create: conda create --name pycourse (you can replace pycourse with any custom name)\nTo activate: conda activate pycourse\nTo install pip: conda install pip\nTo install package: pip install packagename (replace packagename with the name of the package you want to install)\n\nFor this lesson, please install: jupyterlab and/or notebook to be able to open Jupyter Notebooks (like this) (see here for more information)"
  },
  {
    "objectID": "Python/Lectures/New/lecture1.html#importing-packages",
    "href": "Python/Lectures/New/lecture1.html#importing-packages",
    "title": "Lesson 1",
    "section": "3. Importing packages",
    "text": "3. Importing packages\nType import packagename\n\nimport random\n\n\nprint(random.random())"
  },
  {
    "objectID": "Python/Lectures/New/lecture1.html#variables",
    "href": "Python/Lectures/New/lecture1.html#variables",
    "title": "Lesson 1",
    "section": "4. Variables",
    "text": "4. Variables\nWhy - you need to keep track of what’s what\n\n4.1 Assignment\nAssign a value to a name using = (this is not equivalent to mathematical equality, check that using ==)\n\nx = 10\nprint(x)\n\n\n\n4.2 Naming\nChoose names carefully\n\nx = 10\ndistance = 10\n\n\n\n4.3 Types\nstr, int, float, bool, lists/tuples/sets, dicts\n\ncourse_name_v1 = 'Python Course, Summer 2024'\ncourse_name_v2 = \"Python Course, Summer 2024\"\ncourse_name_v3 = \\\n'''\nPython Course, Summer 2024\n'''\ncourse_year = 2024\nlecture_1_frac_complete = 1/5 # Or 0.2\nlecture_1_complete = False # Or True\nlectures = [1, 2, 3, 4, 5, 6, 7, 8]\nlecture_v2 = (1, 2, 3, 4, 5, 6, 7, 8)\nlectures_v3 = {1, 2, 3, 4, 5, 6, 7, 8, 8}\nlectures_occurred = {1: 'True', 2: 'False', 3: 'False', 4: 'False', 5: 'False', 6: 'False', 7: 'False', 8: 'False'}\n\n\n\n4.4 For ints/floats: operations\n\nAddition: +\nSubtraction: -\nMultiplication: *\nDivision: /\nExponentiation: **\nIn-place: +=, -=, *=, /=, **=\n\n\na = 5\nb = 2\n\n\nprint(a + b)\n\n\na += b\nprint(a)\n\n\na = 5\na *= b\nprint(a)\n\n\na = 5\na **= b\nprint(a)\n\n\n\n4.5 Lists/tuples/sets and dicts\nLists are mutable (they can be changed) - Access an element using list[index] (indexing starts at 0)\nTuples are immutable (they cannot be changed) - Access an element using tuple[index] (indexing starts at 0)\nSets don’t have an order\nDicts work like a dictionary (a term called a ‘key’ will be linked to an associated variable called a ‘value’) - Access a value using dict[key]\n\nprint(lectures)\nlectures[0] = 0\nprint(lectures)\n\n\nprint(lecture_v2)\nlecture_v2[0] = 0\n\n\nprint(lectures_v3)\nlectures_v3[0] = 0\n\n\nprint(lectures_occurred)\nlectures_occurred[0] = False\nprint(lectures_occurred)\nlectures_occurred['word'] = 'definition'\nprint(lectures_occurred)\n\n\n\n4.5.1 For lists/tuples: subsets, len(), sum(), max(), min(), etc.\nAccess a subset of a list/tuple using list[a: b]/tuple[a: b], which gives you the elements starting and index a and ending at index b-1 (remember that indexing starts at 0)\n\nprint(lectures)\nprint('Subset of list:', lectures[2: 4])\nprint('Last element of list:', lectures[-1])\nprint('Length of list:', len(lectures))\nprint('Max of tuple:', max(lecture_v2))\nprint('Min of tuple:', min(lecture_v2))\n\n\n\n4.6 For strings: subsets, addition, and f-strings\nAccess substrings as if the string is a list\n\na = 'hello'\na[3: 5]\n\n\na[0]\n\n\na[2:]\n\n\na[-3:]\n\nStrings can be combined using +\n\na = 'hello'\nb = 'goodbye'\na + b\n\nVariables can easily be put into strings using f-strings\n\na = 5\nb = 6\nf'a is {a} and b is {b}'"
  },
  {
    "objectID": "Python/Lectures/New/lecture1.html#if-statements",
    "href": "Python/Lectures/New/lecture1.html#if-statements",
    "title": "Lesson 1",
    "section": "5. If statements",
    "text": "5. If statements\nIf you want a task to occur under certain conditions\n\n5.1 Comparisons\n\n== for equality\n!= for inequality\n&gt; or &lt; for strict inequality\n&gt;= or &lt;= for weak inequality\nin for list membership\nis for variable reference ids and None\n\n\nx\n\n\nif x == 8:\n    print('x is 8')\nelif x == 9:\n    print('x is 9')\nelse:\n    print('x is neither 8 nor 9')\n\nIf a variable is already a boolean, it can directly be used as a comparison - conciseness is preferred\n\na = 5\nx = (a == 5)\nif x: # Preferred\n    print('x is True since a is 5')\nelse:\n    print('x is False since a is not 5')\nif x == True: # Works, but not preferred\n    print('x is True since a is 5')\nelse:\n    print('x is False since a is not 5')\n\n\n\n5.2 and and or\nCombine statements with and and or\n\nif (x &gt;= 0) and (x &lt; 20):\n    print('x is in [0, 20)')\n\n\nif 0 &lt;= x &lt; 20:\n    print('x is in [0, 20)')\n\n\n\n5.3 Indentation\nMake sure the code inside the if statement is properly indented (4 spaces)\nNested if statements should also have nested indentation"
  },
  {
    "objectID": "Python/Lectures/New/lecture1.html#loops",
    "href": "Python/Lectures/New/lecture1.html#loops",
    "title": "Lesson 1",
    "section": "6. Loops",
    "text": "6. Loops\nIf you want to repeat a task\n\n6.1 Indentation\nMake sure the code inside the loop is properly indented (4 spaces)\nNested loops should also have nested indentation\n\n\n6.2 For loops\nIterate through the elements of a list/tuple/etc\n\n# List/tuple\nfor lecture in lectures:\n    print('Lecture:', lecture)\n\n\nlectures_occurred.items()\n\n\n# Dict\nfor lecture, lecture_occurred in lectures_occurred.items():\n    print(f'Lecture {lecture} occurred: {lecture_occurred}')\n\n\nlen(lectures)\n\n\n# Range\nfor i in range(len(lectures)):\n    print(f'Loop {i}, lecture {lectures[i]}')\n\n\n# Enumerate\nfor i, lecture in enumerate(lectures):\n    print(f'Loop {i}, lecture {lecture}')\n\n\n\n6.3 While loops\nIterate as long as some condition holds\n\ni = 0\nwhile i &lt; 10:\n    print(i)\n    i += 1\n\n\n\n6.4 Breaks\nAn alternative way to get out of loops\n\ni = 0\nwhile True:\n    print(i)\n    i += 1\n    if i &gt;= 10:\n        break\n\n\n\n6.5 Continue\nIf you want an if statement for clarity, but you don’t want it to do anything\n\nfor i, lecture in enumerate(lectures):\n    print(i)\n    if lecture == 3:\n        continue\n    else:\n        print('This is not lecture 3')\n\n\nfor i, lecture in enumerate(lectures):\n    print(i)\n    if lecture == 3:\n    else:\n        print('This is not lecture 3')"
  },
  {
    "objectID": "Python/Lectures/New/lecture1.html#functions",
    "href": "Python/Lectures/New/lecture1.html#functions",
    "title": "Lesson 1",
    "section": "7. Functions",
    "text": "7. Functions\nA simple way to repeat a task\n\n7.1 Syntax\nMake sure to write def before the function name, put the function arguments inside parantheses, and make sure the parentheses are followed by a semicolon\n\n\n7.2 Indentation\nMake sure the code inside the function is properly indented (4 spaces)\nNested functions should also have nested indentation\n\n\n7.3 Arguments\nThe input the function requires to run (equivalent to the arguments of a mathematical function)\n\n\n7.4 Returns\nWhat the function produces after it runs\n\n\n7.5 Comments\nExplain what you code is doing (put # before a single-line comment, or wrap a multi-line comment in triple quotes ''')\n\n7.5.1 Docstrings\nDetail at the top of the function what it does, what the arguments are, and what it returns\n\ndef square_x(x):\n    '''\n    Return the square of x.\n    \n    Arguments:\n        x (float): value to square\n        \n    Returns:\n        (float): square of x\n    '''\n    return x ** 2\n\ndef list_mean(lst):\n    '''\n    Return the mean of a list of numbers.\n    \n    Arguments:\n        lst (list): list to compute the mean of\n        \n    Returns:\n        (float): mean value of lst\n    '''\n    lst_sum = 0\n    lst_len = 0\n    for val in lst:\n        # Add values to sum\n        lst_sum += val\n        # Update length of list\n        lst_len += 1\n    # Compute mean value in lst\n    return lst_sum / lst_len\n\ndef list_mean_v2(lst):\n    '''\n    Return the mean of a list of numbers.\n    \n    Arguments:\n        lst (list): list to compute the mean of\n        \n    Returns:\n        (float): mean value of lst\n    '''\n    return sum(lst) / len(lst)\n\n# Two arguments, plus using functions inside other functions\ndef list_mean_v3(lst1, lst2):\n    '''\n    Return the mean of the means of two lists of numbers.\n    \n    Arguments:\n        lst1 (list): list 1 to compute the mean of\n        lst2 (list): list 2 to compute the mean of\n\n    Returns:\n        (float): mean value of mean values of lst1 and lst2\n    '''\n    return (list_mean_v2(lst1) + list_mean_v2(lst2)) / 2\n\n\nsquare_x(10)\n\n\nlist_mean([2, 7, 10])\n\n\nlist_mean_v2([2, 7, 10])\n\n\nlist_mean_v3([2, 7, 10], [5, 12, 1])"
  },
  {
    "objectID": "Python/Lectures/New/lecture1.html#printing-text",
    "href": "Python/Lectures/New/lecture1.html#printing-text",
    "title": "Lesson 1",
    "section": "8. Printing text",
    "text": "8. Printing text\nUseful for debugging\nLook throughout for examples, but primarily use f-strings:\n\nprint(f'This is an f statement, so we can print variables like lists: {lectures} or dicts: {lectures_occurred} easily')\n\nFor simple cases, use commas (this is not as clean for complicated examples):\n\nprint('Lectures:', lectures)"
  },
  {
    "objectID": "Python/Lectures/Old/lecture1.html",
    "href": "Python/Lectures/Old/lecture1.html",
    "title": "Lesson 1",
    "section": "",
    "text": "Conda\n\nEnvironments\n\nImporting Packages\nVariables\n\nAssignment (using =)\n\n\nNaming\n\n\nTypes (str, int, float, bool, lists/tuples/sets, dicts)\n\n\nLists/tuples/sets and dicts\n\n\n\nFor lists/tuples: subsets, len(), sum(), max(), min(), etc.\n\n\nIf statements\n\nComparisons\n\n\nand and or\n\n\nIndentation\n\nLoops\n\nIndentation\n\n\nFor loops\n\n\nWhile loops\n\n\nBreaks\n\n\nContinue\n\nFunctions\n\nIndentation\n\n\nArguments\n\n\nReturns\n\n\nComments\n\n\n\nDocstrings\n\n\nPrinting text"
  },
  {
    "objectID": "Python/Lectures/Old/lecture1.html#overview",
    "href": "Python/Lectures/Old/lecture1.html#overview",
    "title": "Lesson 1",
    "section": "",
    "text": "Conda\n\nEnvironments\n\nImporting Packages\nVariables\n\nAssignment (using =)\n\n\nNaming\n\n\nTypes (str, int, float, bool, lists/tuples/sets, dicts)\n\n\nLists/tuples/sets and dicts\n\n\n\nFor lists/tuples: subsets, len(), sum(), max(), min(), etc.\n\n\nIf statements\n\nComparisons\n\n\nand and or\n\n\nIndentation\n\nLoops\n\nIndentation\n\n\nFor loops\n\n\nWhile loops\n\n\nBreaks\n\n\nContinue\n\nFunctions\n\nIndentation\n\n\nArguments\n\n\nReturns\n\n\nComments\n\n\n\nDocstrings\n\n\nPrinting text"
  },
  {
    "objectID": "Python/Lectures/Old/lecture1.html#conda",
    "href": "Python/Lectures/Old/lecture1.html#conda",
    "title": "Lesson 1",
    "section": "Conda",
    "text": "Conda\nDoes lots of things, we’re using it for package management\n\nEnvironments\nAllows you to keep packages organized - see here\n\nTo create: conda create --name pycourse (you can replace pycourse with any custom name)\nTo activate: conda activate pycourse\nTo install pip: conda install pip\nTo install package: pip install packagename (replace packagename with the name of the package you want to install)\n\nFor this lesson, please install: jupyterlab and/or notebook to be able to open Jupyter Notebooks (like this) (see here for more information)"
  },
  {
    "objectID": "Python/Lectures/Old/lecture1.html#importing-packages",
    "href": "Python/Lectures/Old/lecture1.html#importing-packages",
    "title": "Lesson 1",
    "section": "Importing Packages",
    "text": "Importing Packages\nType import packagename\n\nimport random\n\n\nprint(random.random())\n\n0.7773242780744012"
  },
  {
    "objectID": "Python/Lectures/Old/lecture1.html#variables",
    "href": "Python/Lectures/Old/lecture1.html#variables",
    "title": "Lesson 1",
    "section": "Variables",
    "text": "Variables\nWhy - you need to keep track of what’s what\n\nAssignment\nAssign a value to a name using = (this is not equivalent to mathematical equality, check that using ==)\n\nx = 10\nprint(x)\n\n10\n\n\n\n\nNaming\nChoose names carefully\n\nx = 10\ndistance = 10\n\n\n\nTypes\nstr, int, float, bool, lists/tuples/sets, dicts\n\ncourse_name_v1 = 'Python Course, Summer 2023'\ncourse_name_v2 = \"Python Course, Summer 2023\"\ncourse_year = 2023\nlecture_1_frac_complete = 1/5\nlecture_1_complete = False\nlectures = [1, 2, 3, 4, 5, 6, 7, 8]\nlecture_v2 = (1, 2, 3, 4, 5, 6, 7, 8)\nlectures_v3 = {1, 2, 3, 4, 5, 6, 7, 8, 8}\nlectures_occurred = {1: 'True', 2: 'False', 3: 'False', 4: 'False', 5: 'False', 6: 'False', 7: 'False', 8: 'False'}\n\n\n\nLists/tuples/sets and dicts\nLists are mutable (they can be changed) - Access an element using list[index] (indexing starts at 0)\nTuples are immutable (they cannot be changed) - Access an element using tuple[index] (indexing starts at 0)\nSets don’t have an order\nDicts work like a dictionary (a term called a ‘key’ will be linked to an associated variable called a ‘value’) - Access a value using dict[key]\n\nprint(lectures)\nlectures[0] = 0\nprint(lectures)\n\n[1, 2, 3, 4, 5, 6, 7, 8]\n[0, 2, 3, 4, 5, 6, 7, 8]\n\n\n\nprint(lecture_v2)\nlecture_v2[0] = 0\n\n(1, 2, 3, 4, 5, 6, 7, 8)\n\n\nTypeError: 'tuple' object does not support item assignment\n\n\n\nprint(lectures_v3)\nlectures_v3[0] = 0\n\n{1, 2, 3, 4, 5, 6, 7, 8}\n\n\nTypeError: 'set' object does not support item assignment\n\n\n\nlectures_occurred = {1: 'True', 2: 'False', 3: 'False', 4: 'False', 5: 'False', 6: 'False', 7: 'False', 8: 'False'}\nprint(lectures_occurred)\nlectures_occurred[0] = False\nprint(lectures_occurred)\nlectures_occurred['word'] = 'definition'\nprint(lectures_occurred)\n\n{1: 'True', 2: 'False', 3: 'False', 4: 'False', 5: 'False', 6: 'False', 7: 'False', 8: 'False'}\n{1: 'True', 2: 'False', 3: 'False', 4: 'False', 5: 'False', 6: 'False', 7: 'False', 8: 'False', 0: False}\n{1: 'True', 2: 'False', 3: 'False', 4: 'False', 5: 'False', 6: 'False', 7: 'False', 8: 'False', 0: False, 'word': 'definition'}\n\n\n\n\nFor lists/tuples: subsets, len(), sum(), max(), min(), etc.\nAccess a subset of a list/tuple using list[a: b]/tuple[a: b], which gives you the elements starting and index a and ending at index b-1 (remember that indexing starts at 0)\n\nlectures\n\n[0, 2, 3, 4, 5, 6, 7, 8]\n\n\n\nprint('Subset of list:', lectures[2: 4])\nprint('Length of list:', len(lectures))\nprint('Max of tuple:', max(lecture_v2))\nprint('Min of tuple:', min(lecture_v2))\n\nSubset of list: [3, 4]\nLength of list: 8\nMax of tuple: 8\nMin of tuple: 1"
  },
  {
    "objectID": "Python/Lectures/Old/lecture1.html#if-statements",
    "href": "Python/Lectures/Old/lecture1.html#if-statements",
    "title": "Lesson 1",
    "section": "If statements",
    "text": "If statements\nIf you want a task to occur under certain conditions\n\nComparisons\n\n== for equality\n!= for inequality\n&gt; or &lt; for strict inequality\n&gt;= or &lt;= for weak inequality\nin for list membership\n\n\nx != 10\n\nFalse\n\n\n\nif x == 8:\n    print('x is 8')\nelif x == 9:\n    print('x is 9')\nelse:\n    print('x is neither 8 nor 9')\n\nx is neither 8 nor 9\n\n\n\n\nand and or\nCombine statements with and and or\n\nif (x &gt;= 0) and (x &lt; 20):\n    print('x is in [0, 20)')\n\nx is in [0, 20)\n\n\n\nif 0 &lt;= x &lt; 20:\n    print('x is in [0, 20)')\n\nx is in [0, 20)\n\n\n\n\nIndentation\nMake sure the code inside the if statement is properly indented (4 spaces)"
  },
  {
    "objectID": "Python/Lectures/Old/lecture1.html#loops",
    "href": "Python/Lectures/Old/lecture1.html#loops",
    "title": "Lesson 1",
    "section": "Loops",
    "text": "Loops\nIf you want to repeat a task\n\nIndentation\nMake sure the code inside the loop is properly indented (4 spaces)\n\n\nFor loops\nIterate through the elements of a list/tuple/etc\n\n# List/tuple\nfor lecture in lectures:\n    print('Lecture:', lecture)\n\nLecture: 0\nLecture: 2\nLecture: 3\nLecture: 4\nLecture: 5\nLecture: 6\nLecture: 7\nLecture: 8\n\n\n\nlectures_occurred.items()\n\ndict_items([(1, 'True'), (2, 'False'), (3, 'False'), (4, 'False'), (5, 'False'), (6, 'False'), (7, 'False'), (8, 'False'), (0, False), ('word', 'definition')])\n\n\n\n# Dict\nfor lecture, lecture_occurred in lectures_occurred.items():\n    print(f'Lecture {lecture} occurred: {lecture_occurred}')\n\nLecture 1 occurred: True\nLecture 2 occurred: False\nLecture 3 occurred: False\nLecture 4 occurred: False\nLecture 5 occurred: False\nLecture 6 occurred: False\nLecture 7 occurred: False\nLecture 8 occurred: False\nLecture 0 occurred: False\nLecture word occurred: definition\n\n\n\nlen(lectures)\n\n8\n\n\n\n# Range\nfor i in range(len(lectures)):\n    print(f'Loop {i}, lecture {lectures[i]}')\n\nLoop 0, lecture 0\nLoop 1, lecture 2\nLoop 2, lecture 3\nLoop 3, lecture 4\nLoop 4, lecture 5\nLoop 5, lecture 6\nLoop 6, lecture 7\nLoop 7, lecture 8\n\n\n\n# Enumerate\nfor i, lecture in enumerate(lectures):\n    print(f'Loop {i}, lecture {lecture}')\n\nLoop 0, lecture 0\nLoop 1, lecture 2\nLoop 2, lecture 3\nLoop 3, lecture 4\nLoop 4, lecture 5\nLoop 5, lecture 6\nLoop 6, lecture 7\nLoop 7, lecture 8\n\n\n\n\nWhile loops\nIterate as long as some condition holds\n\ni = 0\nwhile i &lt; 10:\n    print(i)\n    i += 1\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\nBreaks\nAn alternative way to get out of loops\n\ni = 0\nwhile True:\n    print(i)\n    i += 1\n    if i &gt;= 10:\n        break\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\nContinue\nIf you want an if statement for clarity, but you don’t want it to do anything\n\nfor i, lecture in enumerate(lectures):\n    print(i)\n    if lecture == 3:\n        continue\n    else:\n        print('This is not lecture 3')\n\n0\nThis is not lecture 3\n1\nThis is not lecture 3\n2\n3\nThis is not lecture 3\n4\nThis is not lecture 3\n5\nThis is not lecture 3\n6\nThis is not lecture 3\n7\nThis is not lecture 3"
  },
  {
    "objectID": "Python/Lectures/Old/lecture1.html#functions",
    "href": "Python/Lectures/Old/lecture1.html#functions",
    "title": "Lesson 1",
    "section": "Functions",
    "text": "Functions\nA simple way to repeat a task\n\nIndentation\nMake sure the code inside the function is properly indented (4 spaces)\n\n\nArguments\nThe input the function requires to run (equivalent to the arguments of a mathematical function)\n\n\nReturns\nWhat the function produces after it runs\n\n\nComments\nExplain what you code is doing (put # before a single-line comment, or wrap a multi-line comment in triple quotes ''')\n\nDocstrings\nDetail at the top of the function what it does, what the arguments are, and what it returns\n\ndef square_x(x):\n    '''\n    Return the square of x.\n    \n    Arguments:\n        x (float): value to square\n        \n    Returns:\n        (float): square of x\n    '''\n    return x ** 2\n\ndef list_mean(lst):\n    '''\n    Return the mean of a list of numbers.\n    \n    Arguments:\n        lst (list): list to compute the mean of\n        \n    Returns:\n        (float): mean value of lst\n    '''\n    lst_sum = 0\n    lst_len = 0\n    for val in lst:\n        # Add values to sum\n        lst_sum += val\n        # Update length of list\n        lst_len += 1\n    # Compute mean value in lst\n    return lst_sum / lst_len\n\ndef list_mean_v2(lst):\n    '''\n    Return the mean of a list of numbers.\n    \n    Arguments:\n        lst (list): list to compute the mean of\n        \n    Returns:\n        (float): mean value of lst\n    '''\n    return sum(lst) / len(lst)\n\ndef list_mean_v3(lst1, lst2):\n    '''\n    Return the mean of the means of two lists of numbers.\n    \n    Arguments:\n        lst1 (list): list 1 to compute the mean of\n        lst2 (list): list 2 to compute the mean of\n\n    Returns:\n        (float): mean value of mean values of lst1 and lst2\n    '''\n    return (list_mean_v2(lst1) + list_mean_v2(lst2)) / 2\n\n\nsquare_x(10)\n\n100\n\n\n\nlist_mean([2, 7, 10])\n\n6.333333333333333\n\n\n\nlist_mean_v2([2, 7, 10])\n\n6.333333333333333\n\n\n\nlist_mean_v3([2, 7, 10], [5, 12, 1])\n\n6.166666666666666"
  },
  {
    "objectID": "Python/Lectures/Old/lecture1.html#printing-text",
    "href": "Python/Lectures/Old/lecture1.html#printing-text",
    "title": "Lesson 1",
    "section": "Printing text",
    "text": "Printing text\nLook throughout for examples, but primarily use f:\n\nprint(f'This is an f statement, so we can print variables like lists: {lectures} or dicts: {lectures_occurred} easily')\n\nThis is an f statement, so we can print variables like lists: [0, 2, 3, 4, 5, 6, 7, 8] or dicts: {1: 'True', 2: 'False', 3: 'False', 4: 'False', 5: 'False', 6: 'False', 7: 'False', 8: 'False', 0: False, 'word': 'definition'} easily\n\n\nFor simple cases, use commas (this is not as clean for complicated examples):\n\nprint('Lectures:', lectures)\n\nLectures: [0, 2, 3, 4, 5, 6, 7, 8]"
  },
  {
    "objectID": "Python/Lectures/lecture5.html",
    "href": "Python/Lectures/lecture5.html",
    "title": "Lesson 5",
    "section": "",
    "text": "NumPy"
  },
  {
    "objectID": "Python/Lectures/lecture5.html#overview",
    "href": "Python/Lectures/lecture5.html#overview",
    "title": "Lesson 5",
    "section": "",
    "text": "NumPy"
  },
  {
    "objectID": "Python/Lectures/lecture5.html#numpy",
    "href": "Python/Lectures/lecture5.html#numpy",
    "title": "Lesson 5",
    "section": "NumPy",
    "text": "NumPy\nVectors/arrays/matrices in Python.\n\nimport numpy as np\n\n\na = [\n    [1, 2, 3],\n    [4, 5, 6],\n    [7, 8, 9]\n]\n\n\nb = np.array(a)\n\n\nb * b\n\narray([[ 1,  4],\n       [ 9, 16]])\n\n\n\nb @ b\n\narray([[ 7, 10],\n       [15, 22]])\n\n\n\nnp.linalg.inv(b) @ b\n\narray([[1.00000000e+00, 0.00000000e+00],\n       [2.22044605e-16, 1.00000000e+00]])\n\n\n\nzeros/ones\n\na = np.ones(100)\na\n\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n\n\n\na = np.zeros((5, 10))\na\n\narray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n\n\n\n\nAccessing elements/slicing/indexing\n\na[0][0]\n\n1\n\n\n\nb[0, 0]\n\n1\n\n\n\nidx = (0, 0)\nb[idx]\n\n1\n\n\n\na[idx]\n\nTypeError: list indices must be integers or slices, not tuple\n\n\n\na[:1]\n\n[[1, 2]]\n\n\n\nb\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\n\nb[:, [0, 2]][[0, 2], :]\n\narray([[1, 3],\n       [7, 9]])\n\n\n\na = rng.normal(size=1000)\nb = rng.integers(1000, size=50)\n\n\nb\n\narray([854,  55, 721, 913, 582, 439, 713, 117, 541, 820, 156, 623, 870,\n       966, 450, 282, 695, 531, 311, 678, 634, 645, 638, 191, 864, 611,\n       780,  71, 855, 821, 675,  97, 334, 291, 375, 484, 908, 241,  55,\n       878, 874, 752, 142,  44, 140, 563, 856, 566, 142, 274])\n\n\n\na[b]\n\narray([ 0.2689581 ,  1.41934817,  1.57621281,  1.139808  , -1.76639489,\n        0.81610715,  0.38888301,  1.71726308,  1.14546214,  0.8108156 ,\n       -0.67623437, -1.41618068, -0.60233814,  0.56134346, -0.35607535,\n       -0.98763303,  0.65829702,  1.63569133, -0.01772804,  0.19893244,\n       -1.54752077, -0.31806732,  0.14708579,  0.08111794, -0.6938663 ,\n        0.26720002,  0.03590914, -0.87805471,  2.37575881, -2.2908119 ,\n        0.88363284,  1.46243824, -0.17557353, -0.49139499, -0.69848635,\n       -0.47201708, -0.85016032, -0.0994117 ,  1.41934817, -0.02496758,\n        0.97252838,  0.26191014,  0.03688618, -0.58286632,  0.2434175 ,\n       -0.92525986, -1.0388805 , -1.73462436,  0.03688618,  0.5394642 ])\n\n\n\n\nTranspose\n\nnp.transpose(b, [1, 0])\n\narray([[1, 4, 7],\n       [2, 5, 8],\n       [3, 6, 9]])\n\n\n\n\nTile and repeat\n\nc = np.arange(3)\nc\n\narray([0, 1, 2])\n\n\n\nnp.tile(c, 3)\n\narray([0, 1, 2, 0, 1, 2, 0, 1, 2])\n\n\n\nnp.tile(c, (3, 2))\n\narray([[0, 1, 2, 0, 1, 2],\n       [0, 1, 2, 0, 1, 2],\n       [0, 1, 2, 0, 1, 2]])\n\n\n\nnp.repeat(c, 3)\n\narray([0, 0, 0, 1, 1, 1, 2, 2, 2])\n\n\n\nnp.repeat(c, (1, 2, 3))\n\narray([0, 1, 1, 2, 2, 2])\n\n\n\n\nBroadcasting\n\nc2 = np.tile(c, (3, 1))\nc2\n\narray([[0, 1, 2],\n       [0, 1, 2],\n       [0, 1, 2]])\n\n\n\nb\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\n\nc2 * b\n\narray([[ 0,  2,  6],\n       [ 0,  5, 12],\n       [ 0,  8, 18]])\n\n\n\nc[None, :] * b\n\narray([[ 0,  2,  6],\n       [ 0,  5, 12],\n       [ 0,  8, 18]])\n\n\n\nc2.T * b\n\narray([[ 0,  0,  0],\n       [ 4,  5,  6],\n       [14, 16, 18]])\n\n\n\nc[:, None] * b\n\narray([[ 0,  0,  0],\n       [ 4,  5,  6],\n       [14, 16, 18]])\n\n\n\nc\n\narray([0, 1, 2])\n\n\n\nc.shape\n\n(3,)\n\n\n\nc[:, None] + c[None, :]\n\narray([[0, 1, 2],\n       [1, 2, 3],\n       [2, 3, 4]])\n\n\n\n\ndiff\n\na = rng.normal(size=100000)\na\n\narray([-0.63772837, -0.26732566, -1.21791619, ...,  0.1078897 ,\n       -0.31508546,  1.53632125])\n\n\n\n%%timeit\na[1:] - a[: -1]\n\n26.7 µs ± 82.2 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n\n\n\n%%timeit\nnp.diff(a)\n\n28.7 µs ± 295 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n\n\n\n\ncumsum\n\na = np.arange(5)\na\n\narray([0, 1, 2, 3, 4])\n\n\n\nnp.cumsum(a)\n\narray([ 0,  1,  3,  6, 10])\n\n\n\n\nargmin/argmax/argsort\n\na = rng.normal(size=100)\n\n\na.argmax()\n\n75\n\n\n\nnp.argmax([2, 2, 1])\n\n0\n\n\n\na.argmin()\n\n27\n\n\n\na.argsort()\n\narray([27, 61,  9, 40, 43, 72, 25, 60, 54, 69, 14, 48, 51, 87,  1, 53, 16,\n       91, 58,  0, 88, 79, 84, 56,  4, 78, 80, 55, 98,  2, 66,  6, 86, 52,\n        8, 15, 95, 23, 81, 39, 92, 49, 85, 30, 45, 17, 34, 11, 83, 62, 93,\n       71, 82, 37, 68, 74, 47, 65, 21, 35, 24, 41, 50, 77, 29, 99, 26, 36,\n       19,  5, 67, 42, 63, 32, 31, 20, 73,  7, 59, 57, 64, 13, 22, 28, 96,\n       70, 10, 18, 46, 89, 38, 12, 33, 90, 76, 44,  3, 94, 97, 75])\n\n\n\n\nRandom generators\n\nrng = np.random.default_rng(1)\n\n\nrng.normal(size=10)\n\narray([ 0.34558419,  0.82161814,  0.33043708, -1.30315723,  0.90535587,\n        0.44637457, -0.53695324,  0.5811181 ,  0.3645724 ,  0.2941325 ])\n\n\n\n\nSparse matrices\n\nfrom scipy.sparse import csc_matrix\n\n\nn = 100\nn_ids = 10\nids = rng.integers(n_ids, size=n)\n\n\nJ = csc_matrix((np.ones(n), (np.arange(n), ids)), shape=(n, n_ids))\n\n\nJ.todense()\n\nmatrix([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n\n\n\n(J.T @ J).todense()\n\nmatrix([[ 6.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0., 10.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  8., ...,  0.,  0.,  0.],\n        ...,\n        [ 0.,  0.,  0., ...,  7.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0., 14.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0., 11.]])\n\n\n\n%%timeit\n(J.T @ J)\n\n702 ms ± 9.54 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n\nBincount\n\nnp.bincount(ids)\n\narray([ 6, 10,  8, ...,  7, 14, 11])\n\n\n\n%%timeit\nnp.bincount(ids)\n\n19.8 ms ± 388 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\nMatrix multiplication with diagonal matrices\n\ndef DxM(diag, m):\n    '''\n    Product of a diagonal and a matrix, i.e. take diag @ m.\n\n    Arguments:\n        diag (NumPy Array or float): diagonal entries or multiplicative factor\n        m (NumPy Array): matrix\n    '''\n    if isinstance(diag, (float, int)):\n        # If multiplicative factor\n        if diag == 1:\n            return m\n        return diag * m\n\n    # If diagonal entries\n    return (diag * m.T).T\n\ndef MxD(m, diag):\n    '''\n    Product of a matrix and a diagonal, i.e. take m @ diag.\n\n    Arguments:\n        m (NumPy Array): matrix\n        diag (NumPy Array or float): diagonal entries or multiplicative factor\n    '''\n    if isinstance(diag, (float, int)):\n        # If multiplicative factor\n        if diag == 1:\n            return m\n        return diag * m\n\n    # If diagonal entries\n    return m * diag\n\n\nn = int(3 * 1e3)\na = rng.normal(size=(n, n))\nb = rng.normal(size=n)\n\n\nnp.diag(b)\n\narray([[-0.12979449,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  1.38349557,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.17053631, ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [ 0.        ,  0.        ,  0.        , ...,  0.36049499,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.35106105,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.69177961]])\n\n\n\n%%timeit\nnp.diag(b) @ a\n\n650 ms ± 25.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n%%timeit\nDxM(b, a)\n\n4.45 ms ± 150 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit\nb[:, None] * a\n\n4.16 ms ± 138 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit\na @ np.diag(b)\n\n630 ms ± 28.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\n%%timeit\nMxD(a, b)\n\n5.55 ms ± 105 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\nDxM(b, a)\n\narray([[ 0.04305389, -0.02450608,  0.03333491, ...,  0.07252111,\n        -0.20889637, -0.06667676],\n       [-3.04643963,  0.695854  ,  1.09382668, ..., -0.3196933 ,\n        -3.23805228, -0.73283361],\n       [ 0.02401034,  0.11501715,  0.01543444, ..., -0.11485651,\n         0.10094913,  0.11068856],\n       ...,\n       [-0.81180489, -0.08033079,  0.15354346, ...,  0.27811731,\n         0.40886214,  0.05923034],\n       [-0.03913632,  0.0205819 ,  0.38672633, ...,  0.51782762,\n        -0.52494684, -0.3598065 ],\n       [-0.56939833,  0.23959058,  0.88602361, ..., -1.20676408,\n         0.2856753 ,  0.46799477]])\n\n\n\n\nNonzero\n\na = rng.binomial(1, 0.5, size=100)\na\n\narray([0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n       1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0])\n\n\n\nnp.argmax(a)\n\n1\n\n\n\nnp.nonzero(a)[0]\n\narray([ 1,  2,  3,  6,  7,  8,  9, 12, 13, 16, 18, 22, 23, 28, 32, 33, 34,\n       37, 39, 41, 42, 43, 44, 47, 48, 49, 50, 53, 60, 61, 62, 67, 71, 74,\n       78, 81, 82, 84, 86, 90, 93, 98])"
  },
  {
    "objectID": "Python/Lectures/lecture4.html",
    "href": "Python/Lectures/lecture4.html",
    "title": "Lesson 4",
    "section": "",
    "text": "Classes\nQueues\nPA3 Review"
  },
  {
    "objectID": "Python/Lectures/lecture4.html#overview",
    "href": "Python/Lectures/lecture4.html#overview",
    "title": "Lesson 4",
    "section": "",
    "text": "Classes\nQueues\nPA3 Review"
  },
  {
    "objectID": "Python/Lectures/lecture4.html#classes",
    "href": "Python/Lectures/lecture4.html#classes",
    "title": "Lesson 4",
    "section": "Classes",
    "text": "Classes\nAn easy way to store and handle “related” data/variables.\n\nclass Student():\n    def __init__(self, first_name, last_name, middle_name=None):\n        self.first_name = first_name\n        self.last_name = last_name\n        self.middle_name = middle_name\n\n    def print_name(self):\n        if self.middle_name is None:\n            print(self.first_name, self.last_name)\n        else:\n            print(self.first_name, self.middle_name, self.last_name)\n\n\nstudent1 = Student(first_name='Adam', middle_name='Alexander', last_name='Oppenheimer')\nstudent1.print_name()\n\nAdam Alexander Oppenheimer\n\n\n\nstudent2 = Student(first_name='Yutong', last_name='Zhong')\nstudent2.print_name()\n\nYutong Zhong\n\n\n\nstudent1.middle_name\n\n'Alexander'\n\n\n\nstudent1.new_variable = 10\n\n\nstudent1.new_variable\n\n10\n\n\n\nclass Classroom():\n    def __init__(self, class_number):\n        self.class_number = class_number\n        self.students = []\n\n    def add_student(self, student):\n        self.students.append(student)\n\n    def sort_students(self, order='last_name'):\n        if order == 'last_name':\n            self.students = sorted(self.students, key=lambda a: a.last_name)\n        elif order == 'first_name':\n            self.students = sorted(self.students, key=lambda a: a.first_name)\n\n    def print(self):\n        print('Class number:', self.class_number)\n        print('Students:')\n        for student in self.students:\n            student.print_name()\n\n\npython_course = Classroom(1)\npython_course.add_student(student2)\npython_course.add_student(student1)\npython_course.print()\n\nClass number: 1\nStudents:\nYutong Zhong\nAdam Alexander Oppenheimer\n\n\n\npython_course.sort_students()\npython_course.print()\n\nClass number: 1\nStudents:\nAdam Alexander Oppenheimer\nYutong Zhong\n\n\n\npython_course.add_student(61)\n\n\npython_course.sort_students()\n\nAttributeError: 'int' object has no attribute 'last_name'\n\n\n\npython_course.print()\n\nClass number: 1\nStudents:\nAdam Alexander Oppenheimer\nYutong Zhong\n\n\nAttributeError: 'int' object has no attribute 'print_name'"
  },
  {
    "objectID": "Python/Lectures/lecture4.html#queues",
    "href": "Python/Lectures/lecture4.html#queues",
    "title": "Lesson 4",
    "section": "Queues",
    "text": "Queues\nWhat goes in first comes out first.\n\nimport queue\n\na = queue.Queue()\na.put(1)\na.put(3)\na.put(2)\nprint(a.get())\nprint(a.get())\nprint(a.get())\n\n1\n3\n2\n\n\n\na.get()\n\nKeyboardInterrupt: \n\n\nPriority Queue orders based on some ranking (often the first element of a tuple). Read more about them for PA4.\n\nb = queue.PriorityQueue()\nb.put((1, 'hello'))\nb.put((3, 'goodbye'))\nb.put((2, 'waiting'))\nprint(b.get())\nprint(b.get())\nprint(b.get())\n\n(1, 'hello')\n(2, 'waiting')\n(3, 'goodbye')"
  },
  {
    "objectID": "Python/Lectures/lecture4.html#pa3-review",
    "href": "Python/Lectures/lecture4.html#pa3-review",
    "title": "Lesson 4",
    "section": "PA3 review",
    "text": "PA3 review\nQuickly review my solution"
  },
  {
    "objectID": "Python/Lectures/lecture2.html",
    "href": "Python/Lectures/lecture2.html",
    "title": "Lesson 2",
    "section": "",
    "text": "Stuff I forgot to teach\n\nAccessing substrings\n\nNesting\n\nNested loops\n\n\nNested lists/tuples/dicts/etc.\n\nScope\n\nVariables\n\n\nFunctions\n\nList index\nPA1 Review"
  },
  {
    "objectID": "Python/Lectures/lecture2.html#overview",
    "href": "Python/Lectures/lecture2.html#overview",
    "title": "Lesson 2",
    "section": "",
    "text": "Stuff I forgot to teach\n\nAccessing substrings\n\nNesting\n\nNested loops\n\n\nNested lists/tuples/dicts/etc.\n\nScope\n\nVariables\n\n\nFunctions\n\nList index\nPA1 Review"
  },
  {
    "objectID": "Python/Lectures/lecture2.html#stuff-i-forgot-to-teach",
    "href": "Python/Lectures/lecture2.html#stuff-i-forgot-to-teach",
    "title": "Lesson 2",
    "section": "Stuff I forgot to teach",
    "text": "Stuff I forgot to teach\n\nAccessing substrings\nAccess substrings as if the string is a list\n\na = 'hello'\na[3: 5]\n\n'lo'\n\n\n\na[0]\n\n'h'\n\n\n\na[2:]\n\n'llo'\n\n\n\na[-3:]\n\n'llo'"
  },
  {
    "objectID": "Python/Lectures/lecture2.html#nesting",
    "href": "Python/Lectures/lecture2.html#nesting",
    "title": "Lesson 2",
    "section": "Nesting",
    "text": "Nesting\n\nNested loops\nA loop inside a loop\nNOTE 1: Be careful about indents!\nNOTE 2: You can include if and/or while statements inside nested loops\n\nfor i in range(3):\n    for j in range(3):\n        print(f'i: {i}, j: {j}')\n\ni: 0, j: 0\ni: 0, j: 1\ni: 0, j: 2\ni: 1, j: 0\ni: 1, j: 1\ni: 1, j: 2\ni: 2, j: 0\ni: 2, j: 1\ni: 2, j: 2\n\n\n\n\nNested lists/tuples/dicts/etc.\nThe elements of the main list are lists - access sublists using brackets, then elements of sublists using brackets\n\nnested_list = [\n    ['a11', 'a12', 'a13'],\n    ['a21', 'a22', 'a23', 'a24'],\n    ['a31', 'a32', 'a33']\n]\nprint(nested_list)\n\n[['a11', 'a12', 'a13'], ['a21', 'a22', 'a23', 'a24'], ['a31', 'a32', 'a33']]\n\n\n\nprint(nested_list[1])\n\n['a21', 'a22', 'a23', 'a24']\n\n\n\nprint(nested_list[1][2])\n\na23\n\n\n\nnested_list = [\n    ['a11', 'a12', 'a13'],\n    ['a21', 'a22', 'a23', 'a24'],\n    ['a31', 'a32', 'a33'],\n    'fjls',\n    134,\n    {'a': {'c': [1, 2, 3], 'd': 123}, 'b': 2}\n]\nprint(nested_list)\n\n[['a11', 'a12', 'a13'], ['a21', 'a22', 'a23', 'a24'], ['a31', 'a32', 'a33'], 'fjls', 134, {'a': {'c': [1, 2, 3], 'd': 123}, 'b': 2}]\n\n\n\nprint(nested_list[5])\n\n{'a': {'c': [1, 2, 3], 'd': 123}, 'b': 2}\n\n\n\nprint(nested_list[5]['a'])\n\n{'c': [1, 2, 3], 'd': 123}\n\n\n\nprint(nested_list[5]['a']['d'])\n\n123"
  },
  {
    "objectID": "Python/Lectures/lecture2.html#scope",
    "href": "Python/Lectures/lecture2.html#scope",
    "title": "Lesson 2",
    "section": "Scope",
    "text": "Scope\nWhat is the effect of modifying a variable?\n\nVariables\n\na = 3\nb = a\nb = 4\nprint(f'a: {a}, b: {b}')\n\na: 3, b: 4\n\n\nVariables that are lists are actually references to where the list is stored in memory\n\na = [1, 2, 3]\nb = a\nb.append(4)\nprint('a:', a)\nprint('b:', b)\n\na: [1, 2, 3, 4]\nb: [1, 2, 3, 4]\n\n\n\nb = [1, 2, 3, 4, 5]\nprint('a:', a)\nprint('b:', b)\n\na: [1, 2, 3, 4]\nb: [1, 2, 3, 4, 5]\n\n\n\n\nCopying\n\nb = a.copy()\nb.append(5)\nprint('a:', a)\nprint('b:', b)\n\na: [1, 2, 3, 4]\nb: [1, 2, 3, 4, 5]\n\n\n\n\nFunctions\nDefining new variables inside a function is a new, smaller scope\n\na = 5\n\ndef a_to_ten():\n    a = 10\n    print('Inside function:', a)\n\nprint('Before function:', a)\na_to_ten()\nprint('After function:', a)\n\nBefore function: 5\nInside function: 10\nAfter function: 5\n\n\nCan still modify lists inside of functions (this is called in-place modification)\n\na = [1, 2, 3]\n\ndef append_4(a):\n    a.append(4)\n\nprint('Before function:', a)\nappend_4(a)\nprint('After function:', a)\n\nBefore function: [1, 2, 3]\nAfter function: [1, 2, 3, 4]\n\n\n\na = [1, 2, 3]\n\ndef append_4():\n    a.append(4)\n\nprint('Before function:', a)\nappend_4()\nprint('After function:', a)\n\nBefore function: [1, 2, 3]\nAfter function: [1, 2, 3, 4]\n\n\n\na = [1, 2, 3]\n\ndef append_4():\n    a.copy().append(4)\n\nprint('Before function:', a)\nappend_4()\nprint('After function:', a)\n\nBefore function: [1, 2, 3]\nAfter function: [1, 2, 3]\n\n\n\na = 'hello'\n\ndef append_4(a):\n    a += 'goodbye'\n    return a\n\nprint('Before function:', a)\na2 = append_4(a)\nprint('After function:', a)\nprint('a2:', a2)\n\nBefore function: hello\nAfter function: hello\na2: hellogoodbye"
  },
  {
    "objectID": "Python/Lectures/lecture2.html#list-index",
    "href": "Python/Lectures/lecture2.html#list-index",
    "title": "Lesson 2",
    "section": "List index",
    "text": "List index\nFind the index of an element in a list - useful for PA2\n\nlist1 = ['a', 'b', 'c']\nprint(list1.index('a'))\nprint(list1.index('b'))\nprint(list1.index('c'))\n\n0\n1\n2\n\n\n\nlist2 = ['a', 'b', 'c', 'a']\nprint(list2.index('a'))\n\n0\n\n\nTo get all indices for a value\n\nimport numpy as np\n\nnp.nonzero((np.array(list2) == 'a').astype(int))[0]\n\narray([0, 3])"
  },
  {
    "objectID": "Python/Lectures/lecture2.html#pa1-review",
    "href": "Python/Lectures/lecture2.html#pa1-review",
    "title": "Lesson 2",
    "section": "PA1 review",
    "text": "PA1 review\nQuickly review my solution"
  },
  {
    "objectID": "Python/Lectures/lecture3.html",
    "href": "Python/Lectures/lecture3.html",
    "title": "Lesson 3",
    "section": "",
    "text": "Tricks for functions\n\nLambda functions\n\n\nComposing functions\n\nTricks for lists\n\nSyntactic sugar\n\n\nsorted()\n\n\nzip()\n\n\nany() and all()\n\nTricks for strings\n\nlower()\n\n\nsplit()\n\n\nstrip()\n\n\nstartswith()\n\nType casting\nPA2 Review"
  },
  {
    "objectID": "Python/Lectures/lecture3.html#overview",
    "href": "Python/Lectures/lecture3.html#overview",
    "title": "Lesson 3",
    "section": "",
    "text": "Tricks for functions\n\nLambda functions\n\n\nComposing functions\n\nTricks for lists\n\nSyntactic sugar\n\n\nsorted()\n\n\nzip()\n\n\nany() and all()\n\nTricks for strings\n\nlower()\n\n\nsplit()\n\n\nstrip()\n\n\nstartswith()\n\nType casting\nPA2 Review"
  },
  {
    "objectID": "Python/Lectures/lecture3.html#tricks-for-functions",
    "href": "Python/Lectures/lecture3.html#tricks-for-functions",
    "title": "Lesson 3",
    "section": "Tricks for functions",
    "text": "Tricks for functions\n\nLambda functions\nShorthand functions for simple tasks. Especially useful for sorting (will discuss soon).\n\nsum_a_b_sq = lambda a, b: a + b ** 2\nprint(sum_a_b_sq(2, 4))\n\n18\n\n\n\n\nComposing functions\nApply multiple functions in one line. Notice *, which unpacks the list (** unpacks a dictionary).\n\na_sq_b_cubed = lambda a, b: (a ** 2, b ** 3)\nprint(sum_a_b_sq(*a_sq_b_cubed(4, 12)))\n\n2986000\n\n\n\na_sq_b_cubed(4, 12)\n\n(16, 1728)\n\n\n\n*a_sq_b_cubed(4, 12)\n\nSyntaxError: can't use starred expression here (2410165554.py, line 1)\n\n\n\ndef print_name(first_name, last_name, middle_name=''):\n    print(first_name, middle_name, last_name)\n\nprint_name(first_name='Adam', middle_name='Alexander', last_name='Oppenheimer')\nprint_name(**{'first_name': 'Adam', 'middle_name': 'Alexander', 'last_name': 'Oppenheimer'})\n\nSyntaxError: non-default argument follows default argument (1961358567.py, line 1)\n\n\n\ndef print_name(first_name, middle_name='', last_name):\n    print(first_name, middle_name, last_name)\n\nSyntaxError: non-default argument follows default argument (4160617308.py, line 1)"
  },
  {
    "objectID": "Python/Lectures/lecture3.html#tricks-for-lists",
    "href": "Python/Lectures/lecture3.html#tricks-for-lists",
    "title": "Lesson 3",
    "section": "Tricks for lists",
    "text": "Tricks for lists\n\nSyntactic sugar\nSuper convenient way to create lists (also works for dictionaries and tuples).\n\nlst = []\nfor a in range(5):\n    lst.append(a)\nprint(lst)\n\n[0, 1, 2, 3, 4]\n\n\n\n[a for a in range(5)]\n\n[0, 1, 2, 3, 4]\n\n\n\n[a if (a % 2 == 0) else 1 / a for a in range(5)]\n\n[0, 1.0, 2, 0.3333333333333333, 4]\n\n\n\n[a for a in range(5) if a != 3]\n\n[0, 1, 2, 4]\n\n\n\n[a if (a % 2 == 0) else 1 / a for a in range(5) if a != 2]\n\n[0, 1.0, 0.3333333333333333, 4]\n\n\nCan even nest syntactic sugar. Notice you order the for loops in the same order as if you were writing out the full loops.\n\n[(i, j) for i in range(3) for j in range(2)]\n\n[(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1)]\n\n\n\n[(i, j) for i in range(3) for j in range(i)]\n\n[(1, 0), (2, 0), (2, 1)]\n\n\nBe careful about some weird behavior with syntactic sugar (this can also happen with regular loops) (see https://stackoverflow.com/questions/3431676/creating-functions-or-lambdas-in-a-loop-or-comprehension).\n\n\nsorted()\nSort a list and specify the key. Notice the lambda functions to set the key for sorting.\n\nsorted([('d', 4), ('a', 1), ('r', 2)], key=lambda a: a[0])\n\n[('a', 1), ('d', 4), ('r', 2)]\n\n\n\nsorted([('d', 4), ('a', 1), ('r', 2)], key=lambda a: a[1])\n\n[('a', 1), ('r', 2), ('d', 4)]\n\n\n\n\nzip()\nCombine two lists element by element. Make sure to convert to a list for PA3.\n\nlist(zip(range(0, 5), range(5, 0, -1)))\n\n[(0, 5), (1, 4), (2, 3), (3, 2), (4, 1)]\n\n\nMake sure the lists are the same length! They’ll zip even if they aren’t!\n\nlist(zip(range(0, 7), range(5, 0, -1)))\n\n[(0, 5), (1, 4), (2, 3), (3, 2), (4, 1)]\n\n\n\nfor i in zip(range(0, 5), range(5, 0, -1)):\n    print(i)\n\n(0, 5)\n(1, 4)\n(2, 3)\n(3, 2)\n(4, 1)\n\n\n\nzipped_lst = zip(range(0, 5), range(5, 0, -1))\nfor elmt in zipped_lst:\n    print(elmt)\n    break\nfor elmt in zipped_lst:\n    print(elmt)\n    break\nprint(zipped_lst[0])\n\n(0, 5)\n(1, 4)\n\n\nTypeError: 'zip' object is not subscriptable\n\n\n\n\nany() and all()\nany(): check whether any element of a list is True.\nall(): check whether all elements of a list are True.\n\nany([True, True, False])\n\nTrue\n\n\n\nany([False, False, False])\n\nFalse\n\n\n\nall([True, True, False])\n\nFalse\n\n\n\nall([True, True, True])\n\nTrue"
  },
  {
    "objectID": "Python/Lectures/lecture3.html#tricks-for-strings",
    "href": "Python/Lectures/lecture3.html#tricks-for-strings",
    "title": "Lesson 3",
    "section": "Tricks for strings",
    "text": "Tricks for strings\n\nlower()\nConvert text to lowercase.\n\n'HELLO'.lower()\n\n'hello'\n\n\n\n\nsplit()\nSplit string into a list, dividing words by the specified character.\n\n'Hello, I am Adam.'.split(' ')\n\n['Hello,', 'I', 'am', 'Adam.']\n\n\n\n'Hello, I am Adam.'.split('m')\n\n['Hello, I a', ' Ada', '.']\n\n\n\n\nstrip()\nRemove the specified characters from the start and end of a string.\n\n'abcdefgabcdefg'.strip('bacdg')\n\n'efgabcdef'\n\n\n\n\nstartswith()\nCheck whether the string starts with the specified string.\n\n'hello'.startswith('he')\n\nTrue\n\n\n\n'hello'.startswith('hen')\n\nFalse\n\n\n\n\nType casting\nConvert between types by writing the name of the type you want to convert to and using the name as if it is a function.\n\nval = 1.0\nprint(val)\nprint(int(val))\n\n1.0\n1\n\n\n\nlst = [1, 2, 3]\nprint(lst)\nprint(tuple(lst))\n\n[1, 2, 3]\n(1, 2, 3)\n\n\n\nprint(zip(range(0, 5), range(5, 0, -1)))\nprint(list(zip(range(0, 5), range(5, 0, -1))))\n\n&lt;zip object at 0x7fd818792d80&gt;\n[(0, 5), (1, 4), (2, 3), (3, 2), (4, 1)]"
  },
  {
    "objectID": "Python/Lectures/lecture3.html#pa2-review",
    "href": "Python/Lectures/lecture3.html#pa2-review",
    "title": "Lesson 3",
    "section": "PA2 review",
    "text": "PA2 review\nQuickly review my solution"
  },
  {
    "objectID": "Python/Lectures/lecture1.html",
    "href": "Python/Lectures/lecture1.html",
    "title": "Lesson 1",
    "section": "",
    "text": "Self-introductions\nConda\n\n\nEnvironments\n\n\nImporting packages\nVariables\n\n\nAssignment (using =)\nNaming\nTypes (str, int, float, bool, lists/tuples/sets, dicts)\nFor ints/floats: operations\nLists/tuples/sets and dicts\n\nFor lists/tuples: subsets, len(), sum(), max(), min(), etc.\n\nFor strings: subsets, addition, and f-strings\n\n\nIf statements\n\n\nComparisons\nand and or\nIndentation\n\n\nLoops\n\n\nIndentation\nFor loops\nWhile loops\nBreaks\nContinue\n\n\nFunctions\n\n\nSyntax\nIndentation\nArguments\nReturns\nComments\n\nDocstrings\n\n\n\nPrinting text"
  },
  {
    "objectID": "Python/Lectures/lecture1.html#overview",
    "href": "Python/Lectures/lecture1.html#overview",
    "title": "Lesson 1",
    "section": "",
    "text": "Self-introductions\nConda\n\n\nEnvironments\n\n\nImporting packages\nVariables\n\n\nAssignment (using =)\nNaming\nTypes (str, int, float, bool, lists/tuples/sets, dicts)\nFor ints/floats: operations\nLists/tuples/sets and dicts\n\nFor lists/tuples: subsets, len(), sum(), max(), min(), etc.\n\nFor strings: subsets, addition, and f-strings\n\n\nIf statements\n\n\nComparisons\nand and or\nIndentation\n\n\nLoops\n\n\nIndentation\nFor loops\nWhile loops\nBreaks\nContinue\n\n\nFunctions\n\n\nSyntax\nIndentation\nArguments\nReturns\nComments\n\nDocstrings\n\n\n\nPrinting text"
  },
  {
    "objectID": "Python/Lectures/lecture1.html#self-introductions",
    "href": "Python/Lectures/lecture1.html#self-introductions",
    "title": "Lesson 1",
    "section": "1. Self-introductions",
    "text": "1. Self-introductions"
  },
  {
    "objectID": "Python/Lectures/lecture1.html#conda",
    "href": "Python/Lectures/lecture1.html#conda",
    "title": "Lesson 1",
    "section": "2. Conda",
    "text": "2. Conda\nDoes lots of things, we’re using it for package management\nPackages are how people share their code with others\n\n2.1 Environments\nAllows you to keep packages organized - see here\n\nTo create: conda create --name pycourse (you can replace pycourse with any custom name)\nTo activate: conda activate pycourse\nTo install pip: conda install pip\nTo install package: pip install packagename (replace packagename with the name of the package you want to install)\n\nFor this lesson, please install: jupyterlab and/or notebook to be able to open Jupyter Notebooks (like this) (see here for more information)"
  },
  {
    "objectID": "Python/Lectures/lecture1.html#importing-packages",
    "href": "Python/Lectures/lecture1.html#importing-packages",
    "title": "Lesson 1",
    "section": "3. Importing packages",
    "text": "3. Importing packages\nType import packagename\n\nimport random\n\n\nprint(random.random())"
  },
  {
    "objectID": "Python/Lectures/lecture1.html#variables",
    "href": "Python/Lectures/lecture1.html#variables",
    "title": "Lesson 1",
    "section": "4. Variables",
    "text": "4. Variables\nWhy - you need to keep track of what’s what\n\n4.1 Assignment\nAssign a value to a name using = (this is not equivalent to mathematical equality, check that using ==)\n\nx = 10\nprint(x)\n\n\n\n4.2 Naming\nChoose names carefully\n\nx = 10\ndistance = 10\n\n\n\n4.3 Types\nstr, int, float, bool, lists/tuples/sets, dicts\n\ncourse_name_v1 = 'Python Course, Summer 2024'\ncourse_name_v2 = \"Python Course, Summer 2024\"\ncourse_name_v3 = \\\n'''\nPython Course, Summer 2024\n'''\ncourse_year = 2024\nlecture_1_frac_complete = 1/5 # Or 0.2\nlecture_1_complete = False # Or True\nlectures = [1, 2, 3, 4, 5, 6, 7, 8]\nlecture_v2 = (1, 2, 3, 4, 5, 6, 7, 8)\nlectures_v3 = {1, 2, 3, 4, 5, 6, 7, 8, 8}\nlectures_occurred = {1: 'True', 2: 'False', 3: 'False', 4: 'False', 5: 'False', 6: 'False', 7: 'False', 8: 'False'}\n\n\n\n4.4 For ints/floats: operations\n\nAddition: +\nSubtraction: -\nMultiplication: *\nDivision: /\nExponentiation: **\nIn-place: +=, -=, *=, /=, **=\n\n\na = 5\nb = 2\n\n\nprint(a + b)\n\n\na += b\nprint(a)\n\n\na = 5\na *= b\nprint(a)\n\n\na = 5\na **= b\nprint(a)\n\n\n\n4.5 Lists/tuples/sets and dicts\nLists are mutable (they can be changed) - Access an element using list[index] (indexing starts at 0)\nTuples are immutable (they cannot be changed) - Access an element using tuple[index] (indexing starts at 0)\nSets don’t have an order\nDicts work like a dictionary (a term called a ‘key’ will be linked to an associated variable called a ‘value’) - Access a value using dict[key]\n\nprint(lectures)\nlectures[0] = 0\nprint(lectures)\n\n\nprint(lecture_v2)\nlecture_v2[0] = 0\n\n\nprint(lectures_v3)\nlectures_v3[0] = 0\n\n\nprint(lectures_occurred)\nlectures_occurred[0] = False\nprint(lectures_occurred)\nlectures_occurred['word'] = 'definition'\nprint(lectures_occurred)\n\n\n\n4.5.1 For lists/tuples: subsets, len(), sum(), max(), min(), etc.\nAccess a subset of a list/tuple using list[a: b]/tuple[a: b], which gives you the elements starting and index a and ending at index b-1 (remember that indexing starts at 0)\n\nprint(lectures)\nprint('Subset of list:', lectures[2: 4])\nprint('Last element of list:', lectures[-1])\nprint('Length of list:', len(lectures))\nprint('Max of tuple:', max(lecture_v2))\nprint('Min of tuple:', min(lecture_v2))\n\n\n\n4.6 For strings: subsets, addition, and f-strings\nAccess substrings as if the string is a list\n\na = 'hello'\na[3: 5]\n\n\na[0]\n\n\na[2:]\n\n\na[-3:]\n\nStrings can be combined using +\n\na = 'hello'\nb = 'goodbye'\na + b\n\nVariables can easily be put into strings using f-strings\n\na = 5\nb = 6\nf'a is {a} and b is {b}'"
  },
  {
    "objectID": "Python/Lectures/lecture1.html#if-statements",
    "href": "Python/Lectures/lecture1.html#if-statements",
    "title": "Lesson 1",
    "section": "5. If statements",
    "text": "5. If statements\nIf you want a task to occur under certain conditions\n\n5.1 Comparisons\n\n== for equality\n!= for inequality\n&gt; or &lt; for strict inequality\n&gt;= or &lt;= for weak inequality\nin for list membership\nis for variable reference ids and None\n\n\nx\n\n\nif x == 8:\n    print('x is 8')\nelif x == 9:\n    print('x is 9')\nelse:\n    print('x is neither 8 nor 9')\n\nIf a variable is already a boolean, it can directly be used as a comparison - conciseness is preferred\n\na = 5\nx = (a == 5)\nif x: # Preferred\n    print('x is True since a is 5')\nelse:\n    print('x is False since a is not 5')\nif x == True: # Works, but not preferred\n    print('x is True since a is 5')\nelse:\n    print('x is False since a is not 5')\n\n\n\n5.2 and and or\nCombine statements with and and or\n\nif (x &gt;= 0) and (x &lt; 20):\n    print('x is in [0, 20)')\n\n\nif 0 &lt;= x &lt; 20:\n    print('x is in [0, 20)')\n\n\n\n5.3 Indentation\nMake sure the code inside the if statement is properly indented (4 spaces)\nNested if statements should also have nested indentation"
  },
  {
    "objectID": "Python/Lectures/lecture1.html#loops",
    "href": "Python/Lectures/lecture1.html#loops",
    "title": "Lesson 1",
    "section": "6. Loops",
    "text": "6. Loops\nIf you want to repeat a task\n\n6.1 Indentation\nMake sure the code inside the loop is properly indented (4 spaces)\nNested loops should also have nested indentation\n\n\n6.2 For loops\nIterate through the elements of a list/tuple/etc\n\n# List/tuple\nfor lecture in lectures:\n    print('Lecture:', lecture)\n\n\nlectures_occurred.items()\n\n\n# Dict\nfor lecture, lecture_occurred in lectures_occurred.items():\n    print(f'Lecture {lecture} occurred: {lecture_occurred}')\n\n\nlen(lectures)\n\n\n# Range\nfor i in range(len(lectures)):\n    print(f'Loop {i}, lecture {lectures[i]}')\n\n\n# Enumerate\nfor i, lecture in enumerate(lectures):\n    print(f'Loop {i}, lecture {lecture}')\n\n\n\n6.3 While loops\nIterate as long as some condition holds\n\ni = 0\nwhile i &lt; 10:\n    print(i)\n    i += 1\n\n\n\n6.4 Breaks\nAn alternative way to get out of loops\n\ni = 0\nwhile True:\n    print(i)\n    i += 1\n    if i &gt;= 10:\n        break\n\n\n\n6.5 Continue\nIf you want an if statement for clarity, but you don’t want it to do anything\n\nfor i, lecture in enumerate(lectures):\n    print(i)\n    if lecture == 3:\n        continue\n    else:\n        print('This is not lecture 3')\n\n\nfor i, lecture in enumerate(lectures):\n    print(i)\n    if lecture == 3:\n    else:\n        print('This is not lecture 3')"
  },
  {
    "objectID": "Python/Lectures/lecture1.html#functions",
    "href": "Python/Lectures/lecture1.html#functions",
    "title": "Lesson 1",
    "section": "7. Functions",
    "text": "7. Functions\nA simple way to repeat a task\n\n7.1 Syntax\nMake sure to write def before the function name, put the function arguments inside parantheses, and make sure the parentheses are followed by a semicolon\n\n\n7.2 Indentation\nMake sure the code inside the function is properly indented (4 spaces)\nNested functions should also have nested indentation\n\n\n7.3 Arguments\nThe input the function requires to run (equivalent to the arguments of a mathematical function)\n\n\n7.4 Returns\nWhat the function produces after it runs\n\n\n7.5 Comments\nExplain what you code is doing (put # before a single-line comment, or wrap a multi-line comment in triple quotes ''')\n\n7.5.1 Docstrings\nDetail at the top of the function what it does, what the arguments are, and what it returns\n\ndef square_x(x):\n    '''\n    Return the square of x.\n    \n    Arguments:\n        x (float): value to square\n        \n    Returns:\n        (float): square of x\n    '''\n    return x ** 2\n\ndef list_mean(lst):\n    '''\n    Return the mean of a list of numbers.\n    \n    Arguments:\n        lst (list): list to compute the mean of\n        \n    Returns:\n        (float): mean value of lst\n    '''\n    lst_sum = 0\n    lst_len = 0\n    for val in lst:\n        # Add values to sum\n        lst_sum += val\n        # Update length of list\n        lst_len += 1\n    # Compute mean value in lst\n    return lst_sum / lst_len\n\ndef list_mean_v2(lst):\n    '''\n    Return the mean of a list of numbers.\n    \n    Arguments:\n        lst (list): list to compute the mean of\n        \n    Returns:\n        (float): mean value of lst\n    '''\n    return sum(lst) / len(lst)\n\n# Two arguments, plus using functions inside other functions\ndef list_mean_v3(lst1, lst2):\n    '''\n    Return the mean of the means of two lists of numbers.\n    \n    Arguments:\n        lst1 (list): list 1 to compute the mean of\n        lst2 (list): list 2 to compute the mean of\n\n    Returns:\n        (float): mean value of mean values of lst1 and lst2\n    '''\n    return (list_mean_v2(lst1) + list_mean_v2(lst2)) / 2\n\n\nsquare_x(10)\n\n\nlist_mean([2, 7, 10])\n\n\nlist_mean_v2([2, 7, 10])\n\n\nlist_mean_v3([2, 7, 10], [5, 12, 1])"
  },
  {
    "objectID": "Python/Lectures/lecture1.html#printing-text",
    "href": "Python/Lectures/lecture1.html#printing-text",
    "title": "Lesson 1",
    "section": "8. Printing text",
    "text": "8. Printing text\nUseful for debugging\nLook throughout for examples, but primarily use f-strings:\n\nprint(f'This is an f statement, so we can print variables like lists: {lectures} or dicts: {lectures_occurred} easily')\n\nFor simple cases, use commas (this is not as clean for complicated examples):\n\nprint('Lectures:', lectures)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Crash Course for Economics PhD Students, Summer 2024 (UMN)",
    "section": "",
    "text": "Disclaimer: this site is a work in progress!\nWelcome to the 2024 summer course on computational economics at UMN! It will be a 3-week crash course consisting of 2 Julia and 2 Python lectures each week. The Julia lectures will be taught by Xing Xu and the Python lectures will be taught by Adam Oppenheimer. Find the detailed syllabus and information below.\nAll the notebooks for lectures and assignments can be downloaded from Github repo."
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "Computational Crash Course for Economics PhD Students, Summer 2024 (UMN)",
    "section": "Course Overview",
    "text": "Course Overview\nThe course offerings are designed to cater to varying interests and skill levels. The Julia lectures will primarily concentrate on fundamental dynamic programming, demonstrating applications across a range of classical economic models. These include the neo-classical growth model, job search, the Aiyagari model, and firm dynamics. The homework will involve hands-on practice with basic Julia coding and provide exposure to some practical methods, including interpolation, continuous optimization, and parallelization. Lecture 5 on June 18th will feature Professor Kim Ruhl as a guest lecturer to talk about the model part.\nIn contrast, the Python lectures are tailored to those new to programming. These sessions will focus on establishing a solid foundation in programming basics. Students will progressively build their skill set, and by the end of the course should be able to solve a simple dynamic programming model. For those who are new to programming, this will complement the Julia lectures by helping reinforce good coding practices that are necessary for the more complicated models covered in that course. On the other hand, those who are already experienced in programming can benefit from the focus on Python-specific subtleties that are required for highly optimized Python code.\nBoth courses are structured as introductory, requiring no prior experience in programming. While the courses are comprehensive, they intentionally do not delve into advanced methodologies found at the cutting edge of computational economics. Such topics are reserved for the official computational field courses usually taken in the second year.\nIt’s important to note that the skills developed in these classes are broadly applicable and will provide a strong foundation for those interested in advancing to more specialized computational sequences. However, students already familiar with basic or intermediate programming and computational economic skills may find some of the content less interesting. Thus, students equipped with those skills might prefer to direct their attention toward more advanced courses that align with their existing skill levels."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Computational Crash Course for Economics PhD Students, Summer 2024 (UMN)",
    "section": "Schedule",
    "text": "Schedule\nThe class will last three weeks from June 3rd - June 21st, 2024. The class will be online and zoom links will be provided to those who intend to participate. There will be 6 lectures and accompanying problem sets for each language.\nHere is the proposed timeline of the lectures. All lectures will be from 9:30 am - 11:00 am CDT.\n\n\n\nJulia Lectures\nDates\n\n\n\n\nJulia Fundamentals\nTuesday, June 4th\n\n\nNeoclassical growth model (RBC)\nThursday, June 6th\n\n\nRoot finding, Interpolation, and Continuous optimization\nTuesday, June 11th\n\n\nIncomplete market model with heterogeneous household\nThursday, June 13th\n\n\nFirm dynamics with an example of exporter dynamics Guest Lecturer: Kim Ruhl\nTuesday, June 18th\n\n\nMcCall’s Job search model\nThursday, June 20th\n\n\n\n(To get started with the Julia lectures, please set up with Quantecon tutorial)\n\n\n\nPython Lectures\nDates\n\n\n\n\nBasics: Conditionals, Loops, Functions, etc.\nMonday, June 3rd\n\n\nNesting, Scope, and Lists\nWednesday, June 5th\n\n\nTips & Tricks\nMonday, June 10th\n\n\nClasses and Queues\nWednesday, June 12th\n\n\nNumpy\nMonday, June 17th\n\n\nPandas\nWednesday, June 19th"
  },
  {
    "objectID": "index.html#office-hours",
    "href": "index.html#office-hours",
    "title": "Computational Crash Course for Economics PhD Students, Summer 2024 (UMN)",
    "section": "Office Hours",
    "text": "Office Hours\nWe will provide links to sign up for weekly office hours."
  },
  {
    "objectID": "index.html#assignments",
    "href": "index.html#assignments",
    "title": "Computational Crash Course for Economics PhD Students, Summer 2024 (UMN)",
    "section": "Assignments",
    "text": "Assignments\nHere are the links to the assignments:\n\n\n\nJulia Assignments\nDue Dates\n\n\n\n\nAssignment 1\nJune 10th\n\n\nAssignment 2\nJune 12th\n\n\nAssignment 3\nJune 17th\n\n\n\n\n\n\nPython Assignments\nDue Dates\n\n\n\n\nAssignment 1\nJune 5th\n\n\nAssignment 2\nJune 10th\n\n\nAssignment 3\nJune 12th\n\n\nAssignment 4\nJune 17th\n\n\nAssignment 5\nJune 19th\n\n\nAssignment 6\nJune 24th"
  },
  {
    "objectID": "Julia/Assignments/Julia_PS_1_Compecon_Xing_Xu.html",
    "href": "Julia/Assignments/Julia_PS_1_Compecon_Xing_Xu.html",
    "title": "Problem set 1",
    "section": "",
    "text": "Xing Xu, University of Minnesota, 2023 Summer"
  },
  {
    "objectID": "Julia/Assignments/Julia_PS_1_Compecon_Xing_Xu.html#question-2",
    "href": "Julia/Assignments/Julia_PS_1_Compecon_Xing_Xu.html#question-2",
    "title": "Problem set 1",
    "section": "Question 2",
    "text": "Question 2\nExercise: Simple Monte-Carlo with Linear regression (taken from Amil Petrin’s Econometric class Homework)\nThis requires some basic knowledge on OLS.\nThe objective of a Monte Carlo simulation is to verify finite and large sample results. Given a model for how variables are determined, one can test the performance and properties of sample estimators by generating several samples drawn from the same population. We will operate with the following model: \\[\ny_i=\\beta_0+x_i \\beta_1+\\epsilon_i\n\\] where \\(y_i\\) and \\(x_i\\) are random variables. You observe \\(N\\) samples of \\(i=1, \\ldots, n\\) observations of \\(y\\) and \\(x\\). You will estimate: \\[\ny_i=\\hat{\\beta}_0+x_i \\hat{\\beta}_1+e_i\n\\] You will have to execute a variety of simulations, changing sample sizes, number of samples, and assumptions. 1. First assume that the \\(\\epsilon\\) and the regressors are uncorrelated. Assume that both \\(X\\) and \\(\\epsilon\\) are drawn from a normal distribution \\(\\epsilon \\sim N\\left(0, \\sigma_\\epsilon^2\\right)\\), \\(X \\sim N\\left(\\mu_x, \\sigma_x^2\\right)\\). Start with a sample size \\((n)\\) of \\(n=100\\) and define the number of samples to be simulated \\((N)\\) to be \\(N=100\\) as well. You also need to define the true values of \\(\\beta_0\\) and \\(\\beta_1\\). Report the results that you find for the means and variance-covariance matrix of \\(\\hat{\\beta}_0, \\hat{\\beta}_1\\). Finally, plot the distribution of the estimated parameters and the theoretical normal distribution that they are supposed to follow. 2. Now vary the sample size \\(n\\) and redo 1) under the new values. Report and plot your results. Comment. 3. Now vary the number of samples \\(N\\) and redo 1) under the new values. Report and plot your results. Comment. 4. Now vary the distribution of the \\(X\\) and redo 1) under the new assumptions. Report and plot your results. Comment. 5. Now set the mean of the error \\(\\epsilon\\) to be different from zero and redo 1) under the new values. Comment. 6. Now draw the \\(\\epsilon\\) in such a way that it is in fact correlated with \\(X\\) and redo 1) under the new assumptions. Report and plot your results. Comment."
  },
  {
    "objectID": "Julia/Lectures/Julia_Lec_5_Compecon_Xing_Xu.html",
    "href": "Julia/Lectures/Julia_Lec_5_Compecon_Xing_Xu.html",
    "title": "Firm dynamics with an example of exporter dynamics",
    "section": "",
    "text": "1 What is firm dynamics?\nThe firm dynamics literature wants to study firms’ behavior over time. Dynamic models were developed to study firms’ entry and exit decisions, age, size distribution over time and even R& D, export and FDI decisions, etc. More recently, spatial components are incorporated to study, say, firms’ heterogeneous location choices for their subsidiaries.\nTo dig into the literature, a good starting point is Hopenhayn (1992), which provides a general theoretical framework that features uncertainty towards future profits, costly market entry and endogenous exit. The literature then expands dramatically with various focuses. Just to list a few, Klette and Kortum on innovations and firm distribution, Cooley and Quadrini (2001) on financial frictions, Das et al. (2007) on exporter dynamics.\n\n\n2. What’s specific about exporter dynamics?\nIn a world where large multinationals take up a huge chunk of global economy via exports, the roles these giants play is a very interesting research topic. The OECD estimated in 2018 that multinational corporations account for half of global exports, nearly a third of world GDP (28%), and about a fourth of global employment. They hold great market power and sometimes even directly alter domestic and foreign policies. Understanding their growth and policy implications is a fascinating ongoing topic, which requires a lot of the tools discussed here. We can use the dynamic trade framework to study firms’ individual and aggregate behavior, international policies and their implications on consumer welfare.\nFor the remaining part of this section, I will discuss some empirical evidence about firm-level exporting behavior. I mainly follow from the literature review on firm dynamics and trade by George, Costas and Kim, ARE 2021.\n\n\n3. Firm-level facts (from firm-level data of US and Columbia):\nStatic or time-invariant facts: * There are few exporters. * Exports are a small share of an exporter’s total sales. * Exporters are relatively large firms.\nThese facts can already trigger our thinking about the underlying firm distribution in size and productivity. These are consistent with the results of Melitz (2003). Within a group of firms originally producing domestically, only the most productive firms enter the export market. They stay in the market and force the less productive firms to exit.\nIf we further take a look at the dynamic aspect of the data, there are some more interesting observations:\n\nPast export participation is the main predictor of current export participation.\nExporter are less likely to exit if they are older and larger exporters in the past.\nEntry rate is increasing in size and past export activity.\nThe longer an exporter stays in the market, the more it tends to export.\n\nThese can explain why the dynamic aspect is vital to studying the exporting firms’ behavior. I will show some predictions of the results when we go to the theoretical framework.\nThere are also evidences about heterogeneity between exporters on their export destinations, shipment volumes and frequencies and inventories.\nAt last, The long-run response of aggregate trade volumes to changes in trade policy is larger than the short-run response. An important reason, as shown in Kehoe and Ruhl (2013), is that the aggregate trade growth is stronger in the long term due to the extensive margin. That is, during a trade liberalization, previously non-traded products grow faster than products that have already been traded between the same country pairs. One take-away is that larger quantities of firms (for concreteness, plants) would become exporters when there are ease in bilateral trade policies. Combining with the fact that exporters take time to grow, this gives a possible explanation for the long-run growth of trade.\n\n\n4. Some questions to think about:\nOn building a model, what structures do we need on individual firm’s problem to retrieve the same results as we observe? For example, how to make sure that only a few firms enter into the export market and coincidentally they are relatively large? What about on the market structure and the demand side?\nNext, we can think about idiosyncratic and aggregate uncertainties. Idiosyncratic shock is convenient to generate endogenous entry and exit, as in the firm dynamics literature. Now we can look at if there are any heterogeneous short and long run responses to aggregate uncertainties, say real exchange rate fluctuations. If so, what are the policy implications?\nA very important topic in the trade literature is the gains from trade. That is the welfare gain of household in a country facing some sort of trade liberalization. Although the focus of our model is mainly on the firm side, we can still analyze the aggregate impact under a general equilibrium framework.\n\n\n5. A canonical model for exporter dynamics\nThe model is a slightly tweaked version of Das et al. (2007), based upon Melitz (2003). For further reference, Ruhl and Willis (2017) and Alessandria et al. (2021).\nThis section is arranged as follows. I will first lay out the static model and provide analytical solutions to it. Next, I will provide the dynamic setup of the model and compute the model. To look at the firms’ short-term reaction to some sudden and unexpected (MIT) shocks, I will then illustrate the algorithms for obtaining the transition dynamics. In the end, I will provide some basic calibration and some preliminary results. I run some experiments and look at the exporters’ full dynamics facing different shocks.\n\n5.1 Static model\n\n5.1.1 Consumer\nA representative consumer in domestic economy has preferences over an aggregate consumption good, \\(C\\). Each index \\(j\\) denotes a differentiated variety. \\(C\\) takes the form: \\[\n    C = \\left(\\sum_{j=1}^{J} c_j^\\frac{\\theta - 1}{\\theta} \\right)^\\frac{\\theta}{\\theta - 1},\n\\] where \\(\\theta\\) is the elasticity of substitution between varieties, and J is the number of available varieties. The consumer maximize his utility subject to the budget constraint: \\[\n    \\sum_{j=1}^{J} c_j p_j = I.\n\\] The consumer takes prices as given and chooses optimal consumption \\(c_j\\) of each variety: \\[\n    c_j = (\\frac{p_j}{P})^{-\\theta}C,\n\\] where P is an aggregate price level given by: \\[\n    P = \\left(\\sum_{j=1}^{J} p_j^{1-\\theta} \\right)^{\\frac{1}{1 - \\theta}}.\n\\] The foreign market is identical to the domestic market with demand and consumption satisfying: \\[\n    \\begin{aligned}\n    c_j^* &= (\\frac{p_j^*}{P^*})^{-\\theta}C^*, \\\\\n    P^* &= \\left(\\sum_{j=1}^{J} {p_j^*}^{1-\\theta} \\right)^{\\frac{1}{1 - \\theta}}. \\\\\n    \\end{aligned}\n\\] Countries have same elasticity \\(\\theta\\) for differentiated goods but differ in aggregate level of demands and prices.\n\n\n5.1.2 Firm’s static problem\nAssume each firm operates solely on a market \\(j\\), so “plants” will be a better term than “firms”. Plant operates monopolistically in each differentiated variety. Plant chooses the optimal amounts to produce in domestic and foreign market. A unit good produced with plant-level technology $_j $, labor \\(n_j\\) and capital \\(k_j\\) subject to: \\[\n    f(\\tilde{\\epsilon}_j, n_j, k_j) = \\tilde{\\epsilon}_j  n_j^{\\alpha_N}k_j^{\\alpha_K},\n\\] where we assume nonincreasing returns to scale of the production technology, \\(\\alpha_N + \\alpha_K &lt;= 1\\).\nIn each period, the plant chooses the prices, production, inputs, and export status next period \\(X'\\) (\\(X'=1\\) if exporting next period and \\(X'=0\\) if not) to maximize its infinite horizon utility. The plant also faces an iceberg cost \\(\\xi_j\\), where fraction \\(\\xi_j - 1\\) of an export shipment is destroyed in transportation. In addition, foreign market might put an ad valorem tariff \\(\\tau_j\\) on exports.\nWe can thus first solve for the plant’s single period or static problem given all the states and plant’s export decision last period. A plant’s profit is sum of revenue from domestic and foreign sales less the input costs: \\[\n\\Pi_j =  p_j y_j + I(X_j = 1) (1 - \\tau_j) Q p_j^* y_j^* - wn_j - rk_j,\n\\] where \\(Q\\) is the real exchange rate; r is the rental rate of capital; and w is the wage. The plant is also subject to its feasibility constraint: \\[\ny_j + \\xi_j y_j^* = \\tilde{\\epsilon}_j  n_j^{\\alpha_N}k_j^{\\alpha_K}.\n\\] With market clearing condition in both markets \\(c_j = y_j\\) and \\(c^*_j = y^*_j\\) if \\(X_j = 1\\), with demand functions from the household problem. The plant charges constant markup over marginal cost in both markets: \\[\n    \\begin{aligned}\n    p_j &= \\frac{\\theta}{\\theta - 1} {MC}_j \\\\\n    Q p_j^* &= \\frac{1}{1- \\tau_j} \\frac{\\theta}{\\theta - 1} \\xi_j {MC}_j.\n    \\end{aligned}\n\\] where \\(MC_j = \\frac{1}{\\tilde{\\epsilon_j}} \\left(\\frac{w}{\\alpha_n}\\right)^{\\alpha_n} \\left(\\frac{r}{1 - \\alpha_n}\\right)^{1 - \\alpha_n}\\) with \\(\\alpha_n + \\alpha_k = 1\\) (if not, the formula for marginal cost will be more complicated).\nThe plant’s static profit maximization problem is: \\[\n\\Pi_j = \\max_{y_j, y_j^*}\\{ P C^{\\frac{1}{\\theta}} y_j^\\frac{\\theta - 1}{\\theta} +  I(X_j = 1) (1 - \\tau_j) Q P^* {C^*}^{\\frac{1}{\\theta}}  {y_j^*}^\\frac{\\theta - 1}{\\theta} - wn_j - rk_j\\},\n\\] subject to equation the feasibility constraint. The optimal amounts for a plant to produce in domestic and foreign markets are: \\[\n\\begin{aligned}\ny_{j} &=\\frac{ \\xi_j^{\\theta} (1 - \\tau_j)^{-\\theta}   (\\frac{P}{Q P^*})^\\theta \\frac{C}{C^{*}}}{I \\left(X_{j}=1\\right) \\xi_j + \\xi_j^{\\theta} (1 - \\tau_j)^{-\\theta} (\\frac{P}{Q P^*})^\\theta \\frac{C}{C^{*}}} \\tilde{\\epsilon}_{j} n_{j}^{\\alpha_{N}} k_{j}^{\\alpha_{K}} \\\\\ny_{j}^{*} &= \\frac{I(X_j = 1)}{\\xi_j+ \\xi_j^{\\theta} (1 - \\tau_j)^{-\\theta} (\\frac{P}{Q P^*})^\\theta \\frac{C}{C^{*}}} \\tilde{\\epsilon}_{j} n_{j}^{\\alpha_{N}} k_{j}^{\\alpha_{K}} .\n\\end{aligned}\n\\]\nSubstituting in \\(y_j\\) and \\(y_j^*\\) to the profit maximization problem yields: \\[\n\\begin{aligned}\n\\Pi\\left(X_{j}, \\xi_j,  \\epsilon_{j}, Q\\right)=&\\max _{n_{j}, k_{j}} M n_{j}^{\\alpha_{N} \\frac{(\\theta-1)}{\\theta}} k_{j}^{\\alpha_{K} \\frac{(\\theta-1)}{\\theta}} - wn_{j}- r k_{j},\n\\end{aligned}\n\\] where \\(M = \\left(1+I\\left(X_{j}=1\\right) \\xi_j^{1 - \\theta} (1 - \\tau_j)^\\theta \\left(\\frac{Q P^*}{P}\\right)^{\\theta} \\frac{C^{*}}{C}\\right)^{\\frac{1}{\\theta}} P C^{\\frac{1}{\\theta}} \\tilde{\\epsilon}_{j}^{\\frac{\\theta-1}{\\theta}}\\)\nFrom first order conditions of labor and capital, for simplicity write \\(a = \\alpha_{N} \\frac{(\\theta-1)}{\\theta}\\) and \\(b = \\alpha_{K} \\frac{(\\theta-1)}{\\theta}\\), the maximized profit can be solved as: \\[\n\\Pi\\left(X_{j}, \\xi_j, \\epsilon_{j}, Q\\right) = M^{\\frac{1}{1-a-b}} (1-a-b) (\\frac{a}{w})^{\\frac{a}{1-a-b}} (\\frac{b}{r})^{\\frac{b}{1-a-b}}.\n\\] Equate \\(\\xi_j = 1\\) you get exactly the plant’s profit without export iceberg cost. Then with only export fixed cost driving the export barrier, the model is equivalent to the baseline sunk cost model from . Assuming no tariff, using the same notation, the profit a plant earns with an iceberg cost is exactly \\(\\left({\\frac{1+I\\left(X_{j}=1 \\right) \\xi_j^{1 - \\theta} \\left(\\frac{Q P^*}{P}\\right)^{\\theta} \\frac{C^{*}}{C}}{1+I\\left(X_{j}=1\\right) \\left(\\frac{Q P^*}{P}\\right)^{\\theta} \\frac{C^{*}}{C}}}\\right)^\\frac{1}{\\theta (1- a-b)}\\) of the same plant without an iceberg cost.\nJust for clarification, we can also solve for domestic and foreign sales: \\[\n    \\begin{aligned}\n       p_j y_{j} &= \\left(\\frac{ \\xi_j^{\\theta} (1 - \\tau_j)^{-\\theta} (\\frac{P}{Q P^*})^\\theta \\frac{C}{C^{*}}}{I \\left(X_{j}=1\\right) \\xi_j + \\xi_j^{\\theta} (1 - \\tau_j)^{-\\theta} (\\frac{P}{Q P^*})^\\theta \\frac{C}{C^{*}}}\\right)^{\\frac{\\theta - 1}{\\theta}}   \\\\\n       & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ P C^{\\frac{1}{\\theta}} \\epsilon_j M^{\\frac{a + b}{1-a-b}} (\\frac{a}{w})^{\\frac{a}{1-a-b}} (\\frac{b}{r})^{\\frac{b}{1-a-b}} \\\\\n       Q p_j^* y_j^* &= I(X_j = 1) \\left(\\frac{1}{\\xi_j+ \\xi_j^{\\theta} (1 - \\tau_j)^{-\\theta} (\\frac{P}{Q P^*})^\\theta \\frac{C}{C^{*}}}\\right)^{\\frac{\\theta - 1}{\\theta}} \\\\\n       & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  Q P^* {C^*}^{\\frac{1}{\\theta}} \\epsilon_j M^{\\frac{a + b}{1-a-b}} (\\frac{a}{w})^{\\frac{a}{1-a-b}} (\\frac{b}{r})^{\\frac{b}{1-a-b}} .\n    \\end{aligned}\n\\]\nWe normalize the size of domestic aggregate demand \\(C\\) to 1, so \\(C^*\\) denotes the size of foreign demand relative the domestic demand. Define \\(\\epsilon_j = {\\tilde{\\epsilon}_j}^\\frac{\\theta - 1}{\\theta}\\), which follows an idiosyncratic AR1 shock for each plant. We normalize the mean of the \\(\\epsilon\\) process to one.\nFirms face idiosyncratic productivity shocks, a fixed cost for becoming an exporter abd and an iceberg cost for exports.\n\n\n\n5.2 Firm’s Dynamic problem\nWe first introduce an export fixed cost structure as in Ruhl and Willis (2017). The plant faces a sunk entry cost \\(f_E\\) and a continuation cost \\(f_C\\), \\(f_C \\leq f_E\\). All export decisions are made at the end of previous period and fixed costs are paid upon decision. The exporting cost of each period can be expressed as: \\[\n    f(X, X') = (1-X) * f_E * X' + X * f_C * X' .\n\\]\nWe then link the export decision of a plant with an endogenous and stochastic iceberg transportation cost \\(\\xi_j\\) as in Alessandria et al. (2021). A non-exporting plant doesn’t ship any goods abroad and we set its iceberg cost this period to infinity. The nonexporter can deterministically lower its fixed cost next period to \\(\\xi_E\\) by paying \\(f_E\\). If a current exporter pays \\(f_C\\) to continue exporting next period, it draws iceberg cost \\(\\xi_j \\in \\{\\xi_E, \\xi_C\\}\\) next period stochastically. The structure of the iceberg cost conditional on continuing to exporting can be summarized by a markov chain with states \\(\\xi_E\\) and \\(\\xi_C\\) with transition probability \\([ \\rho_{EE}, 1- \\rho_{EE} ; 1 - \\rho_{CC}, \\rho_{CC} ]\\). Assume \\(\\xi_C \\leq \\xi_E &lt; \\infty\\). If an exporter stops paying \\(f_C\\), it exits the export market and becomes a nonexporter with infinite iceberg cost next period.\nWe also have a persistent condition as \\(\\rho_\\xi(\\xi_E|\\xi_C) \\leq \\rho_\\xi(\\xi_C|\\xi_E)\\). With a lot of plants, this particular structure of iceberg cost creates incentives for some plants to invest in export technology and make the “better” exporters to become less susceptible to unfavorable shocks.\nOne last component is the technological shock \\(\\epsilon_j\\) that governs plant productivity, which generates heterogeneous plants and varying entry and exit export decisions of plants. It follows an idiosyncratic and time-invariant AR(1) processes for each plant: \\[\\begin{equation}\n\\ln{\\epsilon_t} = \\rho_\\epsilon\\ln{\\epsilon_{t-1}} + w_{\\epsilon,t}, \\hspace{1cm} w_\\epsilon \\sim N(0, \\sigma^2_\\epsilon).\n\\end{equation}\\] The shocks are discretized using Tauchen’s method. There are three key parameters to determine here: {{\\(N_\\epsilon\\), \\(\\rho_\\epsilon\\), \\(\\sigma_\\epsilon\\)}}. \\(N_\\epsilon\\) is the states of plant’s productivity, currently set to 1000 for simplicity.\nWe put aside our discussion of exchange rate shocks for the moment as an aggregate shock will make solving for the equilibrium prices and transition dynamics much harder. Exchange rates directly shift the export prices and create more uncertainties which make the foreign market more volatile. In particularly “bad” periods, there can be no firms deciding to export, leading to potentially poor simulation results.\nIn each period, every plant makes an discrete choice based on their current status and discounted expectation of future profits. The discount rate \\(R\\) is set to be \\(\\frac{1}{1+r}\\). We characterize the dynamic problem of each plant by the following Bellman equation: \\[\nV\\left(X_{j}, \\xi_j, \\epsilon_{j}, Q\\right)=\\max _{X_{j}^{\\prime}}\\left\\{\\Pi\\left(X_{j}, \\xi_j, \\epsilon_{j}, Q\\right)-f\\left(X_{j}, X'_{j} \\right)+R \\underset{\\xi_j^{\\prime}, \\epsilon_{j}^{\\prime}, Q^{\\prime}}{\\mathbb{E}} V\\left(X_{j}^{\\prime}, \\xi_j^{\\prime}, \\epsilon_{j}^{\\prime}, Q^{\\prime}\\right)\\right\\}.\n\\]\nThe policy function for export entry is thus: \\[\n    X_{j}^{\\prime}\\left(0, \\infty, \\epsilon_{j}, Q\\right)= \\begin{cases}1 & \\text{ if } \\hspace{0.5cm}  - f_E + \\\\\n{} & R \\underset{\\xi_j^{\\prime}, \\epsilon_{j}^{\\prime}, Q^{\\prime}}{\\mathbb{E}} \\left[V\\left(1, \\xi_E, \\epsilon_{j}^{\\prime}, Q^{\\prime}\\right)-V\\left(0, \\infty, \\epsilon_{j}^{\\prime}, Q^{\\prime}\\right)\\right] \\geq 0 \\\\ 0 & \\text { otherwise. }\\end{cases}\n\\]\nThe inequality on the right is the condition of a non-exporting plant choosing to be an exporter next period. The first two terms denote the current period profit minus the entry fixed cost. The discounted expectation is the difference of expected future values between starting to become an exporter with a low export technology \\(\\xi_E\\) and staying as an nonexporter.\n\n\n\n6. Solving the model\nAs always, let’s input some parameter value. I made the simplifying assumption that the real exchange rate \\(Q\\) is fixed.\n\nusing LinearAlgebra, Statistics, Distributions\nusing Plots\n\n\nBase.@kwdef struct Exporter{T1, T2, R1, S}\n    r::R1 = 0.109\n    αn::R1 = 0.45\n\n    αk::R1 = 1.0 - αn\n    θ::R1 = 5.0\n    w::R1 = 0.02\n\n    ξE::R1 = 1.6\n    ξC::R1 = 1.2\n    ξ::T1 = [ξE; ξC]\n    \n    ρEE::R1 = 0.92\n    ρCC::R1 = 0.92\n    Ξ::T2 = [ρEE (1.0-ρEE); (1.0-ρCC) ρCC]\n\n    Q::R1 = 1.0 # fix exchange rate for the moment\n\n    fE::R1 = 0.6\n    fC::R1 = 0.2\n    \n    ρϵ::R1 = 0.872524\n    σϵ::R1 = 0.115886\n\n    Cstar::R1 = 0.7 #C normalized to be 1.0\n\n    grids::S = 100\n\n    R = (1/(1+r))^0.25 # quarterly discount factor\nend\n\n\nE = Exporter() \n\nExporter{Vector{Float64}, Matrix{Float64}, Float64, Int64}(0.109, 0.45, 0.55, 5.0, 0.02, 1.6, 1.2, [1.6, 1.2], 0.92, 0.92, [0.92 0.07999999999999996; 0.07999999999999996 0.92], 1.0, 0.6, 0.2, 0.872524, 0.115886, 0.7, 100, 0.9744669483879411)\n\n\n\n6.1 Discretize an AR(1) process\nRecall that the reason we use discrete approximations of value functions is that the computer can’t process continuos variables. Same logic applies with an AR(1) process. We want to approximate the AR(1) process with a discrete markov chain, which is characterized by discrete states and a transition probability matrix. Check Quantecon’s lecture notes for a detailed explanation.\nAgain the AR(1) process we want to discretize is: \\[\n\\ln{\\epsilon_t} = \\rho_\\epsilon\\ln{\\epsilon_{t-1}} + w_{\\epsilon,t}, \\hspace{1cm} w_\\epsilon \\sim N(0, \\sigma^2_\\epsilon).\n\\]\nThe code (adopted from Quantecon) is:\n\nfunction tauchen(N::Integer, ρ::T1, σ::T2, μ=zero(promote_type(T1, T2)), n_std::T3=3) where {T1 &lt;: Real, T2 &lt;: Real, T3 &lt;: Real}\n  # Get discretized space\n  a_bar = n_std * sqrt(σ^2 / (1 - ρ^2))\n  y = range(-a_bar, stop=a_bar, length=N)\n  d = y[2] - y[1]\n\n  # Get transition probabilities\n  Π = zeros(promote_type(T1, T2), N, N)\n  for row = 1:N\n      # Do end points first\n      Π[row, 1] = cdf(Normal(),(y[1] - ρ*y[row] + d/2) / σ)\n      Π[row, N] = 1.0 - cdf(Normal(),(y[N] - ρ*y[row] - d/2) / σ)\n\n      # fill in the middle columns\n      for col = 2:N-1\n          Π[row, col] = (cdf(Normal(),(y[col] - ρ*y[row] + d/2) / σ) -\n                        cdf(Normal(),(y[col] - ρ*y[row] - d/2) / σ))\n      end\n  end\n\n  yy = exp.(y .+ μ / (1 - ρ)) # center process around its mean (wbar / (1 - rho)) in new variable\n  # take exponential to get to a ln process\n\n  # renormalize. In some test cases the rows sum to something that is 2e-15\n  # away from 1.0, which caused problems in the MarkovChain constructor\n  Π = Π./sum(Π, dims = 2)\n\n  return Π, yy\nend\n\ntauchen (generic function with 3 methods)\n\n\n\nΠ, ϵ_vec = tauchen(100, E.ρϵ, E.σϵ)\n\n([0.2355397082043846 0.0398220365205688 … 0.0 0.0; 0.2035639923092491 0.03686888293414207 … 0.0 0.0; … ; 4.784202347164862e-30 1.4778853656337744e-29 … 0.03686888293414202 0.20356399230924901; 1.3827115757372961e-30 4.347177100735715e-30 … 0.039822036520568704 0.23553970820438463], [0.4908675431085489, 0.4979749102029403, 0.5051851862545925, 0.5124998613024105, 0.5199204469598645, 0.5274484767273707, 0.5350855063091983, 0.5428331139349621, 0.5506929006857724, 0.5586664908251056  …  1.7899766970506505, 1.8158941194896647, 1.84218680535361, 1.8688601881549594, 1.8959197800790755, 1.9233711731233287, 1.9512200402527142, 1.9794721365721941, 2.0081333005160213, 2.0372094550542794])\n\n\n\n\n6.2 Functions\nExporter fixed cost (just for illustration, we don’t use this function)\n\nfunction expfixcost(X1::Int, X2::Int; E = E)\n    #X1 and X2 are 0, 1 variables\n    f = (1-X1) * E.fE * X2 + X1 * E.fC * X2;\n    return f\nend\n\nexpfixcost (generic function with 1 method)\n\n\nFirm’s profit function\n\nfunction profit(X, Evalue, ξ_idx, P, Pstar; E= E, Qvalue = E.Q, τ = 0.0)\n    (;θ, Cstar, αn, αk, w, r, ξ ) = E\n    M = (1.0 + X * ξ[ξ_idx]^(1.0 - θ)* (1.0 - τ)^θ * ((Qvalue * Pstar/ P)^θ) * Cstar)^(1.0/θ) * P * Evalue\n    a = αn * (θ - 1.0)/θ\n    b = αk * (θ - 1.0)/θ\n    Profit = (1.0-a-b) * M^(1.0/(1.0-a-b)) * (a/w)^(a/(1.0-a-b)) * (b/r)^(b/(1.0-a-b))\n    \n    return Profit\nend\n\nprofit (generic function with 1 method)\n\n\nSales at domestic and foreign markets:\n\nfunction sales(X, Evalue, ξ_idx, P, Pstar; E= E, Qvalue = E.Q, τ = 0.0)\n    (;θ, Cstar, αn, αk, w, r, ξ) = E\n    M = (1.0 + X * ξ[ξ_idx]^(1.0 - θ)* (1.0 - τ)^θ * ((Qvalue * Pstar/ P)^θ) * Cstar)^(1.0/θ) * P * Evalue\n    a = αn * (θ - 1.0)/θ\n    b = αk * (θ - 1.0)/θ\n    con = ξ[ξ_idx]^θ * (1.0 - τ)^(-θ) * (P/ (Qvalue * Pstar))^θ/Cstar\n    sales_do = (con/(X * ξ[ξ_idx] + con))^((θ-1.0)/θ) * P * Evalue * M^((a + b)/(1.0-a-b)) * (a/w)^(a/(1.0-a-b)) * (b/r)^(b/(1.0-a-b))\n    if X == 0\n        sales_fo = 0.0\n    else\n        sales_fo = (1.0-τ) * (1.0/(ξ[ξ_idx] + con))^((θ-1.0)/θ) * Qvalue * Pstar * Cstar^(1.0/θ) * Evalue * M^((a + b)/(1.0-a-b)) * (a/w)^(a/(1.0-a-b)) * (b/r)^(b/(1.0-a-b)) # foreign sales net of tariffs\n    end\n    return [sales_do, sales_fo]\nend\n\nsales (generic function with 1 method)\n\n\nTake a try on the functions. Again . is used for broadcasting and Ref() is used to fix inputs.\n\nprofit.([1, 0], [1.2, 0.8], [1, 1], Ref(0.1), Ref(0.2))\n\n2-element Vector{Float64}:\n 0.08608093339518139\n 0.002565830909582643\n\n\n\nreduce(hcat, sales.([1, 0], [1.2, 0.8], [1, 1], Ref(1.0), Ref(1)))'\n\n2×2 adjoint(::Matrix{Float64}) with eltype Float64:\n 9742.14  1040.57\n 1282.92     0.0\n\n\nIndividual prices (\\(p_j\\) and \\(p_j^*\\))\nThe function defined here needs to be modified to incorporate cases where \\(\\alpha_n + \\alpha_k \\neq 1\\).\n\nfunction ind_price(X, Evalue, ξ_idx; E = E, Qvalue = E.Q, τ = 0.0)\n    (;θ, αn, αk, w, r, ξ) = E\n    MC = Evalue^(θ/(1.0 - θ)) * (w/αn)^αn * (r/αk)^αk\n    do_p = (θ/(θ - 1.0)) * MC\n    if X == 0\n        fo_p = -1.0 # make foreign price negative for non-exporters\n    else\n        fo_p = (θ/(θ - 1.0)) / (1.0 - τ) * ξ[ξ_idx] * MC/Qvalue\n    end\n    return [do_p, fo_p]\nend\n\nind_price (generic function with 1 method)\n\n\n\nind_p_mat = reduce(hcat, ind_price.([0 1], [1.0 1.2], [1 1]))'[:,1]\nind_pstar_mat = reduce(hcat, ind_price.([0 1], [1.0 1.2], [1 1]))'[:,2]\n\n2-element Vector{Float64}:\n -1.0\n  0.16104839447304678\n\n\nAggregate price \\(P\\) and \\(P^*\\)\n\nfunction agg_price(ind_p_mat, ind_pstar_mat; θ = E.θ)\n    P = (sum(ind_p_mat.^(1.0 - θ)))^(1.0/(1.0 - θ))\n    Pstar = ((sum(ind_pstar_mat[ind_pstar_mat .&gt;= 0]).^(1.0 - θ)))^(1.0/(1.0 - θ))\n    return P, Pstar\nend\n\nagg_price (generic function with 1 method)\n\n\n\nagg_price(ind_p_mat, ind_pstar_mat)\n\n(0.09250365544979017, 0.16104839447304678)\n\n\n\n\n6.3 Solve the firm’s problem\nSolving the model is rather standard except that I chose to separate out the problem of a non-exporter and an exporter with either exporting technology \\(\\xi\\).\n\nfunction solve_exporter_fixQ(E, P, Pstar, τ; vNX0 = zeros(E.grids, 1), vEX0 = zeros(E.grids, length(E.ξ)), tol = 1e-6, Q = E.Q)\n    # unpacking\n    (; R, fE, fC, ξ, Ξ, fE, fC, ρϵ, σϵ, grids) = E\n\n    vNX1 = similar(vNX0) # to store value of non-exporters\n    vEX1 = similar(vEX0) # to store value of exporters\n    polNX = similar(vNX0, Int) # to store policy of non-exporters\n    polEX = similar(vEX0, Int) # to store policy of exporters\n\n    REvNX = similar(vNX0) # expected value if choosing not to export\n    REvEX_NX = similar(vNX0) # expected value if choosing to export as a non-exporter\n    REvEX_EX = similar(vEX0) # expected value if choosing to export as an exporter with different ξ's\n    \n    domesticm, ~ = sales(0, 1.0, 1, P, Pstar; E = E, Qvalue = Q, τ = 0.0) # sales of a non-exporting medium firm\n\n    # productivity process\n    Π, ϵ_vec = tauchen(grids, ρϵ, σϵ)\n\n    # Precompute the profits for firms at all states \n    proNX = profit.(zeros(Int, grids, 1), ϵ_vec, ones(Int, grids, 1), Ref(P), Ref(Pstar); E= E, Qvalue = Q, τ = τ)\n    # input for ξ doesn't matter\n\n    proEX = similar(vEX0)\n    for i in 1:length(ξ)\n        proEX[:,i] = profit.(ones(Int, grids, 1), ϵ_vec, i.*ones(Int, grids, 1), Ref(P), Ref(Pstar); E= E, Qvalue = Q, τ = τ)\n    end\n\n    # VFI\n    iter = 0\n    while true\n        distance = zero(eltype(vNX0))\n        iter += 1 \n\n        # Precompute RE[V(.)|X, ϵ, ξ] for better performance\n        REvNX = R * Π * vNX0\n        REvEX_NX = R * Π * vEX0[:,1] # enters with entry export technology\n        REvEX_EX = R * Π * vEX0 * Ξ'\n\n        vNX1 = max.((proNX + REvNX), (proNX .- fE * domesticm + REvEX_NX))\n        vEX1 = max.((proEX .+ REvNX), (proEX .- fC * domesticm + REvEX_EX))\n\n        distance = max(maximum(abs.(vNX1 - vNX0)), maximum(abs.(vEX1 - vEX0)))\n\n        (distance &lt; tol || iter == 2000) && break\n        vNX0 .= vNX1\n        vEX0 .= vEX1\n    end\n\n    # get policy\n    polNX .= 0\n    polEX .= 0\n    for i in 1:grids\n        if (REvNX[i]) &lt; (- fE * domesticm + REvEX_NX[i])\n            polNX[i] = 1\n        end\n        for j in 1:length(ξ)\n            if (REvNX[i]) &lt; (- fC * domesticm + REvEX_EX[i,j])\n                polEX[i,j] = 1\n            end\n        end\n    end\n\n    return (vNX = vNX1, vEX = vEX1, polNX = polNX, polEX = polEX, Π = Π, ϵ_vec =ϵ_vec, iter = iter)\n\nend\n\nsolve_exporter_fixQ (generic function with 1 method)\n\n\n\n@time begin\n    sol_try = solve_exporter_fixQ(E, 0.1, 0.1, 0.0);\nend\n\n  0.021312 seconds (14.35 k allocations: 7.747 MiB, 48.11% gc time)\n\n\n(vNX = [0.4360154494851622; 0.437186123813252; … ; 1.4838358575240558; 1.5257584977020988;;], vEX = [0.43603928462977926 0.4360907803125939; 0.43721173522491963 0.43726706852173247; … ; 1.5350851689447875 1.680995332627831; 1.5793313776889149 1.7326647962605208], polNX = [0; 0; … ; 1; 1;;], polEX = [0 0; 0 0; … ; 1 1; 1 1], Π = [0.2355397082043846 0.0398220365205688 … 0.0 0.0; 0.2035639923092491 0.03686888293414207 … 0.0 0.0; … ; 4.784202347164862e-30 1.4778853656337744e-29 … 0.03686888293414202 0.20356399230924901; 1.3827115757372961e-30 4.347177100735715e-30 … 0.039822036520568704 0.23553970820438463], ϵ_vec = [0.4908675431085489, 0.4979749102029403, 0.5051851862545925, 0.5124998613024105, 0.5199204469598645, 0.5274484767273707, 0.5350855063091983, 0.5428331139349621, 0.5506929006857724, 0.5586664908251056  …  1.7899766970506505, 1.8158941194896647, 1.84218680535361, 1.8688601881549594, 1.8959197800790755, 1.9233711731233287, 1.9512200402527142, 1.9794721365721941, 2.0081333005160213, 2.0372094550542794], iter = 375)\n\n\nFind the cutoff productivity levels\n\nfunction find_cutoff_prod(sol)\n    (; polNX, polEX, ϵ_vec) = sol\n    cutoff_ϵ = zeros(eltype(ϵ_vec), size(polEX)[2] + 1)\n    for i in 1:size(polNX)[1]\n        if polNX[i] == 1\n            cutoff_ϵ[1] = ϵ_vec[i]\n            break\n        end\n    end\n    \n    for j in 1:size(polEX)[2]\n        for i in 1:size(polEX)[1]\n            if polEX[i, j] == 1\n                cutoff_ϵ[j + 1] = ϵ_vec[i]\n                break # only break out of the inner loop\n            end\n        end\n    end\n\n    return cutoff_ϵ\nend\n\nfind_cutoff_prod (generic function with 1 method)\n\n\nNow we can find out the cutoff levels for the productivity \\(\\epsilon\\) for different export status \\(X\\) and export technology \\(\\xi\\) .\n\nfind_cutoff_prod(sol_try)\n\n3-element Vector{Float64}:\n 1.7644291820741218\n 1.3818813801525107\n 1.1299695318784664\n\n\nThis says that among different states, non-exporter needs the highest draw of productivity to become an exporter and the exporter with highest \\(\\xi\\) will not go back to a non-exporter only if the productivity falls very low.\n\n\n6.4 Stationary distribution for firms given prices\n\nfunction compute_stationary_distribution(sol;E = E, tol = 1e-8, pdf_0 = fill(1.0 / (size(sol_try.vEX)[1] * (size(sol_try.vEX)[2] + 1))  , (size(sol_try.vEX)[1] , (size(sol_try.vEX)[2] + 1))))\n\n    (; polEX, polNX, vEX, vNX) = sol\n\n    (; Ξ, ρϵ, σϵ, grids) = E\n\n    # productivity process\n    Π, ϵ_vec = tauchen(grids, ρϵ, σϵ)\n    \n    pdf_1 = similar(pdf_0)\n\n    iter = 0\n    while true \n        fill!(pdf_1, zero(eltype(pdf_0)))\n        iter +=1\n\n        for i in 1:grids\n            for iprime in 1:grids\n                pdf_1[iprime,1] += (1 - polNX[i]) * pdf_0[i, 1] * Π[i, iprime]\n                pdf_1[iprime,2] += polNX[i] * pdf_0[i, 1] * Π[i, iprime]\n                for j in 1:size(Ξ)[1]\n                    pdf_1[iprime,1] += (1 - polEX[i,j]) * pdf_0[i, j + 1] * Π[i, iprime]\n                    for jprime in 1:size(Ξ)[1]\n                        pdf_1[iprime,jprime + 1] += polEX[i, j] * Ξ[j, jprime] * Π[i, iprime] * pdf_0[i ,j + 1] \n                    end\n                end\n            end\n        end\n        \n        distance = zero(eltype(pdf_0))\n        for (a, b) in zip(pdf_0, pdf_1)\n            distance = max(abs(a - b), distance)\n        end\n        \n        (distance &lt; tol || iter == 2000) && break \n        pdf_0 .= pdf_1\n    end\n    pdf_1 = pdf_1\n    return pdf_1, iter\nend\n\ncompute_stationary_distribution (generic function with 1 method)\n\n\n\n@time begin\n    pdf_stationary, ~ = compute_stationary_distribution(sol_try)\nend\n\n  0.072110 seconds (224.32 k allocations: 12.099 MiB, 92.28% compilation time)\n\n\n([0.0011570437242512165 2.1145547603126288e-17 2.4311023610085744e-16; 0.0002998008153782488 3.0370638439024366e-17 3.491402314311281e-16; … ; 8.081413651159851e-5 0.00018671373465131073 3.2272944215721654e-5; 0.00020250322875128642 0.0008151092583492217 0.00013943123715096507], 55)\n\n\nCheck if it is still a distribution:\n\nsum(pdf_stationary)\n\n1.0\n\n\nLook at the shares of exporters at each states.\n\nNX_share, EX_low_share, EX_high_share = sum(pdf_stationary, dims = 1)\nprintln(\"The share of nonexporters is $NX_share, the share of exporters with low technology is $EX_low_share, the share of exporters with high technology is $EX_high_share, given prices in the stationary distribution, \")\n\nThe share of nonexporters is 0.9768202808538854, the share of exporters with low technology is 0.016599699825925476, the share of exporters with high technology is 0.006580019320189167, given prices in the stationary distribution, \n\n\n\n\n6.5 Stationary prices\nNow we have all the pieces ready for the stationary prices.\nThe algorithm goes as follows:\n\nFix the number of firms N\nStart from guesses of \\(P_0\\) and \\(P^*_0\\)\nFor each \\(P_t\\) and \\(P^*_t\\) solve the firm’s problem given prices.\nCompute invariant distribution \\(\\lambda(X, \\epsilon, \\xi)\\)\nGet new individual firm prices according to first order conditions of firms.\nGet the updated aggregate prices \\(P'_t\\) and \\(P'^{*}_t\\).\nGuess \\(P_{t + 1} = ϵ P'_t + (1 - ϵ) P_t\\) and \\(P^*_{t + 1} = ϵ P'^*_t + (1 - ϵ) P^*_t\\). Go back to the second step and iterate until convergence.\n\n\nfunction compute_stationary_equilibrium(E; P0=0.1, Pstar0=0.1, tol=1e-5, ϵ=0.2, τ=0.0, N=2000)\n    (; Ξ, ρϵ, σϵ, grids, θ) = E\n\n    Π, ϵ_vec = tauchen(grids, ρϵ, σϵ)\n\n    ind_p_mat = zeros(grids, size(Ξ)[1] + 1)\n    ind_pstar_mat = zeros(grids, size(Ξ)[1] + 1)\n\n    sol = solve_exporter_fixQ(E, P0, Pstar0, τ)\n    pdf, ~ = compute_stationary_distribution(sol)\n\n    for i in 1:grids\n        ind_p_mat[i, 1], ind_pstar_mat[i, 1] = ind_price(0, ϵ_vec[i], 1; τ=τ) .* pdf[i, 1]\n        for j in 1:size(Ξ)[1]\n            ind_p_mat[i, j+1], ind_pstar_mat[i, j+1] = ind_price(1, ϵ_vec[i], j; τ=τ) .* pdf[i, j+1]\n        end\n    end\n\n    Pprime1 = (sum(ind_p_mat.^(1.0 - θ) .*pdf .* N ))^(1.0/(1.0 - θ))\n    temp = ind_pstar_mat.^(1.0 - θ) .*pdf .* N \n    Pstarprime1 = (sum(temp[temp .&gt; 0.0]))^(1.0/(1.0 - θ))\n\n    P1 = ϵ * Pprime1 + (1.0 - ϵ) * P0\n    Pstar1 = ϵ * Pstarprime1 + (1.0 - ϵ) * Pstar0\n\n    P0 = copy(P1)\n    Pstar0 = copy(Pstar1)\n\n    iter = 0\n    while true\n        distance = zero(eltype(P0))\n        iter += 1\n\n        sol = solve_exporter_fixQ(E, P0, Pstar0, τ)\n        pdf, ~ = compute_stationary_distribution(sol)\n\n        for i in 1:grids\n            ind_p_mat[i, 1], ind_pstar_mat[i, 1] = ind_price(0, ϵ_vec[i], 1; τ=τ)\n            for j in 1:size(Ξ)[1]\n                ind_p_mat[i, j+1], ind_pstar_mat[i, j+1] = ind_price(1, ϵ_vec[i], j; τ=τ)\n            end\n        end\n\n        Pprime1 = (sum(ind_p_mat.^(1.0 - θ) .*pdf .* N ))^(1.0/(1.0 - θ))\n        temp = ind_pstar_mat.^(1.0 - θ) .*pdf .* N \n        Pstarprime1 = (sum(temp[temp .&gt; 0.0]))^(1.0/(1.0 - θ))\n\n        P1 = ϵ * Pprime1 + (1.0 - ϵ) * P0\n        Pstar1 = ϵ * Pstarprime1 + (1.0 - ϵ) * Pstar0\n\n        distance = max(abs(P1 - P0), abs(Pstar1 - Pstar0))\n        (distance &lt; tol || iter == 2000) && break\n\n        P0 = copy(P1)\n        Pstar0 = copy(Pstar1)\n    end\n\n    return P1, Pstar1, ind_p_mat, ind_pstar_mat, sol, pdf, iter\nend\n\ncompute_stationary_equilibrium (generic function with 1 method)\n\n\n\n@time begin\n    P_rce, Pstar_rce, ind_p_mat_rce, ind_pstar_mat_rce, sol_rce, pdf_rce, iter_rce = compute_stationary_equilibrium(E)\nend\n\n  0.416649 seconds (254.81 k allocations: 91.882 MiB, 2.54% gc time)\n\n\n(0.01595205933641332, 0.021695700591961128, [0.30768588844713596 0.30768588844713596 0.30768588844713596; 0.30220639279011097 0.30220639279011097 0.30220639279011097; … ; 0.052883757118820714 0.052883757118820714 0.052883757118820714; 0.05194196443888268 0.05194196443888268 0.05194196443888268], [-1.0 0.4922974215154175 0.36922306613656314; -1.0 0.4835302284641776 0.3626476713481332; … ; -1.0 0.08461401139011314 0.06346050854258485; -1.0 0.08310714310221229 0.062330357326659216], (vNX = [2.6845862763859143e-5; 2.7012079309207837e-5; … ; 0.0001826363856354905; 0.00018807831253375335;;], vEX = [2.6857343001530896e-5 2.6882145984155057e-5; 2.7024415088905326e-5 2.7051066464794964e-5; … ; 0.0002016186436944281 0.0002742056298972245; 0.00020817529306058711 0.00028429120581876285], polNX = [0; 0; … ; 1; 1;;], polEX = [0 0; 0 0; … ; 1 1; 1 1], Π = [0.2355397082043846 0.0398220365205688 … 0.0 0.0; 0.2035639923092491 0.03686888293414207 … 0.0 0.0; … ; 4.784202347164862e-30 1.4778853656337744e-29 … 0.03686888293414202 0.20356399230924901; 1.3827115757372961e-30 4.347177100735715e-30 … 0.039822036520568704 0.23553970820438463], ϵ_vec = [0.4908675431085489, 0.4979749102029403, 0.5051851862545925, 0.5124998613024105, 0.5199204469598645, 0.5274484767273707, 0.5350855063091983, 0.5428331139349621, 0.5506929006857724, 0.5586664908251056  …  1.7899766970506505, 1.8158941194896647, 1.84218680535361, 1.8688601881549594, 1.8959197800790755, 1.9233711731233287, 1.9512200402527142, 1.9794721365721941, 2.0081333005160213, 2.0372094550542794], iter = 37), [0.001099533362581301 4.863113223732801e-6 5.264581886217994e-5; 0.0002765981598866844 2.0442021739576122e-6 2.115811823782667e-5; … ; 1.0871545107504635e-11 0.00015613753141058758 0.00014366293801633918; 9.50637483804308e-12 0.0006012986410113883 0.0005557436441494431], 35)\n\n\nJust look at the insane speed. Remember we didn’t do any parallelization and stuff. These are just very efficient codes.\n\n\n6.6 Some results from the stationary equilibrium\nShare of firms in each state\n\nNX_share, EX_low_share, EX_high_share = sum(pdf_rce, dims = 1)\nprintln(\"The share of nonexporters is $NX_share, the share of exporters with low technology is $EX_low_share, the share of exporters with high technology is $EX_high_share, in the stationary distribution, \")\n\nThe share of nonexporters is 0.19266736559312644, the share of exporters with low technology is 0.4157090422674407, the share of exporters with high technology is 0.391623592139432, in the stationary distribution, \n\n\nCutoff productivity for firms at different states.\n\nfind_cutoff_prod(sol_rce)\n\n3-element Vector{Float64}:\n 1.036592023817942\n 0.7555421023503837\n 0.5749616962539099\n\n\nWe can collect some moments from the stationary distribution. They will be useful for estimations.\n\nfunction moments_fixedQ(P, Pstar, sol, pdf, ind_p_mat, ind_pstar_mat; E = E, Qvalue = E.Q, τ = 0.0)\n    (;ρϵ, σϵ, grids, ξ) = E\n\n    Π, ϵ_vec = tauchen(grids, ρϵ, σϵ)\n\n    # exporter share\n    exporter_share = sum(pdf, dims = 1)[1]\n\n    # starter rate\n    starter_rate = sol.polNX⋅pdf[:,1]\n\n    # stopper rate (should be same as starter rate under stationary equilibrium)\n    stopper_rate = (1 .- sol.polEX)⋅pdf[:,2:3]\n    \n    # exporter sales ratio conditional on exporting\n    sales_EX_do = zeros(eltype(P), grids, length(ξ))\n    sales_EX_fo = similar(sales_EX_do)\n    accum = zero(eltype(P))\n    for i in 1:grids\n        for j in 1:length(ξ)\n               sales_EX_do[i, j], sales_EX_fo[i, j]  = sales(1, ϵ_vec[i], j, P, Pstar; E= E, Qvalue = Qvalue, τ = τ)\n               accum += sales_EX_fo[i, j]/(sales_EX_do[i, j] + sales_EX_fo[i, j]) * pdf[i, j+1]/(1.0-exporter_share )\n        end\n    end\n\n    # average export price (in domestic currency) and domestic price ratio conditional on exporting\n    fo_price_ratio = sum(Qvalue.*ind_pstar_mat[:,2:3]./ind_p_mat[:,2:3].*pdf_rce[:,2:3])/(1.0-exporter_share)\n\n    return exporter_share, starter_rate, stopper_rate, accum, fo_price_ratio \nend\n\nmoments_fixedQ (generic function with 1 method)\n\n\n\nmoments_fixedQ(P_rce, Pstar_rce, sol_rce, pdf_rce, ind_p_mat_rce, ind_pstar_mat_rce)\n\n(0.19266736559312644, 0.01391198296999171, 0.013911817889600284, 0.46736658942224996, 1.4059666732401315)\n\n\nNote that by optimality condition of an exporting firm. \\(Q p_j^* /p_j = \\frac{\\xi}{1 - \\tau}\\), so the last moment, the average export price ratio conditional on exporting can also be computed from the the parameter values of \\(\\xi\\) and \\(\\tau\\) and the conditional fraction of exporters at different states of \\(\\xi\\). This moment can be interpreted as a premium for exporting.\nPlay with it and try with different parameters. How does the steady state equilibrium change?"
  },
  {
    "objectID": "Julia/Lectures/Julia_Lec_1_Compecon_Xing_Xu.html",
    "href": "Julia/Lectures/Julia_Lec_1_Compecon_Xing_Xu.html",
    "title": "Introduction to Julia on Computational Economics",
    "section": "",
    "text": "Xing Xu, University of Minnesota, 2024 Summer"
  },
  {
    "objectID": "Julia/Lectures/Julia_Lec_1_Compecon_Xing_Xu.html#overview",
    "href": "Julia/Lectures/Julia_Lec_1_Compecon_Xing_Xu.html#overview",
    "title": "Introduction to Julia on Computational Economics",
    "section": "Overview",
    "text": "Overview\nThe purpose of the class is to get you familiarize with some basic dynamic programming (DP) problems in economics and train you to be comfortable with coding them in Julia.\n\nWhy DP?\nDynamic programming is the key to solving modern economic models. Most macro models now are dynamic general equilibrium models. Knowing how to solve recursive models is in additional useful for searching, matching and even game theory (with sequential games).\n### Why Julia?\nJulia is the most modern tool for computations. It preserves the efficiency and clarity of coding while providing astounding speed. For comparison, c++ and Fortran are as fast but coding in them requires a lot more work as basically everything has to be built from scratch. Another extreme is Stata, which is super easy to code in (say, reg y x), but is absurdly slow and extremely limited in its applications (can’t even perform DP).\nJulia reaches a great balance and is perfectly suited for computational economics. You will see its beauty in action once you get comfortable with it.\n\n\nBackground knowledge\nI will list the backgrounds used that are considered as known. Additional knowledge will be specified when used.\nMath Preliminaries (undergraduate level knowledge is sufficient):\n\nLinear algebra\nReal analysis\nProbability theory\nBasic understanding of Markov Chains\nKnowledge of basic optimization theory will be a plus (Sundaram &lt;A First Course in Optimization Theory&gt;)\n\nEconomics: * Basic choice theory (Chapter 2 MWG) (Preferences, utility representation)\n\nBasic consumer theory (Chapter 3 MWG) (Utility maximization)\nBasic producer theory (Chapter 5 MWG)\nAn idea of Competitive Equilibrium and Welfare Theorems (Chapter 10 MWG)\n\nJulia (required reading): * Setup of Julia environment, Quantecon 1\n\nIntroduction to Julia Quantecon 2\nJulia Essentials Quantecon 3\nArrays, Tuples, Ranges, and Other Fundamental Types Quantecon 4\nBasic understanding is good: Introduction to Types and Generic Programming Quantecon 5\n\nOther good references:\nNotes: * Dirk Krueger’s Macroeconomic Theory notes\n\nTim Kehoe’s notes on Blackwell sufficient conditions\n\nBooks: * Adda & Cooper &lt;Dynamic economics&gt; (strongly recommend)\n\nStokey, Lucas with Prescott &lt;Recursive methods in economic dynamics&gt;\nLjungqvist & Sargent &lt;Recursive Macroeconomic Theory&gt;\nHeer & Maußner &lt;Dynamic General Equilibrium Modeling&gt;\nStachurski &lt;Economic Dynamics: Theory and Computation (Second Edition)&gt;"
  },
  {
    "objectID": "Julia/Lectures/Julia_Lec_1_Compecon_Xing_Xu.html#lecture-1-julia-fundamentals",
    "href": "Julia/Lectures/Julia_Lec_1_Compecon_Xing_Xu.html#lecture-1-julia-fundamentals",
    "title": "Introduction to Julia on Computational Economics",
    "section": "Lecture 1: Julia Fundamentals",
    "text": "Lecture 1: Julia Fundamentals\nThis acts as a review for Lecture 1.1 - 1.5 for Julia on Quantecon. I will only focus on stuffs we will use for the following lectures. This lecture accompanies a succinct assignment to get you familiarized with writing in the language and playing with it on the Jupyter Notebook.\n\n1.1 Packages and Projects\nWorking with packages is of vital importance in Julia. We use “LinearAlgebra” for matrix operations, “Statistics” for different distributions, “Plots” for, obviously, plots, etc. One thing you always need to keep in mind is how to download some packages.\nAfter downloading the essential packages you need, you have developed something called an “environment”. For compatibility, version control and reproducibility reasons, one often wants to create individual environments for different files. “Projects” manages each individual local environments. It will create a project repository that usually contains a “Project.toml”, a “Manifest.toml” and your code files.\n\n\n1.1.1 Packages and Projects using the Pkg API\nNow what are these exactly? Put this notebook into an individual folder and run the following lines.\n\nimport Pkg\n\n\nPkg.activate(\".\")  # Activate a local environment \nPkg.add(\"LinearAlgebra\") # add the package \"LinearAlgebra\"\n\n  Activating project at `~/Documents/Teaching/Julia course 2024/Julia/Lectures`\n   Resolving package versions...\n  No Changes to `~/Documents/Teaching/Julia course 2024/Julia/Lectures/Project.toml`\n  No Changes to `~/Documents/Teaching/Julia course 2024/Julia/Lectures/Manifest.toml`\n\n\nYou should find two extra files in the folder. A “Project.toml” and a “Manifest.toml”. Double click on each of them in the folder or just click on them in the editor in Vscode. Take a look. What are in them?\nThe “Project.toml” file contains the name of the package, its unique UUID, its version, the authors and potential dependencies.\nThe “Manifest.toml” file shows the information for the resulting dependencies of the added packages.\nYou can check the status of your package using the following code.\n\nPkg.status()\n\nStatus `~/Documents/Teaching/Julia course 2024/Julia/Lectures/Project.toml`\n  [37e2e46d] LinearAlgebra\n\n\nSometimes you want to run other people’s code. Say you have stored some people’s project into a folder on your laptop (you just need the “Project.toml” file). To activate the exact environment, the following code will automatically download all packages and their dependencies of the same version and make it the current environment.\n\nPkg.instantiate()\n\n\n\n1.1.2 Packages and Projects using REPL\nAll the above operations can also be done using REPL (Read-Evaluate-Print-Loop).\nTo activate REPL in Vscode, press CTRL + Shift + P in Windows or CMD + Shift + P in OS, then type “start REPL” in the command palette and click on it.\nNow the Terminal should pop up and you should see “julia&gt;”. This indicates we have successfully started the REPL.\nNext type ] to enter the package mode. It should write something like “(Julia course 2023 Summer) pkg&gt;”. To exit, simply press delete.\nWith the package mode, we can perform the same functionality as before and more.\nactivate. activate the project at the current directory.\nst shows the status.\nadd LinearAlgebra add the LinearAlgebra package to the local environment.\ninstantiate automatically downloads all the missing dependencies from the particular “Project.toml”.\n\n\n1.2 Introductory example for using packages\nWe will see a lot more packages and their usages along the way. For the moment, I will show some basic functionalities of the LinearAlgebra package as an example. For more information, check here.\nFirst, you need to call the Package with “using”.\n\nusing LinearAlgebra\n\nDefine a matrix:\n\nA = [1 2 3; 4 5 6; 7 8 9]\n\n3×3 Matrix{Int64}:\n 1  2  3\n 4  5  6\n 7  8  9\n\n\nA couple things you can do. The codes explain themselves.\n\ntr(A)\n\n15\n\n\n\ndet(A)\n\n-9.516197353929915e-16\n\n\n\ninv(A)\n\n3×3 Matrix{Float64}:\n  3.15252e15  -6.30504e15   3.15252e15\n -6.30504e15   1.26101e16  -6.30504e15\n  3.15252e15  -6.30504e15   3.15252e15\n\n\n\nnorm(A)\n\n16.881943016134134\n\n\n\neigvals(A)\n\n3-element Vector{Float64}:\n -1.1168439698070434\n -8.582743335036247e-16\n 16.11684396980703\n\n\n\neigvecs(A)\n\n3×3 Matrix{Float64}:\n -0.78583     0.408248  -0.231971\n -0.0867513  -0.816497  -0.525322\n  0.612328    0.408248  -0.818673\n\n\nI represents an identity matrix of any size. For example,\n\nA * I\n\n3×3 Matrix{Int64}:\n 1  2  3\n 4  5  6\n 7  8  9\n\n\nThe dot product can also be calculated.\n\ndot(A, I) # Same as tr(A)\n\n15\n\n\n\nA ⋅ I\n#⋅ is typed by \"\\cdot\" then press \"tab\"\n\n15\n\n\nAsolves Ax = B. Note that this is strictly preferred to inv(A)*B. Never do the latter.\n\nB = [1, 2, 3]\nA\\B\n# or B/A\n\n3-element Vector{Float64}:\n -0.23333333333333334\n  0.46666666666666673\n  0.09999999999999994\n\n\nElement-wise operations are done through . (more discussions on this next lecture).\n\nA .+ 3\n\n3×3 Matrix{Int64}:\n  4   5   6\n  7   8   9\n 10  11  12\n\n\nYou can also perform factorizations on the matrices.\n\nlu(A)\n\nLU{Float64, Matrix{Float64}}\nL factor:\n3×3 Matrix{Float64}:\n 1.0       0.0  0.0\n 0.142857  1.0  0.0\n 0.571429  0.5  1.0\nU factor:\n3×3 Matrix{Float64}:\n 7.0  8.0        9.0\n 0.0  0.857143   1.71429\n 0.0  0.0       -1.58603e-16\n\n\n\nqr(A)\n\nLinearAlgebra.QRCompactWY{Float64, Matrix{Float64}}\nQ factor:\n3×3 LinearAlgebra.QRCompactWYQ{Float64, Matrix{Float64}}:\n -0.123091   0.904534   0.408248\n -0.492366   0.301511  -0.816497\n -0.86164   -0.301511   0.408248\nR factor:\n3×3 Matrix{Float64}:\n -8.12404  -9.60114   -11.0782\n  0.0       0.904534    1.80907\n  0.0       0.0        -8.88178e-16\n\n\n\n# Cholesky decomposition doesn't work here, which creates an error\ncholesky(A)\n\nPosDefException: PosDefException: matrix is not Hermitian; Cholesky factorization failed.\n\n\nNot surprisingly, we can also do vector operations.\n\nv1 = [1, 1, 3]\nv2 = [2, 2, 3]\n\n3-element Vector{Int64}:\n 2\n 2\n 3\n\n\n\nv1 + v2 \n# same as v1 .+ v2\n\n3-element Vector{Int64}:\n 3\n 3\n 6\n\n\nDot products for vectors are same as for matrices, except for vectors we can simply do:\n\nv1' * v2 #' for transpose\n\n13\n\n\n\ndot(v1, v2)\n\n13\n\n\n\nv1 ⋅ v2\n\n13\n\n\n\nα = 0.3\nα * 2\n\n0.6\n\n\n\n\n1.2 Functions\nIn Julia functions can be built in line or specifically calling function.\n\nf(x, y) =  x^y\nf(2,2)\n\n4\n\n\n\n#Or\nfunction f(x, y)\n    return x^y\nend\nf(2,2)\n\n4\n\n\nIf you want to input an array into f, it gives an error as it is not clear what you mean.\n\nv1 = [1, 2, 3]\nf(v1, 2)\n\nMethodError: MethodError: no method matching ^(::Vector{Int64}, ::Int64)\n\nClosest candidates are:\n  ^(!Matched::Union{AbstractChar, AbstractString}, ::Integer)\n   @ Base strings/basic.jl:733\n  ^(!Matched::Diagonal, ::Integer)\n   @ LinearAlgebra ~/Applications/Julia-1.9.3.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/diagonal.jl:208\n  ^(!Matched::Diagonal, ::Real)\n   @ LinearAlgebra ~/Applications/Julia-1.9.3.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/diagonal.jl:207\n  ...\n\n\nYou can modify this by defining the function specifically for vectors.\n\nfunction g(x,y)\n    z = similar(x) # similar() generates an size/matrix of the same size and type as the input\n    for i in eachindex(x)\n        z[i] = x[i]^y\n    end\n    return z\nend\n@show g(v1, 2)\n\ng(v1, 2) = [1, 4, 9]\n\n\n3-element Vector{Int64}:\n 1\n 4\n 9\n\n\nOr in a more concise fashion,\n\ng(x,y) = [z^y for z in x] # or g(x,y) = [x[i]^y for i in eachindex(x)]\ng(v1, 2)\n\n3-element Vector{Int64}:\n 1\n 4\n 9\n\n\nInstead, you can also apply “.” to broadcast the function onto every element of v1. This comes very handy in a lot of cases.\n\nf(x, y) =  x^y\nf.(v1, 2)\n# should write f.(v1, Ref(2)) for rigidity. You can think of Ref() as fixing the input here.\n\n3-element Vector{Int64}:\n 1\n 4\n 9\n\n\n\n\n1.3 Types (a short summary)\nTypes are incredibly important for coding in Julia. It matters for the correctness, consistency and efficiency of the codes. However, my past experience told me that it is almost impossible to learn this from pure memorization. You have to actually work with them and think along the way. Here I will just let you see some commonly used types and give a simple example about declaration of types.\nFor more info on types, check the documentation.\nThe default type for (simple) integers is Int64\n\n@show typeof(1)\n\ntypeof(1) = Int64\n\n\nInt64\n\n\nThe default type for (simple) floats is Float64\n\n@show typeof(1.0) #putting \".0\" after 1 make the Julia compiler infer it is a float\n\ntypeof(1.0) = Float64\n\n\nFloat64\n\n\nThe default type for strings is String\n\n@show typeof(\"string\")\n\ntypeof(\"string\") = String\n\n\nString\n\n\nType of Boolean (true of false) variables.\n\n@show typeof(true)\n@show typeof(false)\n\ntypeof(true) = Bool\ntypeof(false) = Bool\n\n\nBool\n\n\n\n# Note that sometimes we use the feature that true equals to 1 and false equals to 0\n@show true == 1\n@show false == 0\n\ntrue == 1 = true\nfalse == 0 = true\n\n\ntrue\n\n\nWhat are the type of arrays?\n\n@show typeof([1, 2, 3])\n\ntypeof([1, 2, 3]) = Vector{Int64}\n\n\n\nVector{Int64} (alias for Array{Int64, 1})\n\n\n\n\n@show typeof([1.0, 2.0, 3.0])\n\ntypeof([1.0, 2.0, 3.0]) = Vector{Float64}\n\n\n\nVector{Float64} (alias for Array{Float64, 1})\n\n\n\nHow about the type of [1, 2.0, 3.0], where the first entry is an integer?\n\n@show typeof([1, 2.0, 3.0])\n\ntypeof([1, 2.0, 3.0]) = Vector{Float64}\n\n\n\nVector{Float64} (alias for Array{Float64, 1})\n\n\n\nNote that it returns a vector of floats. This is subtle but keep in mind that sometimes these type of inconsistencies can create problems. This also indicates that the type within an array is unified, to find the type of the elements in an array. We commonly use the following eltype().\n\n@show eltype([1.0, 2.0, 3.0])\n# differentiate with typeof([1.0, 2.0, 3.0])\n\neltype([1.0, 2.0, 3.0]) = Float64\n\n\nFloat64\n\n\nTuples are constructed using small brackets. We can also check the type of a tuple, which is different from the behavior of an array (vector).\n\n@show typeof((1, 2.0, 3.0, \"string\"))\n\ntypeof((1, 2.0, 3.0, \"string\")) = Tuple{Int64, Float64, Float64, String}\n\n\nTuple{Int64, Float64, Float64, String}\n\n\nNow let’s look at the function in 1.2 again, which is\n\nfunction g(x,y)\n    z = similar(x)\n    for i in eachindex(x)\n        z[i] = x[i]^y\n    end\n    return z\nend\n@show g(v1, 2)\n\ng(v1, 2) = [1, 4, 9]\n\n\n3-element Vector{Int64}:\n 1\n 4\n 9\n\n\nIn practice, sometimes we want to specify the types of inputs, which can be down using ::.\n\nfunction g(x :: Vector{Int64},y :: Int64)\n    z = similar(x)\n    for i in eachindex(x)\n        z[i] = x[i]^y\n    end\n    return z\nend\n@show g(v1, 2)\n\ng(v1, 2) = [1, 4, 9]\n\n\n3-element Vector{Int64}:\n 1\n 4\n 9\n\n\n\ng([2], 2)\n\n1-element Vector{Int64}:\n 4\n\n\n\ng([2.0], 2)\n\n1-element Vector{Float64}:\n 4.0\n\n\nHowever this sometimes creates confusions. We can input a matrix or a float and still get out results:\n\nm1 = [2 2; 2 2]\ng(m1, 2)\n\n2×2 Matrix{Int64}:\n 4  4\n 4  4\n\n\n\ng(2.0, 2) # Note that 2.0 is not even technically a vector and the output becomes a 0-dimensional Array\n\nMethodError: MethodError: no method matching similar(::Float64)\n\nClosest candidates are:\n  similar(!Matched::Union{Adjoint{T, var\"#s972\"}, Transpose{T, var\"#s972\"}} where {T, var\"#s972\"&lt;:(AbstractVector)})\n   @ LinearAlgebra ~/Applications/Julia-1.9.3.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/adjtrans.jl:329\n  similar(!Matched::Union{Adjoint{T, var\"#s972\"}, Transpose{T, var\"#s972\"}} where {T, var\"#s972\"&lt;:(AbstractVector)}, !Matched::Type{T}) where T\n   @ LinearAlgebra ~/Applications/Julia-1.9.3.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/adjtrans.jl:330\n  similar(!Matched::Union{Adjoint{T, S}, Transpose{T, S}} where {T, S})\n   @ LinearAlgebra ~/Applications/Julia-1.9.3.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/adjtrans.jl:333\n  ...\n\n\nThis is why Quantecon stresses the importance for generic programming. See Quantecon 5 and Quantecon 6 for details. In short, you should avoid specifying particular types unless necessary and let your codes be compatible with different types.\n\nIn addition, keep in mind that you might specify some types without even knowing that you are doing so. One example is when you want to create a vector of 0 of type Int with length 5. It is tempted to use the built-in function zeros(5). Beware that this implicitly imposes that 0s are of type float.\n\nzeros(5)\n\n5-element Vector{Float64}:\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n\n\n\n@show eltype(zeros(5))\n\neltype(zeros(5)) = Float64\n\n\nFloat64\n\n\nSuppose you want the zeros with type int, one way is to use Int(). Again you need to broadcast it to each element.\n\nInt.(zeros(5))\n\n5-element Vector{Int64}:\n 0\n 0\n 0\n 0\n 0\n\n\nOr you can simply declare within zeros().\n\nzeros(Int,5)\n\n5-element Vector{Int64}:\n 0\n 0\n 0\n 0\n 0\n\n\n\n\n1.4 Help?\nHow do you know you can do something as zeros(Int,5)? For most built-in functions, you can find it using Help from the REPL.\nIf you haven’t quitted Vscode, you are probably still in REPL from 1.1.\nIf you have, press CTRL + Shift + P in Windows or CMD + Shift + P in OS, then type “start REPL” in the command palette and click on it. You should again see “julia&gt;”, which indicates you are at REPL.\nNow simply typing ? enters into the help mode. You should see “help?&gt;”. Let’s try with the function zeros(). Type in the zeros or zeros() and press Return on your keyboard. You should see it shows the first input of function is “[T=Float64,]”, so unless otherwise specified, zeros() will generate an array with type “Float64”.\nHelp? is usually the first place to go if you encounter some built-in functions that you are not sure with. As we go, you will be introduced to a lot more of them.\n\n\n1.5 Macros (not Macroeconomics)\nMacros are a powerful tool in Julia. Macros are a type of metaprogramming (whatever this means). Just keep in mind that Macros start with an @ and take in general expressions instead of values as inputs. You can also check with help? for documentation of each Macro.\nI know it sounds a little absurd but knowing Macros well is a ticket to becoming a Julia master. For the moment, knowing a couple examples is sufficient.\nWe have used @show to show the output of a function. However, note that the inputs it can take is much more general. Say, it can take in the function itself.\n\n@show f\n\nf = f\n\n\nf (generic function with 1 method)\n\n\n\n@show f(1,2)\n\nf(1, 2) = 1\n\n\n1\n\n\n@time begin ... end works like tic ... tok in Matlab. It gives the duration of running the code between.\n\n@time begin\n    1 + 1\nend\n\n  0.000001 seconds\n\n\n2\n\n\nAnother example is @assert, which can be used for generating some statements if some conditions are not met.\n\nv1 = [1, 2, 3]\nv2 = [4, 5, 6]\n@assert v1 == v2 \"v1 is not equal to v2\"\n\nAssertionError: AssertionError: v1 is not equal to v2\n\n\n\n# no statement is generated if the condition is met\n@assert v1 == v1 \"v1 is not equal to v1\"\n\nA couple other useful Macros:\n@. Broadcasts . onto all arguments in one line.\n@inbounds Eliminates array bounds checking within expressions (efficiency).\n@inline Performs inline Maths (efficiency).\n@view Creates a data structure that acts like an array (it is a subtype of AbstractArray ), but the underlying data is actually part of another array. Often used to create a temporary array for efficiently.\nFor more, check here.\n\nj(x) = x^2\nv1 = [1,2,3]\nj.(v1)\n\n3-element Vector{Int64}:\n 1\n 4\n 9\n\n\n\n@. (j(v1) + 2)*2\n\n3-element Vector{Int64}:\n  6\n 12\n 22\n\n\n\n\n1.6 Miscellaneous facts about Julia (under construction)\nJulia has a particular behavior when assigning an array to another. What is your guess for the result of the following code?\n\nx = [3, 3]\ny = x\ny[1] = 6\n@show x\n\nx = [6, 3]\n\n\n2-element Vector{Int64}:\n 6\n 3\n\n\nOne might guess that the output will be “[3, 3]” as x is not changed. It is exactly what will happen in Python or Matlab. However, running it gives a seemingly surprising result.\n\nx = [3, 3]\ny = x\ny[1] = 6\n@show x\n\nx = [6, 3]\n\n\n2-element Vector{Int64}:\n 6\n 3\n\n\n\n# also\nx[2] = 6\n@show y\n\ny = [6, 6]\n\n\n2-element Vector{Int64}:\n 6\n 6\n\n\nThe reason is that on the background of Python or Matlab. When you run y = x, they create a copy for x in the storage and make it y. However in Julia, y = x simply assigns y to the same array that x is assigned to. That’s why changing either of them changes the other.\nThere are two alternative ways if you want the same behavior as in Python or Matlab.\n\nx = [3, 3]\ny = copy(x)\ny[1] = 6\n@show x\n\nx = [3, 3]\n\n\n2-element Vector{Int64}:\n 3\n 3\n\n\n\nx = [3, 3]\ny .= x #element-wise assignment dodges the problem\ny[1] = 6\n@show x\n\nx = [3, 3]\n\n\n2-element Vector{Int64}:\n 3\n 3\n\n\nEither one of them essentially makes y and x to be assigned to “different” arrays in your storage. If you know what a “pointer” is in c++, they now simply point to different places."
  },
  {
    "objectID": "Julia/Lectures/Julia_Lec_3_Compecon_Xing_Xu.html",
    "href": "Julia/Lectures/Julia_Lec_3_Compecon_Xing_Xu.html",
    "title": "Lecture 3: Continuous optimization",
    "section": "",
    "text": "This lecture is inspired by a question from Minnesota Alumnus Kim Ruhl, who is a coding enthusiast who was new to Julia. In response, I provided this brief introduction to optimization in Julia.\nIn this lecture and the third assignment, we will build towards solving standard dynamic programming problems in economics with continuous optimization methods. If you recall from the second lecture, given capital \\(k\\), we search on a discrete grid of \\(k'\\) for the one that maximizes the right hand side of the Bellman equation. This method is referred to as grid search. While intuitive and straightforward, grid search has inherent limitations. Given each state today, the optimal \\(k'\\) to choose will, in general, lie somewhere between grids of \\(k\\). For example, fixing a grid of \\(k'\\) (say 100 grids between 0 to 10), given a state \\(k\\), the optimal \\(k'\\) to choose might be, say, \\(3.875\\), which lies between the two grids we specify: \\(3.8\\) and \\(3.9\\). With the grid search method, \\(k'\\) will be assigned to be either one of the two and we will update the value function based on that. Note that we are losing precisions of our policy function and value function as a better guess shall be directly using \\(k' = 3.875\\). Poor precisions can cause quantitative biases and make the results of the model less reliable and robust.\nContinuous optimization methods offer a powerful alternative by allowing us to directly pinpoint the optimal value. But the advantages of continuous optimization go beyond mere precision. These methods exploit sophisticated numerical properties and algorithms that significantly accelerate the computation process. For example, techniques such as gradient descent, Newton-Raphson, and quasi-Newton methods are designed to efficiently navigate the complex landscape of the optimization problem, converging to the optimal solution much faster than traditional methods.\nIn the realm of economics, many models feature continuous choice variables, such as investment, consumption and labor supply. Continuous optimization methods are particularly well-suited for these models, as they can seamlessly handle the continuous nature of the decision variables, providing more accurate and reliable results. In these scenarios, continuous methods are usually the go-to method.\nHowever, it is important to recognize that continuous optimization methods come with their own set of challenges. These methods often rely on assumptions about the smoothness and differentiability of the objective function, which may not always hold in practice. Additionally, they can be sensitive to the initial conditions and parameter choices, sometimes leading to convergence issues or local optima traps. As we delve deeper into these methods, we will explore strategies to mitigate these challenges, ensuring that we can harness their full potential.\n\n1. A simple root-finding problem\nYou might or might not have heard or used Newton-Raphson method before. Named after Isaac Newton and Joseph Raphson, it is probably the most famous root-finding algorithm which produces successively better approximations to the roots (or zeroes) of a real-valued function.\nThe idea of it is very simple: we start with an initial guess, then to approximate the function by its tangent line, and finally to compute the x-intercept of this tangent line. This will often be a better approximation to the original function’s root than the first guess, and the method can be iterated.\nThe tangent line to the curve \\(f(x)\\) at \\(x = x_n\\) intercepts the x-axis at \\(x_{n+1}\\), then by definition the slope is \\[\nf'(x_n) = \\frac{f(x_n) - 0}{x_n - x_{n+1}}\n\\]\nSolving for \\(x_{n+1}\\) gets us, \\[\nx_{n+1}= x_n -  \\frac{f(x_n)}{f'(x_n)}\n\\]\nStart with some initial guess \\(x_0\\), we can iterate until convergence, where we obtain the root.\nBut what does this have to do with optimization? Root finding and optimization problems are actually of great mathematical resemblance. Think of the first thing you do with a (well-behaved) optimization problem. You take first order conditions! You get a function, say \\(g'(x) = 0\\), which is exactly a root-finding problem.\nNow, before resorting to any pre-written solvers, let’s do this very simple algorithm by hand to see how it works and get a sense of success before becoming hand-wavy and let solves do our jobs later on.\n\nimport Pkg\nPkg.activate(\".\")  # Activate a local environment \n\n  Activating new project at `~/Documents/Teaching/Julia course 2024/Julia/Lectures`\n\n\n\nusing Plots # add the Plots package if you don't have it yet.\nusing LinearAlgebra\n\nThe goal is to find the root of a function \\(f(x, p) = 0\\), where \\(x\\) is the independent variable and \\(p\\) are some parameters. We will consider where \\(p\\) is some general vectors.\n\n# A simple function of one variable and one parameter\nf(x, p) = -(x .- p) .^ 2;\n\nx = range(-5, 10, length=100);\nfx = f(x, 3);\nplot(x, fx, label = \"f(x)\")\nplot!(x, zeros(size(x)), label = \"x-axis\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObviously the function has a single root that equals to \\(p\\) (here 3).\nLet’s write down the Newton method to do this.\nHere this is just illustrative but for good practices of code, you shall always avoid using global variables and wrap the parameters into a struct (we have seen in lecture 2) or using a named tuple (defined below).\n\n\"\"\"\nCreate an instance of the model, stored as a named tuple.\n\n\"\"\"\nfunction create_showcase_model(; xmin = -10.0, #beware of type\n                                 xmax = 10.0,\n                                 nx = 100,\n                                 p = [3.0, 4.0])\n        x_grid = LinRange(xmin, xmax, nx)\n        f(x, p) = - (x .- p) .^ 2  #you can define functions in named tuples\n        return (; x_grid, f, p, nx)\nend\n\ncreate_showcase_model\n\n\n\n# create the tuple \nmodel = create_showcase_model()\n\n# want to change some parameter? You can do create_showcase_model(p = 4.0)\n\n(x_grid = LinRange{Float64}(-10.0, 10.0, 100), f = var\"#f#12\"(), p = [3.0, 4.0], nx = 100)\n\n\n\n# calling something from the tuple is exactly same as struct\nmodel.p\n\n2-element Vector{Float64}:\n 3.0\n 4.0\n\n\nThe key here is for Newton Method we need analytical or numerical derivative of the function. For functions (or systems) that have an analytical form, you can automatically compute the first derivative by using the ForwardDiff package. You can think of what the package does is to use the known differential laws (like the chain rule) to efficiently solve for analytical derivatives directly. It really works like magic.\n    fp = x -&gt; f(x,p) # change f into a one input funcion\n    autodiff(fp) = x -&gt; ForwardDiff.jacobian(fp, x) # automatic differentiation of f on x\n(Note: For a single output function, simply use ForwardDiff.derivative. Here since I made f multi-variable. I use ForwardDiff.jacobian instead. )\nThen I use fp and autodiff(fp) to get the Jacobian at our guesses and update it with the standard Newton method rule.\n\n# Import the package to perform automatic differentiation (you might need to Pkg.add this)\nusing ForwardDiff\n\n\nfunction Newton(f;p = model.p, tol = 1e-8, maxiter = 1000)\n    x0 = zeros(eltype(p), length(p)) #initial guesses at 0.0\n    x1 = similar(x0)\n    fp = x -&gt; f(x,p) # change f into a one input funcion\n    # automatic differentiation of f\n    autodiff(fp) = x -&gt; ForwardDiff.jacobian(fp, x)\n    \n    iter = 0\n    error = 1.0\n    while (error &gt; tol && iter &lt; maxiter)\n        # not the most efficient but clear\n        J = autodiff(fp)(x0) \n        x1 = x0 .- J\\fp(x0) #or use a linear solver\n        error = maximum(abs.(x1 - x0))\n        iter += 1\n        x0 .= x1\n    end\n\n    return x1\nend\n\nNewton (generic function with 1 method)\n\n\n\nNewton(model.f)\n\n2-element Vector{Float64}:\n 2.9999999944120646\n 3.9999999925494194\n\n\n\nusing BenchmarkTools # package for seeing system details of code running\n\n\n@benchmark Newton(model.f)\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  69.041 μs …  2.718 ms  ┊ GC (min … max): 0.00% … 94.98%\n Time  (median):     70.625 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   73.408 μs ± 71.275 μs  ┊ GC (mean ± σ):  2.68% ±  2.69%\n     ▂█▇▄                                                      \n  ▁▂▅████▇▅▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▂\n  69 μs           Histogram: frequency by time        84.9 μs &lt;\n Memory estimate: 36.55 KiB, allocs estimate: 672.\n\n\n\nThis is an idea of what is behind the nonlinear solvers of Julia. Of course they further optimized the code to make it more efficient.\nNow we use the NLsolve package. The naive implementation of it uses numerical Jacobian by finite differencing. The idea is to use the first order Taylor expansion to approximate the derivative. Note that here it does not require the function to have an analytical derivative.\n\nusing NLsolve\n\n\np = [3.0, 4.0]\nfp = x -&gt; model.f(x,p) # change f into a one input funcion\n# Newton method with numerical Jacobian by finite differencing\nnlsolve(fp, [0.0, 0.0]) #[0.0, 0.0] is the initial guess\n\nResults of Nonlinear Solver Algorithm\n * Algorithm: Trust-region with dogleg and autoscaling\n * Starting Point: [0.0, 0.0]\n * Zero: [2.999945851229831, 3.9999278016397692]\n * Inf-norm of residuals: 0.000000\n * Iterations: 19\n * Convergence: true\n   * |x - x'| &lt; 0.0e+00: false\n   * |f(x)| &lt; 1.0e-08: true\n * Function Calls (f): 20\n * Jacobian Calls (df/dx): 20\n\n\n\n@benchmark nlsolve(fp, [0.0, 0.0]) \n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  45.417 μs …  3.080 ms  ┊ GC (min … max): 0.00% … 96.98%\n Time  (median):     46.709 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   49.535 μs ± 82.344 μs  ┊ GC (mean ± σ):  4.63% ±  2.74%\n     ▄█▆█▅▂                                                    \n  ▂▃▆██████▇▄▄▃▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▂▁▂▂ ▃\n  45.4 μs         Histogram: frequency by time        57.2 μs &lt;\n Memory estimate: 38.47 KiB, allocs estimate: 518.\n\n\n\nAs you can see, even with numerical differencing, it takes less than half of the time of the version I wrote down.\nHow about we also use auto differentiation in NLsolve?\n\n# since we have analytical f here, we can use autodiff\n@benchmark nlsolve(fp, [0.0, 0.0], autodiff = :forward)\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  26.458 μs …  3.341 ms  ┊ GC (min … max): 0.00% … 97.25%\n Time  (median):     27.917 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   29.673 μs ± 64.021 μs  ┊ GC (mean ± σ):  4.24% ±  1.95%\n     ▄▇██▃                                                     \n  ▂▃▇█████▇▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂ ▃\n  26.5 μs         Histogram: frequency by time        41.2 μs &lt;\n Memory estimate: 20.77 KiB, allocs estimate: 258.\n\n\n\nNote that auto-differentiation provides better performance (more than 30% here).\nIf you like algebra, you can also manually inputting the derivatives:\n\nfprime(x, p) =  -2.0 * x .+ 2.0 .* p # analytical derivative\np = [3.0, 4.0]\nfprime_p = x -&gt; Diagonal(fprime(x, p)) #to create correct Jacobian\n\n#21 (generic function with 1 method)\n\n\n\nnlsolve(fp, fprime_p, [0.0, 0.0])\n\nResults of Nonlinear Solver Algorithm\n * Algorithm: Trust-region with dogleg and autoscaling\n * Starting Point: [0.0, 0.0]\n * Zero: [2.9999458512298305, 3.9999278016397737]\n * Inf-norm of residuals: 0.000000\n * Iterations: 19\n * Convergence: true\n   * |x - x'| &lt; 0.0e+00: false\n   * |f(x)| &lt; 1.0e-08: true\n * Function Calls (f): 20\n * Jacobian Calls (df/dx): 20\n\n\n\n@benchmark nlsolve(fp, fprime_p, [0.0, 0.0])\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  24.833 μs …  3.823 ms  ┊ GC (min … max): 0.00% … 98.14%\n Time  (median):     25.708 μs              ┊ GC (median):    0.00%\n Time  (mean ± σ):   27.441 μs ± 67.485 μs  ┊ GC (mean ± σ):  4.83% ±  1.95%\n     ▂▅▆█▂                                                     \n  ▂▃▆██████▆▅▄▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ ▃\n  24.8 μs         Histogram: frequency by time        32.6 μs &lt;\n Memory estimate: 18.34 KiB, allocs estimate: 255.\n\n\n\nSurprisingly (at least to me), manually inputting the Jacobian is not faster than automatic differentiation. This might not be the case when the non-linear system becomes more complicated but in such cases you won’t want to compute the analytical Jacobian anyways.\n*** Caveat: use auto-differentiation whenever possible. ***\nAn alternative package for root-finding is Nonlinearsolve, however from my experience it is slower than NLsolve.\n\n\n2. Interpolations\n\n2.1 Introduction to Interpolations in Julia\nAt its core, interpolation is the process of constructing new data points within the range of a discrete set of known data points. Suppose we have a set of \\(n\\) data points \\((x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)\\), where \\(x_i\\) are the (ordered) independent variable values and \\(y_i\\) are the dependent variable values. Interpolation seeks to estimate the value of the function \\(f(x)\\) at any given point \\(x\\) within the interval \\([x_1, x_n]\\).\nThere are many interpolation methods, but the simplest yet powerful one is Linear Interpolation. The idea is to simply connect the dots and use the lines between as the original functions. Mathematically, \\[\n\\hat{f}(x) = y_i + \\frac{y_{i+1} - y_i}{x_{i+1} - x_i} (x - x_i)\n\\]\nLet’s give it a try! The standard Julia package to use is Interpolations.jl (for linear interpolation it is pretty straightforward to write down your own function, try that.)\n\n# Import the package to perform automatic differentiation (you might need to Pkg.add this)\nusing Interpolations\n\n\n# log function\nu1(c) = log(c)\n\nu1 (generic function with 1 method)\n\n\n\n# specify two linear grids, one with more points\nc_grid_lin_coarse = LinRange(0.1, 5.0, 10)\nc_grid_lin_fine = LinRange(0.1, 5.0, 100)\n\n100-element LinRange{Float64, Int64}:\n 0.1, 0.149495, 0.19899, 0.248485, 0.29798, …, 4.85152, 4.90101, 4.95051, 5.0\n\n\n\nu1_lin_coarse = linear_interpolation(c_grid_lin_coarse, u1.(c_grid_lin_coarse));\nu1_lin_fine = linear_interpolation(c_grid_lin_fine, u1.(c_grid_lin_fine));\n\nWe are done. Not hard, huh? You can think of u1_lin_coarse and u1_lin_fine as the constructed functions, but beware that its actual type is a wrapper of methods. To call it, simply do\n\nu1_lin_fine(2.723) # estimated function value at 2.723\n\n1.0017334325350888\n\n\nLet’s see how they perform.\nInterpolations are widely applied in economics is to estimate numerical functions. Remember we stored the value function \\(V(k)\\) on a discrete grid of \\(k\\). What if we need to find points that are not exactly on the grid points? Since we don’t know the exact functional form of \\(V\\).\n\n# check the accuracy of the interpolations\nc_grid_lin_finer = LinRange(0.1, 5.0, 1000)\nplot(c_grid_lin_finer, u1.(c_grid_lin_finer), label = \"original\")\nplot!(c_grid_lin_finer, u1_lin_fine.(c_grid_lin_finer), label = \"linear interpolation, finer grids\")\nplot!(c_grid_lin_finer, u1_lin_coarse.(c_grid_lin_finer), label = \"linear interpolation, coarser grids\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the graph, it is not hard to see that when the curvature is bigger, interpolating on the coarser grid gives visible numerical errors, while the finer grids perform better.\nWe can also do higher orders of Spline Interpolations. It allows you to get better functional approximation while making sure that the specified grid points are exactly reached.\nTake cubic spline interpolations as example. Mathematically, it constructs a cubic polynomial \\(S_i(x)\\) and finds \\(a_i, b_i ,c_i\\) such that\n\\[\nS_i(x) = a_i + b_i(x - x_i) + c_i(x - x_i)^2 + d_i(x - x_i)^3,\n\\] and \\(S_i(x_i) = y_i\\), \\(S_i(x_{i+1}) = y_{i+1}\\) and the first and second derivatives of \\(S_i(x)\\) are continuous at each \\(x_i\\).\nNote that from the second condition, you see that higher-order interpolations are also powerful in obtaining numerical derivatives. Recall from the graph before, the function constructed from linear interpolation is continuous but generally not differentiable everywhere due to kinks at each grid points.\nLet’s see an example with cubic spline interpolation and compare it with the linear interpolation on the coarser grid.\n\nu1_cubic_coarse = cubic_spline_interpolation(c_grid_lin_coarse, u1.(c_grid_lin_coarse));\n\n\nplot(c_grid_lin_finer, u1.(c_grid_lin_finer), label = \"original\")\nplot!(c_grid_lin_finer, u1_lin_coarse.(c_grid_lin_finer), label = \"linear interpolation, coarser grids\")\nplot!(c_grid_lin_finer, u1_cubic_coarse.(c_grid_lin_finer), label = \"cubic spline interpolation, coarser grids\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can see that cubic spline interpolation (green line) gives smaller errors compared to linear interpolations (red line).\nOf course, we are still left with plenty of errors and in reality you will want to use more grids for this.\n\n\n2.2 Peril of Interpolations\nNow let’s try one of economists’ favorite function, the CRRA utility function (log is a special case) and do the same as before.\n\n# the constant σ is the relative risk aversion\nu2(c, σ) = c^(1.0 - σ)/(1.0 - σ)\n\nu2 (generic function with 1 method)\n\n\n\nσ = 2.0 # let the risk aversion be 2\nu2_lin_coarse = linear_interpolation(c_grid_lin_coarse, u2.(c_grid_lin_coarse, Ref(σ))); # \"Ref()\" specifies that σ is a scalar and won't be broadcasted\nu2_cubic_coarse = cubic_spline_interpolation(c_grid_lin_coarse, u2.(c_grid_lin_coarse, Ref(σ)));\n\n\nu2_cubic_coarse(2.5)\n\n-0.41019260074593517\n\n\n\nplot(c_grid_lin_finer, u2.(c_grid_lin_finer, Ref(σ)), label = \"original\")\nplot!(c_grid_lin_finer, u2_lin_coarse.(c_grid_lin_finer), label = \"linear interpolation, coarser grids\")\nplot!(c_grid_lin_finer, u2_cubic_coarse.(c_grid_lin_finer), label = \"cubic spline interpolation, coarser grids\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThink:\n\nFor both interpolations, when do they have larger errors and why (hint: what feature does \\(u''(c)\\) have?)?\nFor both interpolations, when does cubic spline interpolation has a larger error and why (hint: what feature does \\(S_i(x)\\) have?)?\n\nExercise:\n\nChange \\(\\sigma\\) to 5 and 10 and do the same experiment. Try with both coarser and finer grids. How does the accuracy vary and what are the lessons?\n\n\n\n\n3. Introduction to Continuous Optimization\nImplementing optimization routines is simple in Julia with the help of nicely written packages. The hard part is to know to use the right method at the right time. There are hundreds of different routines out there and each is best suited for particular cases. Do you know the explicit form of the function? Is the function continuous? Is it concave/convex? Is it differentiable? Are there local maxes/mins? A big chunk of the machine/deep learning literature dedicates to this. The details of the topic is too broad to be covered by this short introduction but just keep in mind that there is no silver bullet of it.\n\n3.1 Unconstrained Optimization\nTake the function we defined in section 1: \\(f(x, p) = -(x - p) ^ 2\\).\nGiven \\(p\\), we want to find the maximum of the function. Obviously the correct result should again be \\(p\\).\nThe standard package for optimization to use in Julia is Optim.jl, but you might also want to check NLopt.jl and JuMP.jl. They each contain different methods and tackle different problems.\nFor the optimization routine, we will use LBFGS here, which is a quasi-Newton method. There are a bunch of other options. Check here for more info.\n\nusing Optim # you have to add this package\n\nWARNING: using Optim.Newton in module Main conflicts with an existing identifier.\n\n\n\nf(x, p) = -(x[1] - p) ^ 2 #optimize take in vectors, here needs to specify x[1] for the first entry\nresult = optimize(x -&gt; -f(x, 3.0), [0.0], LBFGS()) # set p to 3, need to negative as we are trying to maximize the function\n\n * Status: success\n\n * Candidate solution\n    Final objective value:     1.502828e-21\n\n * Found with\n    Algorithm:     L-BFGS\n\n * Convergence measures\n    |x - x'|               = 3.00e+00 ≰ 0.0e+00\n    |x - x'|/|x'|          = 1.00e+00 ≰ 0.0e+00\n    |f(x) - f(x')|         = 9.00e+00 ≰ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 5.99e+21 ≰ 0.0e+00\n    |g(x)|                 = 7.75e-11 ≤ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    1\n    f(x) calls:    3\n    ∇f(x) calls:   3\n\n\n\n# get the argmax\nresult.minimizer \n\n1-element Vector{Float64}:\n 3.0000000000387663\n\n\n\n# the abosulte error is\nabs(result.minimizer[1] - 3.0)\n\n3.8766323484651366e-11\n\n\nAgain here we can use Autodiff as we have a differentiable function with explicit form.\n\nresult = optimize(x -&gt; -f(x, 3.0), [0.0], LBFGS(); autodiff = :forward)\n\n * Status: success\n\n * Candidate solution\n    Final objective value:     0.000000e+00\n\n * Found with\n    Algorithm:     L-BFGS\n\n * Convergence measures\n    |x - x'|               = 3.00e+00 ≰ 0.0e+00\n    |x - x'|/|x'|          = 1.00e+00 ≰ 0.0e+00\n    |f(x) - f(x')|         = 9.00e+00 ≰ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = Inf ≰ 0.0e+00\n    |g(x)|                 = 0.00e+00 ≤ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    1\n    f(x) calls:    3\n    ∇f(x) calls:   3\n\n\n\nabs(result.minimizer[1] - 3.0)\n\n0.0\n\n\nNote that the accuracy improved by using automatic differentiation.\n\n\n3.2 Constrained Optimization\nI rarely use quotes but here is a good one.\n“In economic theory, an agent is a constrained optimization problem. A model consists of a collection of constrained optimization problems. Theories of general equilibrium, games, and macroeconomics acquire power by deploying an equilibrium concept whose role is to organize disparate choice problems by casting them within a coherent environment.”\n– Thomas Sargent\nLet’s maximize the same function \\(f(x,3)\\), but this time put an interval constraint on \\(x\\), we will try \\([2, 6]\\) (which include the global max) and \\([-2, 2]\\) (which does not include the global max).\nThe syntax for optimization with a bounded interval is as follows\noptimize(f, lower, upper, method; kwargs...)\nI will use the Brent() method for illustration. An alternative is to use GoldenSection().\n\noptimize(x -&gt; -f(x, 3.0), 2, 6, Brent())\n\nResults of Optimization Algorithm\n * Algorithm: Brent's Method\n * Search Interval: [2.000000, 6.000000]\n * Minimizer: 3.000000e+00\n * Minimum: 0.000000e+00\n * Iterations: 5\n * Convergence: max(|x - x_upper|, |x - x_lower|) &lt;= 2*(1.5e-08*|x|+2.2e-16): true\n * Objective Function Calls: 6\n\n\n\noptimize(x -&gt; -f(x, 3.0), -2, 2, Brent())\n\nResults of Optimization Algorithm\n * Algorithm: Brent's Method\n * Search Interval: [-2.000000, 2.000000]\n * Minimizer: 2.000000e+00\n * Minimum: 1.000000e+00\n * Iterations: 37\n * Convergence: max(|x - x_upper|, |x - x_lower|) &lt;= 2*(1.5e-08*|x|+2.2e-16): true\n * Objective Function Calls: 38\n\n\nThe Brent method gives correct answers in both cases, showing its robustness (and very fast). Beware some Quasi-Newton methods can fail in the second case as we do not reach \\(f'(x) = 0\\) in the interval.\n\n\n3.3 Optimize an Interpolated Function\nWe have talked about the importance of continuos optimization. However, sometimes we don’t know the exact functional form of which we are optimizing. Moreover, we might only know the value of our objective function at certain points. The example as you have seen in the last lecture, is the right hand side of the Bellman equation.\nThis is where interpolation twines with continuous optimization. From the functional value at discrete grids, we first estimate the function by interpolation, then optimize it using continuous optimization. This is a standard routine in solving many economic models.\nAgain just for showcasing, we will maximize the same function, but let’s pretend we only know its values at a discrete grid and need to approximate it with interpolations.\n\nlingrid = LinRange(2.0, 6.0, 50);\nf_val = -f.(lingrid, Ref(3.0)); # values of fx that we know\n# need to extrapolate as unconstrained optimization requires value out of bounds\n# consult the documentation of Interpolations.jl for details on extrapolations\nf_interp = linear_interpolation(lingrid, f_val, extrapolation_bc = Line());\n\nLet’s check how well the interpolation does.\n\nfiner_grid = LinRange(2.0, 6.0, 500);\nplot(finer_grid, -f.(finer_grid, Ref(3.0)), label = \"Original\")\nplot!(finer_grid, f_interp.(finer_grid), label = \"Linear interpolation\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe two lines seem to align perfectly, so we are good to go, right?\nWe can do unconstrained and constrained optimization as before. Although we can’t use automatic differentiation anymore.\n\nresult1 = optimize(x -&gt; f_interp(x[1]), [4.0], LBFGS())\n\n * Status: success\n\n * Candidate solution\n    Final objective value:     4.168613e-04\n\n * Found with\n    Algorithm:     L-BFGS\n\n * Convergence measures\n    |x - x'|               = 1.23e-05 ≰ 0.0e+00\n    |x - x'|/|x'|          = 4.14e-06 ≰ 0.0e+00\n    |f(x) - f(x')|         = 3.65e-08 ≰ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 8.76e-05 ≰ 0.0e+00\n    |g(x)|                 = 6.58e-13 ≤ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    5\n    f(x) calls:    20\n    ∇f(x) calls:   20\n\n\n\nresult1.minimizer\n\n1-element Vector{Float64}:\n 2.979600858153335\n\n\n\nresult2 = optimize(f_interp, 2.0, 6.0, Brent())\n\nResults of Optimization Algorithm\n * Algorithm: Brent's Method\n * Search Interval: [2.000000, 6.000000]\n * Minimizer: 2.979592e+00\n * Minimum: 4.164937e-04\n * Iterations: 32\n * Convergence: max(|x - x_upper|, |x - x_lower|) &lt;= 2*(1.5e-08*|x|+2.2e-16): true\n * Objective Function Calls: 33\n\n\n\nresult2.minimizer\n\n2.979591849606776\n\n\nPretty big errors of 0.02 (this can be big, say you miss the equilibrium interest rate by 2%)! How come?\nThink about this for a bit yourself before reading forward.\nRemember when using the original function, we obtained error that was close to 0. We didn’t do anything different for the optimization routine, so it has to do with interpolation.\nGo back to the thinking question in the last section and look at the graph of the function again. You shall be able to find the answer yourself.\nIf not, let’s zoom in near the true maximization point (p):\n\nfiner_grid_shrinked = LinRange(2.8, 3.2, 500);\nplot(finer_grid_shrinked, f.(finer_grid_shrinked, Ref(3.0)), label = \"Original\")\nplot!(finer_grid_shrinked, -f_interp.(finer_grid_shrinked), label = \"Linear interpolation\")\nvline!([result2.minimizer], label = \"x obtained from the minimizer\", legend=:bottomright)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour should wow when you see this the first time.\nIn fact, the optimization package did exactly correct. It got the exact maximizer from your interpolated function. It is simply that the interpolated function is too biased around the maximizer due to high curvature around it.\nAlways keep in mind the peril of interpolation. It will save you enormous amount of time.\nHow to tackle this? More grid points and higher order of interpolations can help. Alternatively, you can put more points near where the curvature is high.\nSpecify the following grid where there are 10 more points in the range of 2 to 4 and 10 less points from 4 to 6. Number of total points remain unchanged.\n\nlingrid = vcat(collect(LinRange(2.0, 4.0, 35)), collect(LinRange(4.01, 6.0, 15))); #turn two linrange into vectors and combine them\nf_val = -f.(lingrid, Ref(3.0)); # values of fx that we know\nf_interp = linear_interpolation(lingrid, f_val, extrapolation_bc = false);\n\n\nresult2 = optimize(f_interp, 2.0, 6.0, Brent())\n\nResults of Optimization Algorithm\n * Algorithm: Brent's Method\n * Search Interval: [2.000000, 6.000000]\n * Minimizer: 3.000000e+00\n * Minimum: 9.262795e-10\n * Iterations: 20\n * Convergence: max(|x - x_upper|, |x - x_lower|) &lt;= 2*(1.5e-08*|x|+2.2e-16): true\n * Objective Function Calls: 21\n\n\n\nresult2.minimizer\n\n2.9999999842532477\n\n\n\nfiner_grid_shrinked = LinRange(2.8, 3.2, 500);\nplot(finer_grid_shrinked, f.(finer_grid_shrinked, Ref(3.0)), label = \"Original\")\nplot!(finer_grid_shrinked, -f_interp.(finer_grid_shrinked), label = \"Linear interpolation\")\nvline!([result2.minimizer], label = \"x obtained from the minimizer\", legend=:bottomright)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMuch better results. This kind of tricks is widely used in economic applications. In practice, people often use power grids instead of linear grids.\nIn the homework, you will rewrite the neo-classical growth model you have seen in lecture 2 with continuous optimization. You will compare the performances and results."
  }
]